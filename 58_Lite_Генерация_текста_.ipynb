{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10100111/Display-of-HW1/blob/main/58_Lite_%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D1%8F_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание Lite\n",
        "\n",
        "Макс 10 баллов\n",
        "\n",
        "Используя три любых простых вопроса, сравните ответы сети на них на разной степени натренированности:\n",
        "\n",
        "1. 20 эпох – удается ли боту отвечать целыми словами?\n",
        "\n",
        "2. + 30 эпох на этой же сетке и с этими же вопросами – появился ли прогресс в качестве ответа сети (ответ целыми предложениями разумной длины)?\n",
        "\n",
        "3. Ещё + 50 эпох – удается ли сети выдавать ответы, “похожие на правду”?"
      ],
      "metadata": {
        "id": "wgUR_f8bonxl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g-tBeFP38Rp"
      },
      "source": [
        "# **Import библиотек**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=10s\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j1Wpkvc3Q2s"
      },
      "source": [
        "from google.colab import files # модуль для загрузки файлов в colab\n",
        "import numpy as np # библиотека для работы с массивами данных\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model # из кераса подгружаем абстрактный класс базовой модели, метод загрузки предобученной модели\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input # из кераса загружаем необходимые слои для нейросети\n",
        "from tensorflow.keras.optimizers import RMSprop, Adadelta # из кераса загружаем выбранный оптимизатор\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # загружаем метод ограничения последовательности заданной длиной\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # загружаем токенизатор кераса для обработки текста\n",
        "from tensorflow.keras import utils # загружаем утилиты кераса для one hot кодировки\n",
        "from tensorflow.keras.utils import plot_model # удобный график для визуализации архитектуры модели\n",
        "\n",
        "import yaml # импортируем модуль для удобной работы с файлами"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "200dSPOYZE7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c65941e-63a1-4d0e-8739-eadc38e47543"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxdi0Fqeg1LH"
      },
      "source": [
        "# **Парсинг данных**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=87s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEA8TR_oerov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81d71ed-902d-461e-9fec-0c7df7730dd0"
      },
      "source": [
        "######################\n",
        "# Открываем файл с диалогами\n",
        "######################\n",
        "corpus = open('/content/drive/MyDrive/Базы/Диалоги(рассказы)_censored.yml', 'r') # открываем файл с диалогами в режиме чтения\n",
        "document = yaml.safe_load(corpus) # загружаем файл *глоссарий\n",
        "conversations = document['разговоры'] # загружаем диалоги из файла и заносим в conversations \n",
        "print('Количество пар вопрос-ответ : {}'.format(len(conversations)))\n",
        "print('Пример диалога : {}'.format(conversations[123]))\n",
        "corpus.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество пар вопрос-ответ : 11893\n",
            "Пример диалога : ['Перезалил?', 'Да вроде бы нет...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYg8z8Vj76bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82197ea9-4e5e-4f50-999f-a3b1d4ba604c"
      },
      "source": [
        "######################\n",
        "# Разбираем вопросы-ответы с проставлением тегов ответам\n",
        "######################\n",
        "# Собираем вопросы и ответы в списки\n",
        "questions = list() # здесь будет список вопросов\n",
        "answers = list() # здесь будет список ответов\n",
        "\n",
        "# В каждом диалоге берем фразу и добавляем в лист\n",
        "# Если в ответе не одна фраза - то сцепляем сколько есть\n",
        "for con in conversations: # для каждой пары вопрос-ответ\n",
        "  if len(con) > 2 : # если ответ содержит более двух предложений (кол-во реплик, кол-во вариантов ответа)\n",
        "    questions.append(con[0]) # то вопросительную реплику отправляем в список вопросов\n",
        "    replies = con[1:] # а ответную составляем из последующих строк\n",
        "    ans = '' # здесь соберем ответ\n",
        "    for rep in replies: # каждую реплику в ответной реплике\n",
        "      ans += ' ' + rep \n",
        "    answers.append(ans) #добавим в список ответов\n",
        "  elif len(con)> 1: # если на 1 вопрос приходится 1 ответ\n",
        "    questions.append(con[0]) # то вопросительную реплику отправляем в список вопросов\n",
        "    answers.append(con[1]) # а ответную в список ответов\n",
        "\n",
        "# Очищаем строки с неопределенным типом ответов\n",
        "answersCleaned = list()\n",
        "for i in range(len(answers)):\n",
        "  if type(answers[i]) == str:\n",
        "    answersCleaned.append(answers[i]) #если тип - строка, то добавляем в ответы\n",
        "  else:\n",
        "    questions.pop(i) # если не строка, то ответ не добавился, и плюс убираем соответствующий вопрос\n",
        "\n",
        "# Сделаем теги-метки для начала и конца ответов\n",
        "answers = list()\n",
        "for i in range(len(answersCleaned)):\n",
        "  answers.append( '<START> ' + answersCleaned[i] + ' <END>' )\n",
        "\n",
        "# Выведем обновленные данные на экран\n",
        "print('Вопрос : {}'.format(questions[200]))\n",
        "print('Ответ : {}'.format(answers[200]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вопрос : Около сотни...\n",
            "Ответ : <START> Точнее! <END>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvn1jvRd9tep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325488b3-7fce-4524-dc47-748459dbb8e6"
      },
      "source": [
        "######################\n",
        "# Подключаем керасовский токенизатор и собираем словарь индексов\n",
        "######################\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers) # загружаем в токенизатор список вопросов-ответов для сборки словаря частотности\n",
        "vocabularyItems = list(tokenizer.word_index.items()) # список с cодержимым словаря\n",
        "vocabularySize = len(vocabularyItems)+1 # размер словаря\n",
        "print( 'Фрагмент словаря : {}'.format(vocabularyItems[:50]))\n",
        "print( 'Размер словаря : {}'.format(vocabularySize))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фрагмент словаря : [('start', 1), ('end', 2), ('что', 3), ('не', 4), ('я', 5), ('а', 6), ('ты', 7), ('это', 8), ('да', 9), ('в', 10), ('нет', 11), ('как', 12), ('и', 13), ('вы', 14), ('ну', 15), ('с', 16), ('на', 17), ('же', 18), ('так', 19), ('он', 20), ('у', 21), ('кто', 22), ('где', 23), ('все', 24), ('мы', 25), ('то', 26), ('мне', 27), ('тебя', 28), ('меня', 29), ('здесь', 30), ('еще', 31), ('почему', 32), ('о', 33), ('тебе', 34), ('там', 35), ('есть', 36), ('его', 37), ('за', 38), ('куда', 39), ('вот', 40), ('ничего', 41), ('вас', 42), ('знаю', 43), ('чем', 44), ('но', 45), ('она', 46), ('они', 47), ('ли', 48), ('чего', 49), ('вам', 50)]\n",
            "Размер словаря : 15092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsUqzEBXg9Mu"
      },
      "source": [
        "# **Подготовка выборки**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=305s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4nNBJUQgebF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9853e9af-97c7-47b1-935e-5c6c2965df13"
      },
      "source": [
        "######################\n",
        "# Устанавливаем закодированные входные данные(вопросы) https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=310s\n",
        "######################\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions) # разбиваем текст вопросов на последовательности индексов\n",
        "maxLenQuestions = max([ len(x) for x in tokenizedQuestions]) # уточняем длину самого большого вопроса\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие вопросы\n",
        "paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "encoderForInput = paddedQuestions\n",
        "print('Пример оригинального вопроса на вход : {}'.format(questions[100])) \n",
        "print('Пример кодированного вопроса на вход : {}'.format(encoderForInput[100])) \n",
        "print('Размеры закодированного массива вопросов на вход : {}'.format(encoderForInput.shape)) \n",
        "print('Установленная длина вопросов на вход : {}'.format(maxLenQuestions)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального вопроса на вход : Какая же мораль?\n",
            "Пример кодированного вопроса на вход : [ 170   18 5703    0    0    0    0    0    0    0    0]\n",
            "Размеры закодированного массива вопросов на вход : (11888, 11)\n",
            "Установленная длина вопросов на вход : 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tjvhMuzqFJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a81e13-81e9-414b-b003-5ba18f98288b"
      },
      "source": [
        "######################\n",
        "# Устанавливаем раскодированные входные данные(ответы) https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=375s\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers]) # уточняем длину самого большого ответа\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "decoderForInput = paddedAnswers # переводим в numpy массив\n",
        "print('Пример оригинального ответа на вход: {}'.format(answers[100])) \n",
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[200])) \n",
        "print('Размеры раскодированного массива ответов на вход : {}'.format(decoderForInput.shape)) \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального ответа на вход: <START> Никакой. Так просто вспомнилось. <END>\n",
            "Пример раскодированного ответа на вход : [   1 1743    2    0    0    0    0    0    0    0    0    0    0]\n",
            "Размеры раскодированного массива ответов на вход : (11888, 13)\n",
            "Установленная длина ответов на вход : 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwsKk9dzNeqI"
      },
      "source": [
        "######################\n",
        "# Раскодированные выходные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "for i in range(len(tokenizedAnswers)) : # для разбитых на последовательности ответов\n",
        "  tokenizedAnswers[i] = tokenizedAnswers[i][1:] # избавляемся от тега <START>\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers , padding='post')\n",
        "\n",
        "oneHotAnswers = utils.to_categorical(paddedAnswers, vocabularySize) # переводим в one hot vector\n",
        "decoderForOutput = np.array(oneHotAnswers) # и сохраняем в виде массива numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRl1k7SVaA6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b66c62c-ec08-4053-dbe0-a79873abd4f8"
      },
      "source": [
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[100][:21]))  \n",
        "print('Пример раскодированного ответа на выход : {}'.format(decoderForOutput[100][4][:21])) \n",
        "print('Размеры раскодированного массива ответов на выход : {}'.format(decoderForOutput.shape))\n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример раскодированного ответа на вход : [    1   672    19    93 10547     2     0     0     0     0     0     0\n",
            "     0]\n",
            "Пример раскодированного ответа на выход : [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Размеры раскодированного массива ответов на выход : (11888, 13, 15092)\n",
            "Установленная длина вопросов на выход : 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0KR6Mh_hp1f"
      },
      "source": [
        "# **Параметры нейросети и модель обучения**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=915s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRKDr4rhXcZ"
      },
      "source": [
        "######################\n",
        "# Первый входной слой, кодер, выходной слой https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=915s\n",
        "######################\n",
        "encoderInputs = Input(shape=(None , )) # размеры на входе сетки (здесь будет encoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "encoderEmbedding = Embedding(vocabularySize, 200 , mask_zero=True) (encoderInputs)\n",
        "# Затем выход с Embedding пойдёт в LSTM слой, на выходе у которого будет два вектора состояния - state_h , state_c\n",
        "# Вектора состояния - state_h , state_c зададутся в LSTM слое декодера в блоке ниже\n",
        "encoderOutputs, state_h , state_c = LSTM(200, return_state=True)(encoderEmbedding)\n",
        "encoderStates = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_yv8Y6QWX2D"
      },
      "source": [
        "######################\n",
        "# Второй входной слой, декодер, выходной слой https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1048s\n",
        "######################\n",
        "decoderInputs = Input(shape=(None, )) # размеры на входе сетки (здесь будет decoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "# mask_zero=True - игнорировать нулевые padding при передаче в LSTM. Предотвратит вывод ответа типа: \"У меня все хорошо PAD PAD PAD PAD PAD PAD..\"\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True) (decoderInputs) \n",
        "# Затем выход с Embedding пойдёт в LSTM слой, которому передаются вектора состояния - state_h , state_c\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)\n",
        "decoderOutputs , _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates)\n",
        "# И от LSTM'а сигнал decoderOutputs пропускаем через полносвязный слой с софтмаксом на выходе\n",
        "decoderDense = Dense(vocabularySize, activation='softmax') \n",
        "output = decoderDense (decoderOutputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYnTen_UWc5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be32f1ac-db78-4c8e-a56f-9f78d2b51e31"
      },
      "source": [
        "######################\n",
        "# Собираем тренировочную модель нейросети https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1220s\n",
        "######################\n",
        "model = Model([encoderInputs, decoderInputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "print(model.summary()) # выведем на экран информацию о построенной модели нейросети\n",
        "plot_model(model, to_file='model.png') # и построим график для визуализации слоев и связей между ними"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 200)    3018400     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    3018400     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 15092)  3033492     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,711,892\n",
            "Trainable params: 9,711,892\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbelEm0zhadD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba3bf66-b716-4538-8852-aa1b8add9c64"
      },
      "source": [
        "# Запустим обучение на 20 эпох и сохраним модель https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1348s\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=20) \n",
        "model.save( '/content/drive/MyDrive/Базы/Модели и веса к ДЗ/model_20epochs(rms).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.9261\n",
            "Epoch 2/20\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.8860\n",
            "Epoch 3/20\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.8512\n",
            "Epoch 4/20\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.8167\n",
            "Epoch 5/20\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 1.7873\n",
            "Epoch 6/20\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.7574\n",
            "Epoch 7/20\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.7257\n",
            "Epoch 8/20\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.6941\n",
            "Epoch 9/20\n",
            "238/238 [==============================] - 27s 116ms/step - loss: 1.6599\n",
            "Epoch 10/20\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.6258\n",
            "Epoch 11/20\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.5922\n",
            "Epoch 12/20\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.5576\n",
            "Epoch 13/20\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.5255\n",
            "Epoch 14/20\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.4919\n",
            "Epoch 15/20\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.4581\n",
            "Epoch 16/20\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.4246\n",
            "Epoch 17/20\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.3928\n",
            "Epoch 18/20\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.3622\n",
            "Epoch 19/20\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.3325\n",
            "Epoch 20/20\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.3030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запустим обучение на +30 эпох и сохраним модель \n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=30) \n",
        "model.save( '/content/drive/MyDrive/Базы/Модели и веса к ДЗ/model_50epochs(rms).h5' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTaS4_Gaq5v0",
        "outputId": "7877fb93-0f26-411f-87ac-cbf00a70d8d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.9036\n",
            "Epoch 2/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8962\n",
            "Epoch 3/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8894\n",
            "Epoch 4/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8860\n",
            "Epoch 5/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8816\n",
            "Epoch 6/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8771\n",
            "Epoch 7/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8731\n",
            "Epoch 8/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8694\n",
            "Epoch 9/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8654\n",
            "Epoch 10/30\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.8620\n",
            "Epoch 11/30\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.8578\n",
            "Epoch 12/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8538\n",
            "Epoch 13/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8504\n",
            "Epoch 14/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8469\n",
            "Epoch 15/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8432\n",
            "Epoch 16/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8394\n",
            "Epoch 17/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8359\n",
            "Epoch 18/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8327\n",
            "Epoch 19/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8285\n",
            "Epoch 20/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8247\n",
            "Epoch 21/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8218\n",
            "Epoch 22/30\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.8182\n",
            "Epoch 23/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8151\n",
            "Epoch 24/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8119\n",
            "Epoch 25/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8088\n",
            "Epoch 26/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8062\n",
            "Epoch 27/30\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.8035\n",
            "Epoch 28/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8004\n",
            "Epoch 29/30\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7972\n",
            "Epoch 30/30\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запустим обучение на +50 эпох и сохраним модель \n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=50) \n",
        "model.save( '/content/drive/MyDrive/Базы/Модели и веса к ДЗ/model_100epochs(rms).h5' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePM1_dhYq5mJ",
        "outputId": "48425b74-60db-4ff7-f306-3400ad407bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7927\n",
            "Epoch 2/50\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7905\n",
            "Epoch 3/50\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7885\n",
            "Epoch 4/50\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7855\n",
            "Epoch 5/50\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7831\n",
            "Epoch 6/50\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7816\n",
            "Epoch 7/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7795\n",
            "Epoch 8/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7776\n",
            "Epoch 9/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7752\n",
            "Epoch 10/50\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7734\n",
            "Epoch 11/50\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7712\n",
            "Epoch 12/50\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7700\n",
            "Epoch 13/50\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7686\n",
            "Epoch 14/50\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7665\n",
            "Epoch 15/50\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.7655\n",
            "Epoch 16/50\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.7643\n",
            "Epoch 17/50\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.7623\n",
            "Epoch 18/50\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.7611\n",
            "Epoch 19/50\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.7595\n",
            "Epoch 20/50\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.7585\n",
            "Epoch 21/50\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 0.7572\n",
            "Epoch 22/50\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.7565\n",
            "Epoch 23/50\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7559\n",
            "Epoch 24/50\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7546\n",
            "Epoch 25/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7546\n",
            "Epoch 26/50\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7525\n",
            "Epoch 27/50\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7520\n",
            "Epoch 28/50\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.7518\n",
            "Epoch 29/50\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.7509\n",
            "Epoch 30/50\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7504\n",
            "Epoch 31/50\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7501\n",
            "Epoch 32/50\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7501\n",
            "Epoch 33/50\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7496\n",
            "Epoch 34/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7490\n",
            "Epoch 35/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7486\n",
            "Epoch 36/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7482\n",
            "Epoch 37/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7479\n",
            "Epoch 38/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7478\n",
            "Epoch 39/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7475\n",
            "Epoch 40/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7468\n",
            "Epoch 41/50\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7465\n",
            "Epoch 42/50\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7467\n",
            "Epoch 43/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7459\n",
            "Epoch 44/50\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7459\n",
            "Epoch 45/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7454\n",
            "Epoch 46/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7449\n",
            "Epoch 47/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7446\n",
            "Epoch 48/50\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7433\n",
            "Epoch 49/50\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7432\n",
            "Epoch 50/50\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_U_rY8UiRL2"
      },
      "source": [
        "# **Подготовка и запуск рабочей нейросети с генерацией ответов**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1428s\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_weights('/content/drive/MyDrive/Базы/Модели и веса к ДЗ/model_20epochs(rms).h5')"
      ],
      "metadata": {
        "id": "wBYYhxHOryno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv9utvcjh2co"
      },
      "source": [
        "# ######################\n",
        "# # Создаем рабочую модель для вывода ответов на запросы пользователя https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1455s\n",
        "# ######################\n",
        "# def makeInferenceModels():\n",
        "#   # Определим модель кодера, на входе далее будут закодированные вопросы(encoderForInputs), на выходе состояния state_h, state_c\n",
        "#   encoderModel = Model(encoderInputs, encoderStates) \n",
        "\n",
        "#   decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "#   decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "#   decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "#   # Берём ответы, прошедшие через эмбединг, вместе с состояниями и подаём LSTM cлою\n",
        "#   decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "#   decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "#   decoderOutputs = decoderDense(decoderOutputs) # и ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "#   # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "#   # на выходе предсказываемый ответ и новые состояния\n",
        "#   decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "#   return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSSOhZpgh9LI"
      },
      "source": [
        "######################\n",
        "# Создадим функцию, которая преобразует вопрос пользователя в последовательность индексов https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1593s\n",
        "######################\n",
        "def strToTokens(sentence: str): # функция принимает строку на вход (предложение с вопросом)\n",
        "  words = sentence.lower().split() # приводит предложение к нижнему регистру и разбирает на слова\n",
        "  tokensList = list() # здесь будет последовательность токенов/индексов\n",
        "  for word in words: # для каждого слова в предложении\n",
        "    tokensList.append(tokenizer.word_index[word]) # определяем токенизатором индекс и добавляем в список\n",
        "\n",
        "    # Функция вернёт вопрос в виде последовательности индексов, ограниченной длиной самого длинного вопроса из нашей базы вопросов\n",
        "  return pad_sequences([tokensList], maxlen=maxLenQuestions , padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0Dxd1eiEid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e60230-c6f3-4063-c1ff-6b0d8d7cfc96"
      },
      "source": [
        "# ######################\n",
        "# # Устанавливаем окончательные настройки и запускаем модель https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1645s\n",
        "# ######################\n",
        "\n",
        "# encModel , decModel = makeInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "# for _ in range(3): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "#   # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "#   statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "#   # Создаём пустой массив размером (1, 1)\n",
        "#   emptyTargetSeq = np.zeros((1, 1))    \n",
        "#   emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "#   stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "#   decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "#   while not stopCondition : # пока не сработало стоп-условие\n",
        "#     # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "#     # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "#     decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "#     #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "#     sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "#     sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "#     for word , index in tokenizer.word_index.items():\n",
        "#       if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "#         decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "#         sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "#     # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "#     if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "#       stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "\n",
        "#     emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "#     statesValues = [h, c] # и состояния, обновленные декодером\n",
        "#     # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "#   print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Задайте вопрос : привет\n",
            " что тебе надо человек \n",
            "Задайте вопрос : зачем ты здесь\n",
            " я хотела посмотреть на посмотреть на что я два \n",
            "Задайте вопрос : сколько тебе лет\n",
            " не знаю а сколько нужно \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfhu067toXGQ"
      },
      "source": [
        "# **Загрузка и запуск предобученной модели**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=2100s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Lg3eOVqKyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eaac349-74a4-4258-f28a-338374f5b1d1"
      },
      "source": [
        "# # Подгружаем модель из файла и выведем её параметры\n",
        "# model = load_model('/content/drive/MyDrive/Базы/Модели и веса к ДЗ/model_20epochs(rms).h5')\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 200)    3020800     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 200)    3020800     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 200), (None, 320800      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 200),  320800      embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 15104)  3035904     lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 9,719,104\n",
            "Trainable params: 9,719,104\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEfb58cXqsKi"
      },
      "source": [
        "######################\n",
        "# Устанавливаем связи между слоями рабочей модели и предобученной https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=2174s\n",
        "######################\n",
        "def loadInferenceModels():\n",
        "  encoderInputs = model.input[0]   # входом энкодера рабочей модели будет первый инпут предобученной модели(input_1)\n",
        "  encoderEmbedding = model.layers[2] # связываем эмбединг слои(model.layers[2] это embedding_1)\n",
        "  encoderOutputs, state_h_enc, state_c_enc = model.layers[4].output # вытягиваем аутпуты из первого LSTM слоя обуч.модели и даем энкодеру(lstm_1)\n",
        "  encoderStates = [state_h_enc, state_c_enc] # ложим забранные состояния в состояния энкодера\n",
        "  encoderModel = Model(encoderInputs, encoderStates) # формируем модель\n",
        "\n",
        "  decoderInputs = model.input[1]   # входом декодера рабочей модели будет второй инпут предобученной модели(input_2)\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "  decoderEmbedding = model.layers[3] # связываем эмбединг слои(model.layers[3] это embedding_2)\n",
        "  decoderLSTM = model.layers[5] # связываем LSTM слои(model.layers[5] это lstm_2)\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding.output, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "\n",
        "  decoderDense = model.layers[6] # связываем полносвязные слои(model.layers[6] это dense_1)\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # выход с LSTM мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "    # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "    # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "  return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **Иссл.№1.Загрузка и запуск предобученной модели на 20 эпохах** "
      ],
      "metadata": {
        "id": "VtCulYOvtw3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подгружаем модель из файла и выведем её параметры\n",
        "model = load_model('/content/drive/MyDrive/Базы/Модели и веса к ДЗ/model_20epochs(rms).h5')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toPyZIlqte0G",
        "outputId": "e27efa69-9de9-4e46-8d0b-c2d8cc4da094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 200)    3018400     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    3018400     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 15092)  3033492     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,711,892\n",
            "Trainable params: 9,711,892\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTpsqjakx2rs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d12484-c5fa-43ad-e295-f305bda41371"
      },
      "source": [
        "######################\n",
        "# Устанавливаем окончательные настройки и запускаем рабочую модель над предобученной https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=2272s\n",
        "######################\n",
        "\n",
        "encModel , decModel = loadInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "for _ in range(6): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "  # Создаём пустой массив размером (1, 1)\n",
        "  emptyTargetSeq = np.zeros((1, 1))    \n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "  stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "  decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "  while not stopCondition : # пока не сработало стоп-условие\n",
        "    # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "    # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "    decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "    #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "    sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "    sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "    for word , index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "        sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "    # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "    emptyTargetSeq = np.zeros((1, 1)) # создаем пустой массив\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c] # и состояния, обновленные декодером\n",
        "    # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "  print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос : Привет\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            " что нибудь здесь делать \n",
            "Задайте вопрос : Как тебя зовут\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            " я \n",
            "Задайте вопрос : Сколько тебе лет\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            " не знаю \n",
            "Задайте вопрос : Откуда ты\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            " из знаю \n",
            "Задайте вопрос : ты меня знаешь\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            " конечно \n",
            "Задайте вопрос : как твои дела\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            " все нормально \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **Иссл.№2.Загрузка и запуск предобученной модели на +30 эпохах** "
      ],
      "metadata": {
        "id": "GX_--4O-8mLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подгружаем модель из файла и выведем её параметры\n",
        "model = load_model('/content/drive/MyDrive/Базы/Модели и веса к ДЗ/model_50epochs(rms).h5')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1fc6b3-912c-4917-a071-7a0cd0c06db3",
        "id": "QNROvapI8wnC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 200)    3018400     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    3018400     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 15092)  3033492     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,711,892\n",
            "Trainable params: 9,711,892\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "facb7500-ceea-4eb6-8c27-ec6318d4f069",
        "id": "GL5MoQ_T8wnD"
      },
      "source": [
        "######################\n",
        "# Устанавливаем окончательные настройки и запускаем рабочую модель над предобученной https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=2272s\n",
        "######################\n",
        "\n",
        "encModel , decModel = loadInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "for _ in range(6): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "  # Создаём пустой массив размером (1, 1)\n",
        "  emptyTargetSeq = np.zeros((1, 1))    \n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "  stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "  decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "  while not stopCondition : # пока не сработало стоп-условие\n",
        "    # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "    # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "    decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "    #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "    sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "    sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "    for word , index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "        sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "    # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "    emptyTargetSeq = np.zeros((1, 1)) # создаем пустой массив\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c] # и состояния, обновленные декодером\n",
        "    # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "  print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос : Привет\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            " что ты здесь делаешь \n",
            "Задайте вопрос : Как тебя зовут\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            " меня зовут \n",
            "Задайте вопрос : Сколько тебе лет\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            " не знаю а сколько нужно \n",
            "Задайте вопрос : Откуда ты\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            " я и господин \n",
            "Задайте вопрос : Ты меня знаешь\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            " конечно \n",
            "Задайте вопрос : Как твои дела\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            " все их да \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **Иссл.№3.Загрузка и запуск предобученной модели на +50 эпохах** "
      ],
      "metadata": {
        "id": "a_H3hrXG9nbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подгружаем модель из файла и выведем её параметры\n",
        "model = load_model('/content/drive/MyDrive/Базы/Модели и веса к ДЗ/model_100epochs(rms).h5')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf66d244-f643-4a13-fb08-172b50a67226",
        "id": "GifjjHCe8yIj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 200)    3018400     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    3018400     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 15092)  3033492     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,711,892\n",
            "Trainable params: 9,711,892\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db41184-4a25-4fd0-e2ea-29c7aad1978e",
        "id": "f_exqzXs8yIl"
      },
      "source": [
        "######################\n",
        "# Устанавливаем окончательные настройки и запускаем рабочую модель над предобученной https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=2272s\n",
        "######################\n",
        "\n",
        "encModel , decModel = loadInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "for _ in range(6): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "  # Создаём пустой массив размером (1, 1)\n",
        "  emptyTargetSeq = np.zeros((1, 1))    \n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "  stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "  decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "  while not stopCondition : # пока не сработало стоп-условие\n",
        "    # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "    # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "    decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "    #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "    sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "    sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "    for word , index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "        sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "    # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "    emptyTargetSeq = np.zeros((1, 1)) # создаем пустой массив\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c] # и состояния, обновленные декодером\n",
        "    # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "  print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос : Привет\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            " что ты здесь делаешь \n",
            "Задайте вопрос : Как тебя зовут\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            " меня \n",
            "Задайте вопрос : Сколько тебе лет\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            " не знаю а сколько нужно \n",
            "Задайте вопрос : Откуда ты\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            " я из у тебя \n",
            "Задайте вопрос : Ты меня знаешь\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            " конечно \n",
            "Задайте вопрос : Как твои дела\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            " все идет \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выводы"
      ],
      "metadata": {
        "id": "4R9y9eHN-Xrs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Проанализируем диалог ниже:\n",
        "\n",
        "-Привет\n",
        "\n",
        "--что нибудь здесь делать (после 20 эпох обучения)\n",
        "\n",
        "--*что ты здесь делаешь    (после 50 эпох обучения)\n",
        "\n",
        "--*что ты здесь делаешь    (после 100 эпох обучения)\n",
        "\n",
        "\n",
        "\n",
        "-Как тебя зовут\n",
        "\n",
        "--я           (после 20 эпох обучения)\n",
        "\n",
        "--меня зовут  (после 50 эпох обучения)\n",
        "\n",
        "--меня        (после 100 эпох обучения)\n",
        "\n",
        "\n",
        "\n",
        "-Сколько тебе лет\n",
        "\n",
        "--*не знаю                 (после 20 эпох обучения)\n",
        "\n",
        "--*не знаю а сколько нужно  (после 50 эпох обучения)\n",
        "\n",
        "--*не знаю а сколько нужно  (после 100 эпох обучения)\n",
        "\n",
        "\n",
        "\n",
        "-Откуда ты\n",
        "\n",
        "--из знаю       (после 20 эпох обучения)\n",
        "\n",
        "--я и господин  (после 50 эпох обучения)\n",
        "\n",
        "--я из у тебя   (после 100 эпох обучения)\n",
        "\n",
        "\n",
        "\n",
        "-Tы меня знаешь\n",
        "\n",
        "--*конечно (после 20 эпох обучения)\n",
        "\n",
        "--*конечно  (после 50 эпох обучения)\n",
        "\n",
        "--*конечно  (после 100 эпох обучения)\n",
        "\n",
        "\n",
        "\n",
        "-Как твои дела\n",
        "\n",
        "--*все нормально  (после 20 эпох обучения)\n",
        "\n",
        "-- все их да      (после 50 эпох обучения)\n",
        "\n",
        "--*все идет        (после 100 эпох обучения)\n",
        "\n",
        "\n",
        "После 20 эпох обучения получено 3 логичных ответа из 6.\n",
        "После 50 эпох обучения получено 2 логичных ответа + 1 незаконченый ответ.\n",
        "После 100 эпох обучения получено 4 логичных ответа + 1 ответ незакончен.\n",
        "\n",
        "Как ни странно на 50 эпохах получен менее качествк=енный результат, следует подольше тренировать модель и возможно на разный оптимизаторах. "
      ],
      "metadata": {
        "id": "2D5D6Zfg-dES"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98O0XcM9yCbm"
      },
      "source": [
        "# **Глоссарий**\n",
        "-  Seq2Seq - sequence-to-sequence модель, состоит из двух рекуррентных нейронных сетей (RNN): \n",
        "\n",
        "encoder (кодер), которая обрабатывает входные данные,\n",
        "\n",
        "decoder (декодер), которая генерирует данные вывода.\n",
        "- Yaml - удобный текстовый формат, позволяющий хранить структурированные данные в иерархии. https://ru.bmstu.wiki/YAML\n",
        "yaml.safe_load - безопасный метод загрузки данных из файлов, предотвращающий возможность запуска произвольного кода для файлов из ненадежных источников\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqJ3CgG6jJMq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}