{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10100111/Display-of-HW1/blob/main/57_Ultra_Lite_%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D1%8F_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание Ultra Lite\n",
        "\n",
        "Макс 10 баллов\n",
        "\n",
        "Перепишите сеть для генерации текста с нуля в новом ноутбуке. Можно подсматривать в ноутбук занятия, но крайне желательно писать код своими руками, а не копировать."
      ],
      "metadata": {
        "id": "Z3X-kKNCXRy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка библиотек"
      ],
      "metadata": {
        "id": "PoSGDbx0XfPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files # модуль для загрузки файлов в колаб\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model # подгружаем абстрактный класс базовой модели, метод загрузки предобученной модели\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
        "from tensorflow.keras.optimizers import RMSprop, Adadelta\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # метод ограничения последовательностей заданной длиной\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # токенизатор для обработки текста\n",
        "from tensorflow.keras import utils # утилиты кераса для OHE \n",
        "from tensorflow.keras.utils import plot_model # удобный график для визуализации архитектуры модели\n",
        "\n",
        "import yaml # модуль для удобной работы с файлами"
      ],
      "metadata": {
        "id": "5U7IesZgXVy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRLgokkbaJof",
        "outputId": "37baa97d-717e-4f8e-d5a3-e40832f9ddc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Парсинг данных"
      ],
      "metadata": {
        "id": "eoq31L7ZbZa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Открываем файл  диалогами\n",
        "'''\n",
        "corpus = open('/content/drive/MyDrive/Базы/Диалоги(рассказы)_censored.yml','r') # открываем файл с диалогами в режиме чтения\n",
        "document = yaml.safe_load(corpus) # загружаем файл *глоссарий\n",
        "conversations = document['разговоры'] # загружаем диалоги из файла из блока \"разговоры\" и заносим в conversations\n",
        "print('Количество пар вопрос-ответ: {}'.format(len(conversations)))\n",
        "print('Пример диалога : {}'.format(conversations[777]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYVCIdqBbWiE",
        "outputId": "74a0bb65-2690-4733-f770-eca698cee738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество пар вопрос-ответ: 11893\n",
            "Пример диалога : ['Почему решили, что надо именно это?', 'Догадался.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Разбираем вопросы и ответы с проставлением тегов ответам\n",
        "'''\n",
        "# Собираем вопросы и ответы в списки \n",
        "questions = list() # здесь будет список вопросов\n",
        "answers = list() # здесь будет список ответов\n",
        "\n",
        "# В каждом диалоге берем фразу и добавляем в лист\n",
        "# Если в ответе не одна фраза, то сцепляем сколько есть\n",
        "for con in conversations:     # для каждой пары вопро-ответ\n",
        "  if len(con) > 2:            # если ответ содержит более 2 предложений (к-во реплик, к-во вариантов ответов)  \n",
        "    questions.append(con[0])  # то вопросительную реплику отправляем в список вопросов\n",
        "    replies = con[1:]         # а ответную составляем из соответствующих строк\n",
        "    ans = ''                  # здесь соберем ответ\n",
        "    for rep in replies:       # каждую реплику в ответной реплике \n",
        "      ans += ' ' + rep        \n",
        "    answers.append(ans)       # добавим в список ответов\n",
        "  elif len(con) > 1:          # если на 1 вопрос приходится 1 ответ\n",
        "    questions.append(con[0])  # то вопросительную реплику отправляем в список вопросов\n",
        "    answers.append(con[1])    # а ответную в список ответов\n",
        "\n",
        "# Очищаем строки с неопределенным типом ответов\n",
        "answerCleaned = list() \n",
        "for i in range(len(answers)):\n",
        "  if type(answers[i]) == str:\n",
        "    answerCleaned.append(answers[i]) # если тип - строка, то добавляем в ответы\n",
        "  else:\n",
        "    questions.pop(i)                 # если не строка, то ответ не добавился, и плюс убираем соответствующий вопрос\n",
        "\n",
        "# Сделаем теги-метки для начала и конца ответов\n",
        "answers = list()\n",
        "for i in range(len(answerCleaned)):\n",
        "  answers.append('<START>' + answerCleaned[i] + '<END>')\n",
        "\n",
        "# Выведем обновленные данные на экран\n",
        "print('Вопрос: {}'.format(questions[888]))\n",
        "print('Ответ: {}'.format(answers[888]))\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k3m2DiweZzu",
        "outputId": "db1349ad-fc72-4e2d-fdb3-00e586a3a3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вопрос: Толя, проверь, все?\n",
            "Ответ: <START>Все, товарищ командир!<END>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Подключаем керасовский токенайзер и собираем словарь индексов\n",
        "'''\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers)          # загружаем в токенизатор список вопросов-ответов для сборки словаря частотности\n",
        "vocabularyItems = list(tokenizer.word_index.items()) # список с содержимым словаря\n",
        "vocabularySize = len(vocabularyItems)+1              # размер словаря\n",
        "print('Фрагмент словаря: {}'.format(vocabularyItems[:50]))\n",
        "print('Размер словаря: {}'.format(vocabularySize))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nES2J0a7uF7A",
        "outputId": "9db09973-410e-4967-871b-55a9966688de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фрагмент словаря: [('start', 1), ('end', 2), ('что', 3), ('не', 4), ('я', 5), ('а', 6), ('ты', 7), ('это', 8), ('да', 9), ('в', 10), ('нет', 11), ('как', 12), ('и', 13), ('вы', 14), ('ну', 15), ('с', 16), ('на', 17), ('же', 18), ('так', 19), ('он', 20), ('у', 21), ('кто', 22), ('где', 23), ('все', 24), ('мы', 25), ('то', 26), ('мне', 27), ('тебя', 28), ('меня', 29), ('здесь', 30), ('еще', 31), ('почему', 32), ('о', 33), ('тебе', 34), ('там', 35), ('есть', 36), ('его', 37), ('за', 38), ('куда', 39), ('вот', 40), ('ничего', 41), ('вас', 42), ('знаю', 43), ('чем', 44), ('но', 45), ('она', 46), ('они', 47), ('ли', 48), ('чего', 49), ('вам', 50)]\n",
            "Размер словаря: 15092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка выборки"
      ],
      "metadata": {
        "id": "fqPOyBW4v-1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Устанавливаем закодированные входные данные (вопросы)\n",
        "'''\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions) # разбиваем текст вопросов на последовательности индексов\n",
        "maxLenQuestions = max([len(x) for x in tokenizedQuestions]) # уточняем длину самого большого вопроса\n",
        "# Делаем  последовательности одной длины, заполняя нулями более короткие вопросы\n",
        "paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "encoderForInput = paddedQuestions\n",
        "print('Пример оригинального вопроса на вход: {}'.format(questions[100]))\n",
        "print('Пример кодированного вопроса на вход: {}'.format(encoderForInput[100]))\n",
        "print('Размеры закодированного массива на вход: {}'.format(encoderForInput.shape))\n",
        "print('Установленная длина вопросов на вход: {}'.format(maxLenQuestions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8OyiW9Kv8Pg",
        "outputId": "2e302820-c2e5-41bf-dc3c-662eb0a30071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального вопроса на вход: Какая же мораль?\n",
            "Пример кодированного вопроса на вход: [ 170   18 5703    0    0    0    0    0    0    0    0]\n",
            "Размеры закодированного массива на вход: (11888, 11)\n",
            "Установленная длина вопросов на вход: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Устанавливаем раскодированные входные данные (ответы)\n",
        "'''\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers])  # уточняем длину самого большого ответа\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "decoderForInput = paddedAnswers # переводим в numpy массив\n",
        "print('Пример оригинального ответа на вход: {}'.format(answers[100]))\n",
        "print('Пример раскодированного ответа на вход: {}'.format(decoderForInput[100]))\n",
        "print('Размеры раскодированного массива ответов на вход: {}'.format(decoderForInput.shape))\n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OeyoRNhz1Kn",
        "outputId": "0bf9ed9a-5a65-4157-9e90-c6b6a73d81f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального ответа на вход: <START>Никакой. Так просто вспомнилось.<END>\n",
            "Пример раскодированного ответа на вход: [    1   672    19    93 10547     2     0     0     0     0     0     0\n",
            "     0]\n",
            "Размеры раскодированного массива ответов на вход: (11888, 13)\n",
            "Установленная длина ответов на вход : 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Раскодированные выходные данные(ответы)\n",
        "'''\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "for i in range(len(tokenizedAnswers)):                   # для разбитых последовательностей ответов\n",
        "  tokenizedAnswers[i] = tokenizedAnswers[i][1:]          # избавляемся от тега <START>\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "oneHotAnswers = utils.to_categorical(paddedAnswers, vocabularySize) # переводим в one hot vector\n",
        "decoderForOutput = np.array(oneHotAnswers) # и сохраняем в виде массива numpy"
      ],
      "metadata": {
        "id": "Xe5B6VNJ3Ldy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Пример раскодированного ответа на вход: {}'.format(decoderForInput[100][:21]))\n",
        "print('Пример раскодированного ответа на выход: {}'.format(decoderForOutput[100][4][:21]))\n",
        "print('Размеры раскодрованного массива ответов на выход: {}'.format(decoderForOutput.shape))\n",
        "print('Установленная длина вопросов на выход: {}'.format(maxLenAnswers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTFsr1uE_END",
        "outputId": "6a6be199-6ac6-4756-bd2b-2e81a9866b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример раскодированного ответа на вход: [    1   672    19    93 10547     2     0     0     0     0     0     0\n",
            "     0]\n",
            "Пример раскодированного ответа на выход: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Размеры раскодрованного массива ответов на выход: (11888, 13, 15092)\n",
            "Установленная длина вопросов на выход: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Параметры нейросети и модель обучения"
      ],
      "metadata": {
        "id": "asjOTBwVA0ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Первый входной слой, кодер, выходной слой\n",
        "'''\n",
        "encoderInputs = Input(shape=(None,)) # универсальный параметр под любой размер на вход(здесь будет encoderForOutput)\n",
        "# Эти данные проходят через слой Embedding(длина словаря, размерность)\n",
        "encoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True)(encoderInputs) # mask_zero=True - значит нулевые вектора не анализируются \n",
        "# Затем выход с Embedding пойдет в LSTM слой, на выходе у которого будет два вектора состояния - state_h, state_c\n",
        "# Вектора состояния state_h, state_c зададутся в LSTM слое декодера в блоке ниже\n",
        "encoderOutputs, state_h, state_c = LSTM(200, return_state=True)(encoderEmbedding)\n",
        "encoderStates = [state_h, state_c]"
      ],
      "metadata": {
        "id": "9zCirCVGAwFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.pylabtools import activate_matplotlib\n",
        "'''\n",
        "Второй выходной слой, декодер, выходной слой\n",
        "'''\n",
        "decoderInputs = Input(shape=(None,)) # размеры на входе сетки(здесь будет decoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность)\n",
        "# mask_zero=True - игнорировать нулевые padding при передаче в LSTM. Предотвратит вывод ответа типа: \"У меня все хорошо PAD PAD PAD PAD PAD PAD..\"\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True)(decoderInputs)\n",
        "# Затем выход с Embedding пойдет в LSTM слой, которому передаются вектора состояния state_h, state_c\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)\n",
        "decoderOutputs, _, _ = decoderLSTM(decoderEmbedding, initial_state=encoderStates)\n",
        "# И от LSTM'a сигнал decoderOutputs пропускаем через полносвязный слой с софтмаксом на выходе\n",
        "decoderDense = Dense(vocabularySize, activation='softmax')\n",
        "output = decoderDense(decoderOutputs)"
      ],
      "metadata": {
        "id": "gy8uOWwkDO_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Собираем тренировочную модель нейросети\n",
        "'''\n",
        "model = Model([encoderInputs, decoderInputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "print(model.summary())\n",
        "plot_model(model, to_file='model.png') # построим график модели для визуализации слоев и связей между ними"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "H2XPXAQnHD72",
        "outputId": "cc9eaf87-4601-4633-a0b3-eb3272e77344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_12 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, None, 200)    3018400     ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, None, 200)    3018400     ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  [(None, 200),        320800      ['embedding_4[0][0]']            \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  [(None, None, 200),  320800      ['embedding_5[0][0]',            \n",
            "                                 (None, 200),                     'lstm_4[0][1]',                 \n",
            "                                 (None, 200)]                     'lstm_4[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, None, 15092)  3033492     ['lstm_5[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,711,892\n",
            "Trainable params: 9,711,892\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput, decoderForInput], decoderForOutput, batch_size=50, epochs=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVPVPulCIAWH",
        "outputId": "f71bbd63-627a-4e5e-8ddc-dc947393c42f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "238/238 [==============================] - 41s 132ms/step - loss: 2.2135\n",
            "Epoch 2/2\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 1.9757\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c15bdcb90>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput, decoderForInput], decoderForOutput, batch_size=50, epochs=50 )\n",
        "model.save( '/content/drive/MyDrive/Базы/Модели и веса к ДЗ/model_50epochs(rms).h5' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Yx6FCRFKAeG",
        "outputId": "99e4cf3d-0d70-4fc0-d8c3-3d6a2f59b87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 1.9264\n",
            "Epoch 2/50\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 1.8864\n",
            "Epoch 3/50\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 1.8495\n",
            "Epoch 4/50\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 1.8158\n",
            "Epoch 5/50\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 1.7845\n",
            "Epoch 6/50\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 1.7527\n",
            "Epoch 7/50\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 1.7216\n",
            "Epoch 8/50\n",
            "238/238 [==============================] - 33s 138ms/step - loss: 1.6866\n",
            "Epoch 9/50\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 1.6511\n",
            "Epoch 10/50\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 1.6138\n",
            "Epoch 11/50\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 1.5799\n",
            "Epoch 12/50\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 1.5460\n",
            "Epoch 13/50\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 1.5128\n",
            "Epoch 14/50\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 1.4788\n",
            "Epoch 15/50\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 1.4454\n",
            "Epoch 16/50\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 1.4120\n",
            "Epoch 17/50\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 1.3812\n",
            "Epoch 18/50\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 1.3501\n",
            "Epoch 19/50\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 1.3191\n",
            "Epoch 20/50\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 1.2894\n",
            "Epoch 21/50\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 1.2618\n",
            "Epoch 22/50\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 1.2343\n",
            "Epoch 23/50\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 1.2077\n",
            "Epoch 24/50\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 1.1834\n",
            "Epoch 25/50\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 1.1591\n",
            "Epoch 26/50\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 1.1348\n",
            "Epoch 27/50\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 1.1135\n",
            "Epoch 28/50\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 1.0921\n",
            "Epoch 29/50\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 1.0732\n",
            "Epoch 30/50\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 1.0552\n",
            "Epoch 31/50\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 1.0368\n",
            "Epoch 32/50\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 1.0205\n",
            "Epoch 33/50\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 1.0059\n",
            "Epoch 34/50\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.9919\n",
            "Epoch 35/50\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.9777\n",
            "Epoch 36/50\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.9651\n",
            "Epoch 37/50\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.9533\n",
            "Epoch 38/50\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.9430\n",
            "Epoch 39/50\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.9333\n",
            "Epoch 40/50\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.9259\n",
            "Epoch 41/50\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.9192\n",
            "Epoch 42/50\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.9139\n",
            "Epoch 43/50\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.9087\n",
            "Epoch 44/50\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.9037\n",
            "Epoch 45/50\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.8990\n",
            "Epoch 46/50\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.8933\n",
            "Epoch 47/50\n",
            "238/238 [==============================] - 33s 140ms/step - loss: 0.8881\n",
            "Epoch 48/50\n",
            "238/238 [==============================] - 33s 138ms/step - loss: 0.8818\n",
            "Epoch 49/50\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.8754\n",
            "Epoch 50/50\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.8694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights( '/content/drive/MyDrive/Базы/Модели и веса к ДЗ/model_50epochs(rms).h5' )"
      ],
      "metadata": {
        "id": "ke96KW3mXi0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка и запуск рабочей нейросети с генерацией ответов"
      ],
      "metadata": {
        "id": "ZEFuh_6IrctN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Создаем рабочую модель для вывода ответов на запросы пользователя\n",
        "'''\n",
        "def makeInferenceModels():\n",
        "  # Определим модель кодера, на входе будут закодированные вопросы(EncoderForInputs), на выходе состояния state_h, state_c\n",
        "  encoderModel = Model(encoderInputs, encoderStates)\n",
        "\n",
        "  decoderStateInput_h = Input(shape=(200,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200,)) # обозначим размерность для входного слоя с состоянием state_C\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # оба inputs запишем в decoderStatesInputs\n",
        "\n",
        "  # Берем ответы, прошедшие через Embedding, вместе с состоянием и подаем их LSTM слою\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c]            # LSTM даст нам новые состояния\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # и ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "  # Определим модель декодера, на входе будут раскодированные ответы (decoderForInputs) и состояния\n",
        "  # на выходе предсказываемый ответ и состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "  return encoderModel, decoderModel\n"
      ],
      "metadata": {
        "id": "NqfJhFjPrrtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Cоздадим функцию, которая преобразует вопрос пользователя в последовательность индексов\n",
        "'''\n",
        "def strToTokens(sentence:str): # функция принимает на вход строку (предложение с вопросом)\n",
        "  words = sentence.lower().split() # приводит предложение к нижнему регистру и разбирает на слова\n",
        "  tokenList = list()               # здесь будет последовательность токенов, индексов\n",
        "  for word in words:               # для каждого слова в предложении\n",
        "    tokenList.append(tokenizer.word_index[word]) # определяем токенизатором индекс и добавляем в список\n",
        "\n",
        "    # Функция вернет вопрос в виде последовательности индексов, ограниченной длиной самого длинного вопроса из БД\n",
        "  return pad_sequences([tokenList], maxlen=maxLenQuestions, padding='post') "
      ],
      "metadata": {
        "id": "0vq1fjO8xNe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Устанавливаем окончательные настройки и запускаем модель \n",
        "'''\n",
        "encModel, decModel = makeInferenceModels() # запускаем функцию для построения модели\n",
        "\n",
        "for _ in range(3): #задаем кол-во вопросов и на каждой итерации в этом диапазоне:\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  statesValues = encModel.predict(strToTokens(input('Задайте вопрос: ')))\n",
        "  # Создаем пустой массив размером 1,1\n",
        "  emptyTargetSeq = np.zeros((1, 1))\n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start']  # положим в пустую последовательность начальное слово start в виде индекса\n",
        "\n",
        "  stopCondition = False    # зададим условие, при срабатывании которого прекратится генерация очередного слова\n",
        "  decodedTranslation = ''  # здесь будет собираться генерируемый ответ\n",
        "  while not stopCondition: # пока не сработало стоп условие\n",
        "    # В модель декодера подадим пустую последовательность со словом start и состояния предсказанные кодером по заданному вопросу\n",
        "    # декодер заменит слово start предсказанным словом и обновит состояния\n",
        "    decOutputs, h, c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "\n",
        "    # argmax побежит по вектору decOutputs'a[0, 0, 15092], найдет максимальное значение и вернет нам номер индекса под которым оно лежит в массиве\n",
        "    sampledWordIndex = np.argmax(decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15092 элемента. Получили индекс предсказанного слова.\n",
        "    sampledWord = None                                # создаем переменную, в которую положим слово.\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index:                   # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word)       # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ\n",
        "        sampleWord = word                             # выбранное слово фиксируем в переменную sampleWord\n",
        "\n",
        "    # если выбранным словом оказывается end либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampleWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True                     # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex    # заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c]                      # и состояния, обновленные декодером\n",
        "    # и продолжаем цикл с обновленными параметрами\n",
        "\n",
        "  print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fbDKJc9zyqt",
        "outputId": "ecd643c8-2c7b-410a-dd3e-0347316fa0e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос: привет\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            " что ты здесь делаешь \n",
            "Задайте вопрос: как дела\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            " вот так почему же не надо \n",
            "Задайте вопрос: ты откуда\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            " из за мной \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка и запуск предобученной модели"
      ],
      "metadata": {
        "id": "YTzzvLhUOejf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подгружаем модель из памяти и выведем ее параметры\n",
        "model = load_model( '/content/drive/MyDrive/Базы/Модели и веса к ДЗ/model_50epochs(rms).h5' )\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQRCqlY5OoJP",
        "outputId": "f09d42d7-a8b6-49b2-cba9-6b6edf5920f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_12 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, None, 200)    3018400     ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, None, 200)    3018400     ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  [(None, 200),        320800      ['embedding_4[0][0]']            \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  [(None, None, 200),  320800      ['embedding_5[0][0]',            \n",
            "                                 (None, 200),                     'lstm_4[0][1]',                 \n",
            "                                 (None, 200)]                     'lstm_4[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, None, 15092)  3033492     ['lstm_5[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,711,892\n",
            "Trainable params: 9,711,892\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Устанавливаем связи между слоями рабочей модели и предобученной\n",
        "'''\n",
        "def loadInferenceModels():\n",
        "  encoderInputs = model.input[0] # входом энкодера рабочей модели будет первый инпут предобученной модели (input_1)\n",
        "  encoderEmbedding = model.layers[2] # связываем эмбеддинг слои(model.layers[2] - это embedding_1)\n",
        "  encoderOutputs, state_h_enc, state_c_enc = model.layers[4].output # вытягиваем аутпуты из первого LSTM слоя обучающей модели и даем экодеру (lstm_1)\n",
        "  encoderStates = [state_h_enc, state_c_enc] # кладем забранные состояния в состояние энкодера\n",
        "  encoderModel = Model(encoderInputs, encoderStates) # формируем модель \n",
        "\n",
        "  decoderInputs = model.input[1] # входом декодера рабочей модели будет второй инпут предобученной модели (input_2)\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе  и запишем в decoderStatesInputs\n",
        "\n",
        "  decoderEmbedding = model.layers[3] # связываем эмбеддинг слои (model.layers[3] - это embedding_2)\n",
        "  decoderLSTM = model.layers[5]      # связываем LSTM слои(model.layers[5] - это lstm_2)\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding.output, initial_state = decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "\n",
        "  decoderDense = model.layers[6] # связываем полносвязные слои (model.layers[6] - это dense_1)\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # выход с LSTM мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "  # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "  # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "  return encoderModel, decoderModel"
      ],
      "metadata": {
        "id": "1K2p23aLQYdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Устанавливаем окончательные настройки и запускаем рабочую модель над предобученной\n",
        "'''\n",
        "encModel, decModel = loadInferenceModels() # запускаем функцию построения модели кодера и декодера\n",
        "\n",
        "for _ in range(6): #задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  statesValues = encModel.predict(strToTokens(input('Задайте вопрос: ')))\n",
        "  # Создаем пустой массив (1, )\n",
        "  emptyTargetSeq = np.zeros((1, 1))\n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # подаем в пустую последовательность тег <start>, в виде индекса\n",
        "  stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "  decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "  while not stopCondition : # пока не сработало стоп-условие\n",
        "    # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "    # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "    decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "    #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "    sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15092 элемента. Получили индекс предсказанного слова.\n",
        "    sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "    for word , index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index:              # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "        sampledWord = word                       # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "    # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "    emptyTargetSeq = np.zeros((1, 1))       # создаем пустой массив\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c]                   # и состояния, обновленные декодером\n",
        "    # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "  print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5mamrwvYbkm",
        "outputId": "e09ef671-2d10-4505-b2f4-e31751155c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос: привет\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            " что ты здесь делаешь \n",
            "Задайте вопрос: кто ты\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            " я вы к могу \n",
            "Задайте вопрос: откуда ты\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            " с оно не знаю а как они \n",
            "Задайте вопрос: знаешь меня\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            " а ты почему бы это можно \n",
            "Задайте вопрос: как дела\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            " вот так почему же не надо \n",
            "Задайте вопрос: сколько тебе лет\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            " не знаю а сколько нужно \n"
          ]
        }
      ]
    }
  ]
}