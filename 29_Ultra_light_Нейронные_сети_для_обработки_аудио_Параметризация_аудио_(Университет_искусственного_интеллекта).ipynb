{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "29. Ultra light. Нейронные сети для обработки аудио. Параметризация аудио (Университет искусственного интеллекта).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMwsXjYYEZywv0hBKpKpn71",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10100111/Display-of-HW1/blob/main/29_Ultra_light_%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8_%D0%B4%D0%BB%D1%8F_%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B8_%D0%B0%D1%83%D0%B4%D0%B8%D0%BE_%D0%9F%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_%D0%B0%D1%83%D0%B4%D0%B8%D0%BE_(%D0%A3%D0%BD%D0%B8%D0%B2%D0%B5%D1%80%D1%81%D0%B8%D1%82%D0%B5%D1%82_%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D0%B0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание Ultra Lite\n",
        "\n",
        "Макс 10 баллов\n",
        "\n",
        "Используя шаблон ноутбука, напишите загрузку данных и распознавание стилей музыки с помощью Dense сети. \n",
        "\n",
        "Можно подсматривать в исходный ноутбук с занятия, но желательно писать код своими руками"
      ],
      "metadata": {
        "id": "xY2oVGfNgka4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa # Для параметризации аудио\n",
        "import librosa.display # Для отображения аудиосигнала\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files # Для загрузки файлов \n",
        "import IPython.display as ipd # Для проигрывания аудио\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop \n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import concatenate, Input,  Dense, Dropout, BatchNormalization, Flatten, Conv1D, Conv2D, LSTM\n",
        "from tensorflow.keras.utils import to_categorical #Для представления в формате one_hot_encoding\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "IQDFkwl5gnjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNYUSABQhYc3",
        "outputId": "d1033c39-9fba-4e84-cf0e-c4e05ecd1a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q '/content/drive/MyDrive/Colab Notebooks/Базы/genres.zip'\n",
        "\n"
      ],
      "metadata": {
        "id": "uqeUwkzolApg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc668f59-9832-464d-814d-c73a289bc5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace genres/blues/blues.00000.au? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace genres/blues/blues.00001.au? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "genres = os.listdir('genres') # получаем список папок в распакованной папке\n",
        "\n",
        "#Проверяем выгруженные папки\n",
        "!ls genres \n",
        "#И одну из папок\n",
        "!ls genres/blues"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WNskTvSlAff",
        "outputId": "69833dc4-ddb7-461f-ccbb-6fe4b9c3862e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blues  classical  country  disco  hiphop  jazz\tmetal  pop  reggae  rock\n",
            "blues.00000.au\tblues.00020.au\tblues.00040.au\tblues.00060.au\tblues.00080.au\n",
            "blues.00001.au\tblues.00021.au\tblues.00041.au\tblues.00061.au\tblues.00081.au\n",
            "blues.00002.au\tblues.00022.au\tblues.00042.au\tblues.00062.au\tblues.00082.au\n",
            "blues.00003.au\tblues.00023.au\tblues.00043.au\tblues.00063.au\tblues.00083.au\n",
            "blues.00004.au\tblues.00024.au\tblues.00044.au\tblues.00064.au\tblues.00084.au\n",
            "blues.00005.au\tblues.00025.au\tblues.00045.au\tblues.00065.au\tblues.00085.au\n",
            "blues.00006.au\tblues.00026.au\tblues.00046.au\tblues.00066.au\tblues.00086.au\n",
            "blues.00007.au\tblues.00027.au\tblues.00047.au\tblues.00067.au\tblues.00087.au\n",
            "blues.00008.au\tblues.00028.au\tblues.00048.au\tblues.00068.au\tblues.00088.au\n",
            "blues.00009.au\tblues.00029.au\tblues.00049.au\tblues.00069.au\tblues.00089.au\n",
            "blues.00010.au\tblues.00030.au\tblues.00050.au\tblues.00070.au\tblues.00090.au\n",
            "blues.00011.au\tblues.00031.au\tblues.00051.au\tblues.00071.au\tblues.00091.au\n",
            "blues.00012.au\tblues.00032.au\tblues.00052.au\tblues.00072.au\tblues.00092.au\n",
            "blues.00013.au\tblues.00033.au\tblues.00053.au\tblues.00073.au\tblues.00093.au\n",
            "blues.00014.au\tblues.00034.au\tblues.00054.au\tblues.00074.au\tblues.00094.au\n",
            "blues.00015.au\tblues.00035.au\tblues.00055.au\tblues.00075.au\tblues.00095.au\n",
            "blues.00016.au\tblues.00036.au\tblues.00056.au\tblues.00076.au\tblues.00096.au\n",
            "blues.00017.au\tblues.00037.au\tblues.00057.au\tblues.00077.au\tblues.00097.au\n",
            "blues.00018.au\tblues.00038.au\tblues.00058.au\tblues.00078.au\tblues.00098.au\n",
            "blues.00019.au\tblues.00039.au\tblues.00059.au\tblues.00079.au\tblues.00099.au\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from librosa.feature.spectral import mfcc\n",
        "#Функция параметризации аудио\n",
        "def get_features(y,sr):\n",
        "  #Получаем различные параметры аудио\n",
        "  chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr) #Частота цветности (по усолчанию 12 баков цветности)\n",
        "  mfcc = librosa.feature.mfcc(y=y, sr=sr) # Мел кепстральные коэффициенты (по усолчанию 20)\n",
        "\n",
        "  rmse = np.mean(librosa.feature.mfcc(y=y)) #Среднеквадратичная амплитуда\n",
        "  spec_cent = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)) # Среднее спектрального центроида\n",
        "  spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)) # Среднее ширины полосы частот\n",
        "  rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)) #Среднее спектрального спада частоты\n",
        "  zcr = np.mean(librosa.feature.zero_crossing_rate(y)) # Cредняя частота пересечения нуля звукового временного ряда\n",
        "\n",
        "  # Добавляем все параметры в дин список\n",
        "  out = [] # создаем пустой список\n",
        "  out.append(rmse) # добавляе среднеквадратиную амплитуду\n",
        "  out.append(spec_cent) # добавляем спектральный центроид\n",
        "  out.append(spec_bw) # добавляем ширину полосы частот\n",
        "  out.append(rolloff) # добавляем спектральный спад частоты\n",
        "  out.append(zcr) # добавляем пересечение нуля \n",
        "\n",
        "  # Дбавляем среднее всех мел кепстральных коэффициентов (20 значений)\n",
        "  for e in mfcc:\n",
        "    out.append(np.mean(e))\n",
        "\n",
        "  # Добавляем среднее всех частот цветности (12 значений)\n",
        "  for e in chroma_stft:\n",
        "    out.append(np.mean(e))\n",
        "  \n",
        "  #Возвращаем получившийся список размерностью (37,)\n",
        "  return out"
      ],
      "metadata": {
        "id": "UcckDtITlASV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time # подкючаем модуль time для подсчета времени на обработку одного жанра\n",
        "\n",
        "# Формируем обучающую Выборку\n",
        "# Создаем пустые листы\n",
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "#Запоминаем время старта формирования выборки\n",
        "curr_time = time.time()\n",
        "\n",
        "#Проходим по всем жанрам\n",
        "for i in range(len(genres)):\n",
        "  g = genres[i] # берем текущий жанр\n",
        "  # Проходим по файлам папки текущего жанра\n",
        "  for filename in os.listdir(f'./genres/{g}'):\n",
        "    # получаем имя песни\n",
        "    songname = f'./genres/{g}/{filename}'\n",
        "    # загружаем в аудиосигнал\n",
        "    # используем первые 30 секунд аудио\n",
        "    y, sr = librosa.load(songname, mono = True, duration = 30) # y - массив данных временного ряда аудио, sr - частота дискретизации\n",
        "    # Превращаем сигнал в параметризованные данные\n",
        "    out = get_features(y,sr)\n",
        "\n",
        "    # добавляем строку в X_train\n",
        "    X_train.append(out)\n",
        "    # добавляем в Y_train номер жанра в OHE\n",
        "    Y_train.append(to_categorical(i, len(genres)))\n",
        "\n",
        "  # Выводим инфо о готовности обработки базы\n",
        "  print('Жанр ', g, ' готов  -->', round(time.time() - curr_time), 'c', sep='')\n",
        "  curr_time = time.time()\n",
        "\n",
        "# Превращаем обучающую выборку в numpy массивы\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ePeXDgt6t0F6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5045b2bf-712b-4a0d-fda4-177363daeb32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Жанр disco готов  -->53c\n",
            "Жанр classical готов  -->53c\n",
            "Жанр metal готов  -->53c\n",
            "Жанр hiphop готов  -->57c\n",
            "Жанр rock готов  -->60c\n",
            "Жанр blues готов  -->62c\n",
            "Жанр jazz готов  -->53c\n",
            "Жанр country готов  -->57c\n",
            "Жанр reggae готов  -->60c\n",
            "Жанр pop готов  -->63c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем back up обучающей выборки \n",
        "X_train_backup = X_train.copy()\n",
        "Y_train_backup = Y_train.copy()"
      ],
      "metadata": {
        "id": "gIJ9meQvh0p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выводим номера классов , чтобы проверить, что все правильно заполнилось\n",
        "# И номера классов идут последовательно крупными блоками\n",
        "y_train_class = np.argmax(Y_train, axis=1)\n",
        "print(y_train_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t29Q1b24Q0mR",
        "outputId": "7a80886c-db3b-4728-9c80-6abdd0f5cfdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
            " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
            " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
            " 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
            " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
            " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
            " 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выводим размеры обучающей выборки\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(y_train_class.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWIYGSTBRUQH",
        "outputId": "48a86406-85b5-49a0-9fa6-d912b6011233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 37)\n",
            "(1000, 10)\n",
            "(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем scaler экземпляр класса StandardScaler() для нормировки данных\n",
        "scaler = StandardScaler()\n",
        "# Нормируем X_train\n",
        "X_train = scaler.fit_transform(X_train)\n"
      ],
      "metadata": {
        "id": "aNCZVCnCVgdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверяем , что X_train нормировался\n",
        "print(X_train[0])\n"
      ],
      "metadata": {
        "id": "LXBFWvf4WH-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделяем выборку на обучающую и проверочную (90% и 10%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train_class, test_size=0.1)"
      ],
      "metadata": {
        "id": "jd4tLydwWYF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выводим размеры обучающей и проверочной выборки, для проверки\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnOby1ZLXBQX",
        "outputId": "d873ffe3-2dcf-4436-f502-07f8576558e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(900, 37)\n",
            "(900,)\n",
            "(100, 37)\n",
            "(100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "# Создаем нейронку\n",
        "# Указываем , какие индексы данных во входящих векторах брать для обучения\n",
        "# Это нужно для эксперимента , будем обучат на части колонок\n",
        "# У нас в векторе 5 значений - признаки, 20 значений - кепстральные коэф-ты, 12 значений - частоты цветности\n",
        "indexes = range(0,37)\n",
        "\n",
        "# Cоздаем полносвязную сеть\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='elu', input_shape = (len(indexes),)))\n",
        "model.add(Dense(128, activation='elu'))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(Dense(32, activation='elu'))\n",
        "# В конце количество нейронов равно количеству классов и softmax\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Компилируем сеть \n",
        "model.compile(optimizer=RMSprop(learning_rate=1e-4),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Обучаем\n",
        "history = model.fit(X_train[:,indexes],\n",
        "                    y_train,\n",
        "                    epochs=200,\n",
        "                    batch_size=20,\n",
        "                    validation_data = (X_test[:, indexes], y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rCj4kGdYSri",
        "outputId": "2349717e-d78d-4868-cdaf-fddf38ccf466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "45/45 [==============================] - 3s 19ms/step - loss: 2.0527 - accuracy: 0.2511 - val_loss: 1.8381 - val_accuracy: 0.3600\n",
            "Epoch 2/200\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 1.7267 - accuracy: 0.3933 - val_loss: 1.6449 - val_accuracy: 0.4400\n",
            "Epoch 3/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 1.5698 - accuracy: 0.4556 - val_loss: 1.5509 - val_accuracy: 0.4700\n",
            "Epoch 4/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.4679 - accuracy: 0.4900 - val_loss: 1.4790 - val_accuracy: 0.5000\n",
            "Epoch 5/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.3887 - accuracy: 0.5356 - val_loss: 1.4210 - val_accuracy: 0.5400\n",
            "Epoch 6/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.3260 - accuracy: 0.5700 - val_loss: 1.3731 - val_accuracy: 0.5300\n",
            "Epoch 7/200\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 1.2743 - accuracy: 0.5933 - val_loss: 1.3218 - val_accuracy: 0.5500\n",
            "Epoch 8/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.2288 - accuracy: 0.6067 - val_loss: 1.2838 - val_accuracy: 0.5700\n",
            "Epoch 9/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.1898 - accuracy: 0.6167 - val_loss: 1.2565 - val_accuracy: 0.5700\n",
            "Epoch 10/200\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 1.1527 - accuracy: 0.6256 - val_loss: 1.2311 - val_accuracy: 0.5500\n",
            "Epoch 11/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 1.1226 - accuracy: 0.6411 - val_loss: 1.2062 - val_accuracy: 0.5700\n",
            "Epoch 12/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 1.0946 - accuracy: 0.6500 - val_loss: 1.1833 - val_accuracy: 0.5600\n",
            "Epoch 13/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.0681 - accuracy: 0.6578 - val_loss: 1.1646 - val_accuracy: 0.5500\n",
            "Epoch 14/200\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 1.0441 - accuracy: 0.6644 - val_loss: 1.1501 - val_accuracy: 0.5600\n",
            "Epoch 15/200\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 1.0228 - accuracy: 0.6678 - val_loss: 1.1353 - val_accuracy: 0.5600\n",
            "Epoch 16/200\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 1.0035 - accuracy: 0.6800 - val_loss: 1.1117 - val_accuracy: 0.5600\n",
            "Epoch 17/200\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9838 - accuracy: 0.6722 - val_loss: 1.1152 - val_accuracy: 0.5600\n",
            "Epoch 18/200\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9668 - accuracy: 0.6889 - val_loss: 1.0991 - val_accuracy: 0.5600\n",
            "Epoch 19/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.9482 - accuracy: 0.6867 - val_loss: 1.0913 - val_accuracy: 0.5400\n",
            "Epoch 20/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.9344 - accuracy: 0.6911 - val_loss: 1.0822 - val_accuracy: 0.5600\n",
            "Epoch 21/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.9202 - accuracy: 0.6989 - val_loss: 1.0605 - val_accuracy: 0.5500\n",
            "Epoch 22/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.9056 - accuracy: 0.7000 - val_loss: 1.0582 - val_accuracy: 0.5500\n",
            "Epoch 23/200\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.8901 - accuracy: 0.7056 - val_loss: 1.0461 - val_accuracy: 0.5500\n",
            "Epoch 24/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.8801 - accuracy: 0.7078 - val_loss: 1.0485 - val_accuracy: 0.5400\n",
            "Epoch 25/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.8682 - accuracy: 0.7211 - val_loss: 1.0375 - val_accuracy: 0.5500\n",
            "Epoch 26/200\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.8550 - accuracy: 0.7233 - val_loss: 1.0324 - val_accuracy: 0.5700\n",
            "Epoch 27/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.8444 - accuracy: 0.7267 - val_loss: 1.0186 - val_accuracy: 0.5600\n",
            "Epoch 28/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.8318 - accuracy: 0.7333 - val_loss: 1.0160 - val_accuracy: 0.5700\n",
            "Epoch 29/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.8208 - accuracy: 0.7322 - val_loss: 1.0060 - val_accuracy: 0.5900\n",
            "Epoch 30/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.8100 - accuracy: 0.7411 - val_loss: 1.0152 - val_accuracy: 0.5900\n",
            "Epoch 31/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.8036 - accuracy: 0.7344 - val_loss: 1.0128 - val_accuracy: 0.5900\n",
            "Epoch 32/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.7917 - accuracy: 0.7456 - val_loss: 0.9887 - val_accuracy: 0.5900\n",
            "Epoch 33/200\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.7809 - accuracy: 0.7489 - val_loss: 0.9959 - val_accuracy: 0.5900\n",
            "Epoch 34/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.7742 - accuracy: 0.7500 - val_loss: 0.9933 - val_accuracy: 0.5900\n",
            "Epoch 35/200\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.7634 - accuracy: 0.7578 - val_loss: 0.9902 - val_accuracy: 0.6000\n",
            "Epoch 36/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.7549 - accuracy: 0.7600 - val_loss: 0.9849 - val_accuracy: 0.6000\n",
            "Epoch 37/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.7454 - accuracy: 0.7611 - val_loss: 0.9807 - val_accuracy: 0.6100\n",
            "Epoch 38/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.7391 - accuracy: 0.7633 - val_loss: 0.9785 - val_accuracy: 0.6300\n",
            "Epoch 39/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.7311 - accuracy: 0.7600 - val_loss: 0.9751 - val_accuracy: 0.6300\n",
            "Epoch 40/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.7209 - accuracy: 0.7644 - val_loss: 0.9893 - val_accuracy: 0.6200\n",
            "Epoch 41/200\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.7142 - accuracy: 0.7678 - val_loss: 0.9701 - val_accuracy: 0.6200\n",
            "Epoch 42/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.7050 - accuracy: 0.7767 - val_loss: 0.9815 - val_accuracy: 0.6300\n",
            "Epoch 43/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.6988 - accuracy: 0.7700 - val_loss: 0.9641 - val_accuracy: 0.6300\n",
            "Epoch 44/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.7711 - val_loss: 0.9766 - val_accuracy: 0.6300\n",
            "Epoch 45/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.7733 - val_loss: 0.9738 - val_accuracy: 0.6300\n",
            "Epoch 46/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.6762 - accuracy: 0.7800 - val_loss: 0.9713 - val_accuracy: 0.6400\n",
            "Epoch 47/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.6686 - accuracy: 0.7789 - val_loss: 0.9623 - val_accuracy: 0.6300\n",
            "Epoch 48/200\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.6630 - accuracy: 0.7811 - val_loss: 0.9524 - val_accuracy: 0.6500\n",
            "Epoch 49/200\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.6531 - accuracy: 0.7822 - val_loss: 0.9457 - val_accuracy: 0.6500\n",
            "Epoch 50/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.6480 - accuracy: 0.7867 - val_loss: 0.9658 - val_accuracy: 0.6400\n",
            "Epoch 51/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.7878 - val_loss: 0.9534 - val_accuracy: 0.6800\n",
            "Epoch 52/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.6325 - accuracy: 0.7978 - val_loss: 0.9615 - val_accuracy: 0.6300\n",
            "Epoch 53/200\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.6263 - accuracy: 0.7978 - val_loss: 0.9599 - val_accuracy: 0.6400\n",
            "Epoch 54/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.6192 - accuracy: 0.8078 - val_loss: 0.9673 - val_accuracy: 0.6600\n",
            "Epoch 55/200\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.6118 - accuracy: 0.8033 - val_loss: 0.9621 - val_accuracy: 0.6200\n",
            "Epoch 56/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.6086 - accuracy: 0.8156 - val_loss: 0.9481 - val_accuracy: 0.6500\n",
            "Epoch 57/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.6012 - accuracy: 0.8056 - val_loss: 0.9485 - val_accuracy: 0.6600\n",
            "Epoch 58/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.5941 - accuracy: 0.8078 - val_loss: 0.9434 - val_accuracy: 0.6500\n",
            "Epoch 59/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.5883 - accuracy: 0.8133 - val_loss: 0.9316 - val_accuracy: 0.6800\n",
            "Epoch 60/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.8100 - val_loss: 0.9469 - val_accuracy: 0.6600\n",
            "Epoch 61/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.5718 - accuracy: 0.8233 - val_loss: 0.9593 - val_accuracy: 0.6500\n",
            "Epoch 62/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.5695 - accuracy: 0.8156 - val_loss: 0.9496 - val_accuracy: 0.6800\n",
            "Epoch 63/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.5610 - accuracy: 0.8267 - val_loss: 0.9454 - val_accuracy: 0.6500\n",
            "Epoch 64/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.5577 - accuracy: 0.8222 - val_loss: 0.9417 - val_accuracy: 0.6500\n",
            "Epoch 65/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.5475 - accuracy: 0.8244 - val_loss: 0.9713 - val_accuracy: 0.6500\n",
            "Epoch 66/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.5439 - accuracy: 0.8300 - val_loss: 0.9543 - val_accuracy: 0.6700\n",
            "Epoch 67/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.5393 - accuracy: 0.8300 - val_loss: 0.9646 - val_accuracy: 0.6600\n",
            "Epoch 68/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.8278 - val_loss: 0.9409 - val_accuracy: 0.6800\n",
            "Epoch 69/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.5270 - accuracy: 0.8311 - val_loss: 0.9442 - val_accuracy: 0.6600\n",
            "Epoch 70/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.5192 - accuracy: 0.8333 - val_loss: 0.9626 - val_accuracy: 0.6400\n",
            "Epoch 71/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.8311 - val_loss: 0.9671 - val_accuracy: 0.6500\n",
            "Epoch 72/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.8389 - val_loss: 0.9484 - val_accuracy: 0.6500\n",
            "Epoch 73/200\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.5031 - accuracy: 0.8444 - val_loss: 0.9586 - val_accuracy: 0.6600\n",
            "Epoch 74/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.8422 - val_loss: 0.9593 - val_accuracy: 0.6300\n",
            "Epoch 75/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.8389 - val_loss: 0.9601 - val_accuracy: 0.6500\n",
            "Epoch 76/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.8444 - val_loss: 0.9655 - val_accuracy: 0.6500\n",
            "Epoch 77/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.8433 - val_loss: 0.9640 - val_accuracy: 0.6700\n",
            "Epoch 78/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.8467 - val_loss: 0.9424 - val_accuracy: 0.6700\n",
            "Epoch 79/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.8456 - val_loss: 0.9721 - val_accuracy: 0.6600\n",
            "Epoch 80/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.8489 - val_loss: 0.9696 - val_accuracy: 0.6500\n",
            "Epoch 81/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.8478 - val_loss: 0.9638 - val_accuracy: 0.6500\n",
            "Epoch 82/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8544 - val_loss: 0.9543 - val_accuracy: 0.6700\n",
            "Epoch 83/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.8533 - val_loss: 0.9518 - val_accuracy: 0.6600\n",
            "Epoch 84/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.8678 - val_loss: 0.9549 - val_accuracy: 0.6700\n",
            "Epoch 85/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8600 - val_loss: 0.9756 - val_accuracy: 0.6400\n",
            "Epoch 86/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.8611 - val_loss: 0.9693 - val_accuracy: 0.6300\n",
            "Epoch 87/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8667 - val_loss: 0.9722 - val_accuracy: 0.6400\n",
            "Epoch 88/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8667 - val_loss: 0.9792 - val_accuracy: 0.6700\n",
            "Epoch 89/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8711 - val_loss: 0.9875 - val_accuracy: 0.6400\n",
            "Epoch 90/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8644 - val_loss: 0.9532 - val_accuracy: 0.6500\n",
            "Epoch 91/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8700 - val_loss: 0.9781 - val_accuracy: 0.6700\n",
            "Epoch 92/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8700 - val_loss: 0.9794 - val_accuracy: 0.6500\n",
            "Epoch 93/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8756 - val_loss: 0.9863 - val_accuracy: 0.6600\n",
            "Epoch 94/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8778 - val_loss: 0.9895 - val_accuracy: 0.6700\n",
            "Epoch 95/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8822 - val_loss: 0.9812 - val_accuracy: 0.6500\n",
            "Epoch 96/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.3793 - accuracy: 0.8878 - val_loss: 1.0036 - val_accuracy: 0.6500\n",
            "Epoch 97/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8922 - val_loss: 0.9893 - val_accuracy: 0.6800\n",
            "Epoch 98/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8878 - val_loss: 0.9873 - val_accuracy: 0.6500\n",
            "Epoch 99/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8900 - val_loss: 0.9880 - val_accuracy: 0.6600\n",
            "Epoch 100/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8956 - val_loss: 1.0076 - val_accuracy: 0.6800\n",
            "Epoch 101/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8933 - val_loss: 1.0030 - val_accuracy: 0.6700\n",
            "Epoch 102/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8922 - val_loss: 1.0097 - val_accuracy: 0.6700\n",
            "Epoch 103/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8956 - val_loss: 1.0156 - val_accuracy: 0.6500\n",
            "Epoch 104/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.9011 - val_loss: 1.0249 - val_accuracy: 0.6500\n",
            "Epoch 105/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8956 - val_loss: 1.0047 - val_accuracy: 0.6700\n",
            "Epoch 106/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.9011 - val_loss: 1.0037 - val_accuracy: 0.6600\n",
            "Epoch 107/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3270 - accuracy: 0.9044 - val_loss: 1.0223 - val_accuracy: 0.6900\n",
            "Epoch 108/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9100 - val_loss: 0.9898 - val_accuracy: 0.6500\n",
            "Epoch 109/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3181 - accuracy: 0.9111 - val_loss: 1.0172 - val_accuracy: 0.6700\n",
            "Epoch 110/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3153 - accuracy: 0.9067 - val_loss: 1.0147 - val_accuracy: 0.6600\n",
            "Epoch 111/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.9100 - val_loss: 1.0253 - val_accuracy: 0.6500\n",
            "Epoch 112/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.9133 - val_loss: 1.0245 - val_accuracy: 0.6700\n",
            "Epoch 113/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2980 - accuracy: 0.9144 - val_loss: 1.0414 - val_accuracy: 0.6600\n",
            "Epoch 114/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.2983 - accuracy: 0.9156 - val_loss: 1.0321 - val_accuracy: 0.6500\n",
            "Epoch 115/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2916 - accuracy: 0.9244 - val_loss: 1.0456 - val_accuracy: 0.6900\n",
            "Epoch 116/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.2867 - accuracy: 0.9222 - val_loss: 1.0204 - val_accuracy: 0.6700\n",
            "Epoch 117/200\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.2820 - accuracy: 0.9278 - val_loss: 1.0331 - val_accuracy: 0.6800\n",
            "Epoch 118/200\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 0.2795 - accuracy: 0.9244 - val_loss: 1.0309 - val_accuracy: 0.6700\n",
            "Epoch 119/200\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.2730 - accuracy: 0.9311 - val_loss: 1.0548 - val_accuracy: 0.6700\n",
            "Epoch 120/200\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.2699 - accuracy: 0.9322 - val_loss: 1.0566 - val_accuracy: 0.6500\n",
            "Epoch 121/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2678 - accuracy: 0.9300 - val_loss: 1.0491 - val_accuracy: 0.6800\n",
            "Epoch 122/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2608 - accuracy: 0.9322 - val_loss: 1.0289 - val_accuracy: 0.6800\n",
            "Epoch 123/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2552 - accuracy: 0.9322 - val_loss: 1.0493 - val_accuracy: 0.6800\n",
            "Epoch 124/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.2542 - accuracy: 0.9422 - val_loss: 1.0624 - val_accuracy: 0.6900\n",
            "Epoch 125/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2529 - accuracy: 0.9378 - val_loss: 1.0793 - val_accuracy: 0.6600\n",
            "Epoch 126/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2447 - accuracy: 0.9389 - val_loss: 1.0858 - val_accuracy: 0.6400\n",
            "Epoch 127/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.9356 - val_loss: 1.0689 - val_accuracy: 0.6400\n",
            "Epoch 128/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.2385 - accuracy: 0.9478 - val_loss: 1.0860 - val_accuracy: 0.6900\n",
            "Epoch 129/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2346 - accuracy: 0.9444 - val_loss: 1.0823 - val_accuracy: 0.6500\n",
            "Epoch 130/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2301 - accuracy: 0.9500 - val_loss: 1.0891 - val_accuracy: 0.6900\n",
            "Epoch 131/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9511 - val_loss: 1.0987 - val_accuracy: 0.6700\n",
            "Epoch 132/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2230 - accuracy: 0.9500 - val_loss: 1.0896 - val_accuracy: 0.6600\n",
            "Epoch 133/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2183 - accuracy: 0.9556 - val_loss: 1.1132 - val_accuracy: 0.6900\n",
            "Epoch 134/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2145 - accuracy: 0.9556 - val_loss: 1.1149 - val_accuracy: 0.6600\n",
            "Epoch 135/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.2116 - accuracy: 0.9578 - val_loss: 1.0997 - val_accuracy: 0.6600\n",
            "Epoch 136/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2071 - accuracy: 0.9489 - val_loss: 1.1039 - val_accuracy: 0.7000\n",
            "Epoch 137/200\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.2035 - accuracy: 0.9600 - val_loss: 1.1109 - val_accuracy: 0.7000\n",
            "Epoch 138/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1976 - accuracy: 0.9600 - val_loss: 1.1247 - val_accuracy: 0.6600\n",
            "Epoch 139/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9567 - val_loss: 1.1125 - val_accuracy: 0.6900\n",
            "Epoch 140/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1925 - accuracy: 0.9578 - val_loss: 1.1165 - val_accuracy: 0.6800\n",
            "Epoch 141/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1886 - accuracy: 0.9656 - val_loss: 1.1450 - val_accuracy: 0.6900\n",
            "Epoch 142/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1862 - accuracy: 0.9656 - val_loss: 1.1492 - val_accuracy: 0.6800\n",
            "Epoch 143/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1815 - accuracy: 0.9689 - val_loss: 1.1276 - val_accuracy: 0.6600\n",
            "Epoch 144/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9678 - val_loss: 1.1604 - val_accuracy: 0.6700\n",
            "Epoch 145/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1749 - accuracy: 0.9733 - val_loss: 1.1308 - val_accuracy: 0.6800\n",
            "Epoch 146/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.1725 - accuracy: 0.9744 - val_loss: 1.1554 - val_accuracy: 0.6800\n",
            "Epoch 147/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1693 - accuracy: 0.9700 - val_loss: 1.1427 - val_accuracy: 0.6800\n",
            "Epoch 148/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1657 - accuracy: 0.9722 - val_loss: 1.1666 - val_accuracy: 0.7100\n",
            "Epoch 149/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1629 - accuracy: 0.9700 - val_loss: 1.1552 - val_accuracy: 0.7100\n",
            "Epoch 150/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 0.9767 - val_loss: 1.1849 - val_accuracy: 0.7000\n",
            "Epoch 151/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1574 - accuracy: 0.9722 - val_loss: 1.1697 - val_accuracy: 0.7000\n",
            "Epoch 152/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1553 - accuracy: 0.9722 - val_loss: 1.1492 - val_accuracy: 0.6900\n",
            "Epoch 153/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1484 - accuracy: 0.9789 - val_loss: 1.1745 - val_accuracy: 0.6700\n",
            "Epoch 154/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9744 - val_loss: 1.1943 - val_accuracy: 0.6900\n",
            "Epoch 155/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1433 - accuracy: 0.9778 - val_loss: 1.2143 - val_accuracy: 0.6900\n",
            "Epoch 156/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9744 - val_loss: 1.2179 - val_accuracy: 0.6800\n",
            "Epoch 157/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1396 - accuracy: 0.9800 - val_loss: 1.2162 - val_accuracy: 0.6900\n",
            "Epoch 158/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.9778 - val_loss: 1.2451 - val_accuracy: 0.6800\n",
            "Epoch 159/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1327 - accuracy: 0.9822 - val_loss: 1.2071 - val_accuracy: 0.6800\n",
            "Epoch 160/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.9778 - val_loss: 1.2137 - val_accuracy: 0.6900\n",
            "Epoch 161/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9811 - val_loss: 1.2307 - val_accuracy: 0.6900\n",
            "Epoch 162/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1240 - accuracy: 0.9833 - val_loss: 1.2279 - val_accuracy: 0.6900\n",
            "Epoch 163/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1221 - accuracy: 0.9833 - val_loss: 1.2258 - val_accuracy: 0.6800\n",
            "Epoch 164/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9878 - val_loss: 1.2339 - val_accuracy: 0.6900\n",
            "Epoch 165/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9833 - val_loss: 1.2417 - val_accuracy: 0.6900\n",
            "Epoch 166/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9822 - val_loss: 1.2327 - val_accuracy: 0.6900\n",
            "Epoch 167/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1111 - accuracy: 0.9900 - val_loss: 1.2401 - val_accuracy: 0.6700\n",
            "Epoch 168/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9811 - val_loss: 1.2571 - val_accuracy: 0.6800\n",
            "Epoch 169/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 0.9900 - val_loss: 1.2812 - val_accuracy: 0.6800\n",
            "Epoch 170/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9900 - val_loss: 1.2991 - val_accuracy: 0.7000\n",
            "Epoch 171/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1022 - accuracy: 0.9900 - val_loss: 1.3002 - val_accuracy: 0.6900\n",
            "Epoch 172/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9900 - val_loss: 1.2646 - val_accuracy: 0.6800\n",
            "Epoch 173/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9867 - val_loss: 1.3044 - val_accuracy: 0.6700\n",
            "Epoch 174/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9933 - val_loss: 1.3094 - val_accuracy: 0.6900\n",
            "Epoch 175/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0924 - accuracy: 0.9933 - val_loss: 1.2853 - val_accuracy: 0.6900\n",
            "Epoch 176/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9922 - val_loss: 1.3321 - val_accuracy: 0.6700\n",
            "Epoch 177/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0885 - accuracy: 0.9933 - val_loss: 1.3356 - val_accuracy: 0.6700\n",
            "Epoch 178/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0837 - accuracy: 0.9933 - val_loss: 1.3173 - val_accuracy: 0.6800\n",
            "Epoch 179/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9922 - val_loss: 1.2856 - val_accuracy: 0.6800\n",
            "Epoch 180/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9922 - val_loss: 1.3208 - val_accuracy: 0.7000\n",
            "Epoch 181/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9933 - val_loss: 1.3396 - val_accuracy: 0.6800\n",
            "Epoch 182/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9944 - val_loss: 1.3445 - val_accuracy: 0.6700\n",
            "Epoch 183/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9956 - val_loss: 1.3699 - val_accuracy: 0.6800\n",
            "Epoch 184/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9944 - val_loss: 1.3456 - val_accuracy: 0.6800\n",
            "Epoch 185/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9956 - val_loss: 1.3624 - val_accuracy: 0.6800\n",
            "Epoch 186/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.9956 - val_loss: 1.4020 - val_accuracy: 0.6800\n",
            "Epoch 187/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9956 - val_loss: 1.3468 - val_accuracy: 0.6800\n",
            "Epoch 188/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9967 - val_loss: 1.3975 - val_accuracy: 0.6800\n",
            "Epoch 189/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9944 - val_loss: 1.4372 - val_accuracy: 0.6700\n",
            "Epoch 190/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9933 - val_loss: 1.4016 - val_accuracy: 0.6800\n",
            "Epoch 191/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9956 - val_loss: 1.3965 - val_accuracy: 0.6800\n",
            "Epoch 192/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9933 - val_loss: 1.4076 - val_accuracy: 0.6800\n",
            "Epoch 193/200\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9967 - val_loss: 1.4123 - val_accuracy: 0.6800\n",
            "Epoch 194/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9956 - val_loss: 1.4519 - val_accuracy: 0.6700\n",
            "Epoch 195/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.9967 - val_loss: 1.4456 - val_accuracy: 0.6700\n",
            "Epoch 196/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9944 - val_loss: 1.4519 - val_accuracy: 0.6700\n",
            "Epoch 197/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9978 - val_loss: 1.4960 - val_accuracy: 0.6700\n",
            "Epoch 198/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9967 - val_loss: 1.4956 - val_accuracy: 0.6700\n",
            "Epoch 199/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9967 - val_loss: 1.4641 - val_accuracy: 0.6800\n",
            "Epoch 200/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9967 - val_loss: 1.4784 - val_accuracy: 0.6700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выводим график точности распознования на обучающей и проверочной выборке\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "Vgce8P0AnBzl",
        "outputId": "a710558c-4686-469e-da27-b6d23b527462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}