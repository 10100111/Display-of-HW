{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10100111/Display-of-HW1/blob/main/97_Pro_%D0%97%D0%B0%D0%BC%D0%B5%D0%BD%D0%B0_%D1%8F%D0%B7%D1%8B%D0%BA%D0%B0_%D0%BF%D0%B5%D1%80%D0%B5%D0%B2%D0%BE%D0%B4%D0%B0_%D0%9C%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%B7%D0%BC_Attention%2C_%D0%A1%D0%B5%D1%82%D0%B8_%D1%81_%D0%B2%D0%BD%D0%B8%D0%BC%D0%B0%D0%BD%D0%B8%D0%B5%D0%BC_(%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0)_%7C_%D0%A3%D0%98%D0%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание Pro\n",
        "\n",
        "Макс 10 баллов\n",
        "\n",
        "Используя ноутбук с занятия, переделайте его в переводчик с немецкого на английский. \n",
        "\n",
        "Напишите Ваши выводы.\n"
      ],
      "metadata": {
        "id": "SlAWudtcx2gC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CisjvJh3bdIw"
      },
      "source": [
        "**Содержание темы**\n",
        "\n",
        "1. [Теория](https://colab.research.google.com/drive/1f2RV3yzZIqRoGpP9y-b45NgnivaIT-4q?usp=sharing)\n",
        "\n",
        "2. Практика\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Базы с различными языками можно скачать здесь http://www.manythings.org/anki/."
      ],
      "metadata": {
        "id": "BKHKzZ3i4I4I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XhodKqwLjQ6"
      },
      "source": [
        "Разберем обучение более подробно на примере готовой сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7LxGv5bdgmN"
      },
      "source": [
        "# модуль для загрузки файлов в colab\n",
        "from google.colab import files \n",
        "\n",
        "# Подключим tensorflow\n",
        "import tensorflow as tf \n",
        "\n",
        "# Подключим токенайзер\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Используем метод для формирования последовательностей одинаковой длины\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
        "\n",
        "# Загружаем абстрактный класс базовой модели сети от кераса\n",
        "from tensorflow.keras.models import Model \n",
        "\n",
        "# Подключим необходимые слои\n",
        "from tensorflow.keras.layers import Dense, Embedding, GRU\n",
        "\n",
        "# Подключим оптимайзер\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "# Подключим функцию потерь\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# Подключим numpy - библиотеку для работы с массивами данных\n",
        "import numpy as np \n",
        "\n",
        "# Подключим библиотеку для визуализации данных\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# Подключим модуль для определения форматирования и местоположения делений на осях графиков\n",
        "import matplotlib.ticker as ticker \n",
        "\n",
        "# Подключим модуль для разбивки данных на обучающую и тестовую выборки\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Подключим модуль для работы с регулярными выражениями\n",
        "import re \n",
        "\n",
        "# Подключим модуль для работы с временем\n",
        "import time\n",
        "\n",
        "# Подключим модуль для работы с операционной системой\n",
        "import os \n",
        "\n",
        "import gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHjOn2T74nUk",
        "outputId": "7e6b4b35-06cf-44f6-fa67-4ecbaa5d5226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IjqYknxCqmX8",
        "outputId": "b3c047c4-d39b-46df-dc3b-aa503035f6a2"
      },
      "source": [
        "# Скачаем датасетa из пар фраз на русском и английском языках \n",
        "\n",
        "gdown.download('http://www.manythings.org/anki/deu-eng.zip', None, quiet=True) # https://storage.yandexcloud.net/aiueducation/Content/advanced/l3/rus-eng.zip изменен"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'deu-eng.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGGoRhuVyd_W"
      },
      "source": [
        "Распакуем скачанные тексты и убедимся в появлении файла со словарем:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VlOfx4jtB9e",
        "outputId": "55392d15-2882-4b2c-9fbb-78089726de6b"
      },
      "source": [
        "!unzip -o deu-eng.zip "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  deu-eng.zip\n",
            "  inflating: deu.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHBPiDxa9_Mg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af15be99-1c14-4ab6-d5dd-0ca46da99d60"
      },
      "source": [
        "# Проверим распакованные файлы\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_about.txt  deu-eng.zip  deu.txt  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O7TDn54-ATt"
      },
      "source": [
        "# Определим переменную с именем файла с датасетом\n",
        "path_to_file=\"deu.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGAVJe9iynJi"
      },
      "source": [
        "Определим функцию для подготовки предложений из словаря для обучения нейронной  сети. Добавим пробелы между словами и знаками препинаний, служебные символы заменим на пробелы, уберем пробелы в начале и конце фразы., добавим тег `< start >` в начало фразы, `< end >` в конец:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWA1mr0Rqq_9"
      },
      "source": [
        "def preprocess_sentence(phrases): # Функция принимает содержимое словаря\n",
        "\n",
        "  # Разделяем пробелами слова и знаки препинания(\"А как насчет тебя? \" -> \"А как насчет тебя ? \") \n",
        "  phrases = re.sub(r\"([?.!,;:])\", r\" \\1 \", phrases) # r\" \\1 \" берёт значения 1й группы в скобках; обрамляем указанные символы пробелами\n",
        "\n",
        "  # Заменяем всё на пробелы, за исключением (a-zA-Zа-яёА-ЯЁ?.!,;:)\n",
        "  phrases = re.sub(r\"[^a-zA-Zа-яёА-ЯЁ?.!,;:]+\", \" \", phrases) \n",
        "  \n",
        "  # Получаем строку без случайных лишних пробелов в конце фраз(rstrip удаляет с конца строки)\n",
        "  phrases = phrases.rstrip().strip()      \n",
        "\n",
        "  # Для нашей модели обозначим тегами начало и конец предложения  \n",
        "  phrases = '<start> ' + phrases + ' <end>' \n",
        "\n",
        "  # Функция возвращает предобработанные фразы\n",
        "  return phrases "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKj6v9AIvdSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7df684-7774-433d-85f8-248fcfe3a0eb"
      },
      "source": [
        "# Покажем пример обработки фразц\n",
        "\n",
        "print(\"Фразы после обработки функцией с т.з. пунктуации примут вид:\") \n",
        "print(preprocess_sentence(\"What about you?\"))                         # Выведем пример до обработки \n",
        "print(preprocess_sentence(\"А как насчет тебя?\"))                      # И после"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фразы после обработки функцией с т.з. пунктуации примут вид:\n",
            "<start> What about you ? <end>\n",
            "<start> А как насчет тебя ? <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWrBY276Oyb-"
      },
      "source": [
        "Перегоним фразы в датасет. Он представляет список пар из русского и английского предложения. Будем использовать только первые num_examples пар"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5zJhQmqvyNC"
      },
      "source": [
        "Создадим функцию по формированию датасета. На вход принимает путь к файлу с датасетом и требуемый размер датасета. Читает файл построчно и на выходе формирует список пар фраз."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRaVcSowqr9e"
      },
      "source": [
        "# Функция создания датасета\n",
        "\n",
        "def create_dataset(path,          # Путь к файлу\n",
        "                   num_examples): # Необходимый размер датасета \n",
        "\n",
        "  # Открываем файл и разбиваем фразы на отдельные строчки\n",
        "  lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  # В каждой строке словаря разделяем английскую фразу от русской, и пропускаем через функцию предобработки данных\n",
        "  word_pairs = [[preprocess_sentence(phrases) for phrases in l.split('\\t')[0:2]]  for l in lines[:num_examples]]\n",
        "\n",
        "  # Вернем пары фраз в виде [по-английски, по-русски]\n",
        "  return zip(*word_pairs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5iuvrauv4KN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c135ada-86a8-400b-c8fb-c91e677e94e7"
      },
      "source": [
        "print(\"Взглянем на пример пары фраз на выходе функции:\")\n",
        "\n",
        "english, russian = create_dataset(path_to_file,40000) # Вызовем функцию для демонстрации\n",
        "print(english[-1])                                    # Выведем последний элемент из списка английских фраз\n",
        "print(russian[-1])                                    # Выведем последний элемент из списка русских фраз"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Взглянем на пример пары фраз на выходе функции:\n",
            "<start> I ll do it if I can . <end>\n",
            "<start> Ich werde es tun , wenn ich kann . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plOf8RMSPSz-"
      },
      "source": [
        "Создадим функцию для получения максимальной длины фразы из списка. На вход принимает список фраз. Перебирает список, выбираем максимальное значение длины"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5xw1cPZqu5d"
      },
      "source": [
        "# Создадим мини-функцию, возвращающую максимальную длину тензора\n",
        "def max_length(tensor): # Функция принимает на вход тензор(фразы в виде последовательности индексов)\n",
        "\n",
        "  # Вернем значение максимальной длины его элемента \n",
        "  return max(len(t) for t in tensor) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg-GwLJoPtyJ"
      },
      "source": [
        "Функция преобразовывает тексты в последовательности индексов. \n",
        "Используем стандартный токенайзер из модуля Keras. На вход принимает текст, обучает на нем токенайзер. Переводит текст в токены. Отдает полученые токены и токенайзер"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTLSJIakPmEz"
      },
      "source": [
        "def tokenize(language): # Функция принимает текст одного из языков\n",
        "\n",
        "  language_tokenizer = Tokenizer(filters='')               # Вызываем класс Токенизатор, просим его не удалять символы, которые он удаляет по умолчанию\n",
        "  language_tokenizer.fit_on_texts(language)                # \"скармливаем\" ему тексты для обработки и сборки словаря частотности\n",
        "  tensor = language_tokenizer.texts_to_sequences(language) # Разбиваем текст фраз на последовательности индексов\n",
        "  tensor = pad_sequences(tensor, padding='post')           # Делаем последовательности фиксированной длины, заполняя нулями более короткие фразы\n",
        "\n",
        "  # Возвращаем последовательность индексов(назовем ее тензор) и токенизатор\n",
        "  return tensor, language_tokenizer "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNNNJMfvQBP6"
      },
      "source": [
        "Функция формирующая готовый датасет. Получает на вход путь к файлу с текстами и необходимый размер готового датасета\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaKt_YpuPmbQ"
      },
      "source": [
        "def load_dataset(path,               # Путь к файлу с текстами\n",
        "                 num_examples=None): # Необходимый объем датасета\n",
        "\n",
        "    # Из исходного текста делаем датасет пар фраз, причём входным языком для сети сделаем русский\n",
        "    targ_language, inp_language = create_dataset(path, num_examples)\n",
        "\n",
        "    # Разбиваем текст на последовательность индексов(назовем ее тензор)\n",
        "    input_tensor, inp_language_tokenizer = tokenize(inp_language)    # Формируем тензоры и токенизатор для русского языка\n",
        "    target_tensor, targ_language_tokenizer = tokenize(targ_language) # Формируем тензоры и токенизатор для английского языка\n",
        "\n",
        "    # Функция вернёт: тензор для русского языка, для английского языка; токенизаторы для русского и английского языков\n",
        "    return input_tensor, target_tensor, inp_language_tokenizer, targ_language_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqAYnjBzQMeO"
      },
      "source": [
        "Формируем датасет заданного объема - 40000 (в зависимости от приоритета скорости либо качества обучения), используем ранее написанные функции:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPfw_d52qxtK"
      },
      "source": [
        "num_examples = 40000 # Выберем 40 тысяч строк(всего в базе около 360тысяч строк, в каждой пара фраз)\n",
        "\n",
        "input_tensor, target_tensor, inp_language_tokenizer, targ_language_tokenizer = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Вычислим максимальные длины тензоров для английского и русского языков, используя ранее заданную функцию\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
        "\n",
        "# Создаем тренировочную и тестовую выборки по формуле 80/20\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UCqJHiw5ikC"
      },
      "source": [
        "Создадим вспомогательную функцию для вывода слова фразы и его индекса. На вход подаются токенайзер и фраза:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Xhk8pb5byY"
      },
      "source": [
        "# Визуализируем собранные данные\n",
        "\n",
        "def convert(language_tokenizer,  # Токенайзер\n",
        "            tensor):             # Список индексов слов\n",
        "            \n",
        "  #  Цикл по токенам во фразе\n",
        "  for t in tensor:  \n",
        "    if t!=0:                                                        # Если токен не 0. Т.е. не мусор в конце фразы\n",
        "      print (\"%d ----> %s\" % (t, language_tokenizer.index_word[t])) # Выводи токен и соответствующее слово\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6tkpocE6X_3"
      },
      "source": [
        "Посмотрим на примеры\n",
        "В первом блоке выведем русскую фразу и ее токен\n",
        "Во втором агнлийскую.\n",
        "\n",
        "Далее выводим статистику по датасету"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2XeriQf5fVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595aa0f4-53cd-452f-fcb2-1b5157219ae1"
      },
      "source": [
        "print (\"Фраза на русском языке; соответствие индекса и слова\")   \n",
        "convert(inp_language_tokenizer, input_tensor_train[0])           # Выведем нулевую пару из русского датасета\n",
        "print ()    \n",
        "\n",
        "print (\"Фраза на английском языке; соответствие индекса и слова\")\n",
        "convert(targ_language_tokenizer, target_tensor_train[0])         # Выведем нулевую пару из агнлийского датасета\n",
        "print ()   \n",
        "                                                      \n",
        "print(\"Рус.яз. тренировочная: \" , len(input_tensor_train), \"фраз; \", \"Анг.яз. тренировочная: \", len(target_tensor_train), \"фраз\")# Выведем статистику по обучающей выборке\n",
        "print(\"Рус.яз. тестовая: \", len(input_tensor_val), \"фраз; \", \"Анг.яз. тестовая: \", len(target_tensor_val), \"фраз\")               # Выведем статистику по тестовой выборке"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фраза на русском языке; соответствие индекса и слова\n",
            "1 ----> <start>\n",
            "8 ----> das\n",
            "183 ----> leben\n",
            "6 ----> ist\n",
            "41 ----> sehr\n",
            "375 ----> schwer\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Фраза на английском языке; соответствие индекса и слова\n",
            "1 ----> <start>\n",
            "233 ----> life\n",
            "8 ----> is\n",
            "45 ----> very\n",
            "177 ----> hard\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Рус.яз. тренировочная:  32000 фраз;  Анг.яз. тренировочная:  32000 фраз\n",
            "Рус.яз. тестовая:  8000 фраз;  Анг.яз. тестовая:  8000 фраз\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3AgPtOj83H9"
      },
      "source": [
        "Создаем `tf.data` датасет (Раздел `tf.data.Dataset API` предлагает построить готовый конвейер для обучения моделей)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuEJJsHy9rp5"
      },
      "source": [
        "# Определим постоянные \n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)                     # Укажем что случайно сэмплировать будем по всей длине обучающейся выборки\n",
        "BATCH_SIZE = 256                                          # Указываем размер батча\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE     # Укажем количество шагов в одной эпохе\n",
        "embedding_dim = 256                                       # Размерность эмбеддинга, векторного пространства\n",
        "units = 1024                                              # Задаем размер слоя(количество нейронов в слое) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB82awfvDB6o"
      },
      "source": [
        "# Задаем размер русского словаря\n",
        "vocab_inp_size = len(inp_language_tokenizer.word_index)+1 \n",
        "\n",
        "# Задаем размер английского словаря\n",
        "vocab_tar_size = len(targ_language_tokenizer.word_index)+1 \n",
        "\n",
        "# Создаём датасет из массивов Numpy(рус и анг тренировочные фразы) со случайной подачей тренировочных сэмплов в процессе обучения\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "# Передаем в датасет размер батча и указываем, что если в тренировке последний батч окажется неполным, то опустим его\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDgb_Z7y98ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbbd9d93-a3d6-4027-a438-0c145cdaaff1"
      },
      "source": [
        "# Посмотрим на форму примеров полученных батчей\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([256, 16]), TensorShape([256, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZE7WSCKQ4-H"
      },
      "source": [
        "Вспомним нашу схему - сеть состоит их кодера, декодера и блока attention.\n",
        "\n",
        "Давайте начнем оформлять кодер в виде класса. В этом примере кодер состоит из блоков `Embedding` и `GRU`. Обратим внимание на `return_sequences=True`, `return_state=True` - мы требуем состояния кодера на каждом шаге работы. \n",
        "\n",
        "На вход принимает фразу для перевода и начальное состояние. Отдает выход GRU и вектор скрытых состояний"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJwqiGRCDCu1"
      },
      "source": [
        "class Encoder(Model):\n",
        "\n",
        "  # Конструктор класса \n",
        "  def __init__(self, \n",
        "               vocab_size,    # Размер словаря\n",
        "               embedding_dim, # Размер пространсва эмбеддинга\n",
        "               enc_units,     # Число нейронов в GRU\n",
        "               batch_sz):     # Размер батча\n",
        "\n",
        "    super(Encoder, self).__init__()                                   # Даем возможность использовать и исполнять методы класса-родителя в классе потомке \n",
        "    self.batch_sz = batch_sz                                          # Атрибут возвращает размер батча\n",
        "    self.enc_units = enc_units                                        # Атрибут возвращает размер слоя в кодировщике\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim)             # Атрибут эмбеддинга - слой Кераса с размером словаря на входе и с dim=256\n",
        "\n",
        "    # Реккурентной сетью выберем GRU, указываем размер слоя, вывод из слоя в виде последовательностей, \n",
        "    # и метод инициализации весов 'glorot_uniform'(или метод Ксавьера) для упрощения прохождения сигнала при распростр-ии ошибки\n",
        "    self.gru = GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  # Метод принимает входную фразу и начальное состояние\n",
        "  def call(self, \n",
        "           x,       # Входная фраза\n",
        "           hidden): # Начальное энкодера\n",
        "    x = self.embedding(x) # входящие тензоры преобразовываются в эмбеддинг\n",
        "    output, state = self.gru(x, initial_state = hidden) #затем пропускаются через GRU и получаем выход + новое состояние\n",
        "\n",
        "    # Выход сети GRU и состояние на выходе\n",
        "    return output, state \n",
        "\n",
        "  # Создаем метод инициализации состояний на скрытых слоях\n",
        "  def initialize_hidden_state(self):\n",
        "\n",
        "    # Вернем тензор из нулей размер батча на размер слоя, итсполбьзуем как начальное состояние энкодера\n",
        "    return tf.zeros((self.batch_sz, self.enc_units)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BoTUmLPSsha"
      },
      "source": [
        "Создаем экземпляр класса Encoder. Используем далее как готовый модуль при построении модели сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgR4bQIKDFXF"
      },
      "source": [
        "# Создадим модель кодировщика по уже заданным параметрам \n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXH74Z-B_Mmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429505ca-3394-44a4-8a01-f35d110676ef"
      },
      "source": [
        "# Подадим в качестве примера какой-то сэмпл(Тензор[64, 12]) на вход Encoder'у и визуализируем, что получим\n",
        "sample_hidden = encoder.initialize_hidden_state() #инициализируем начальное скрытое состояние\n",
        "\n",
        "# Даем Encoder'у сэмпл и начальное состояние, и получим выход из сети GRU и состояние на выходе (вызывается метод call класса Encoder)\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Размеры выхода из кодировщика: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Размеры скрытого состояния: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеры выхода из кодировщика: (batch size, sequence length, units) (256, 16, 1024)\n",
            "Размеры скрытого состояния: (batch size, units) (256, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKRwq1d-S86R"
      },
      "source": [
        "Создадим класс модуля `attenton`, как предписывал Bahdanau. Разбор работы данного модуля мы прошли чуть ранее. На входе состояния кодера `hidden_state` и `values` - выход предыдущего декодера с предыдущего шага. На выходе вектор контекста и веса `attention`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWDTK8eqDHu0"
      },
      "source": [
        "class BahdanauAttention(Model): # Название класса именем создателя механизма Дмитрия Богданова(Bahdanau)\n",
        "\n",
        "  # Создаем конструктор класса\n",
        "  def __init__(self, \n",
        "               units):                        # Число нейронов \n",
        "\n",
        "    super(BahdanauAttention, self).__init__() # Даем возможность использовать и исполнять методы класса-родителя в классе потомке\n",
        "    self.W1 = Dense(units)                    # Создаем Dense с заданным числом нейронов\n",
        "    self.W2 = Dense(units)                    # Создаем Dense с заданным числом нейронов\n",
        "    self.V =  Dense(1)                        # Создаем Dense с числом нейронов =1\n",
        "\n",
        "  # Метод принимает состояние и выход энкодера ----------------------------------\n",
        "  \n",
        "  def call(self, \n",
        "           hidden_state, # Состояние энкодера\n",
        "           values):      # Выход энкодера\n",
        "    # Форма состояния на скрытом слое (batch_size, hidden size)\n",
        "    # Форму состояния на каждом такте увеличим до (batch_size, 1, hidden size)\n",
        "    # Добавляем это для того, чтобы получить оценку\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden_state, 1)\n",
        "\n",
        "    # Форма оценки score (размер батча, макс.длина слов на входе, 1), однёрка в конце, чтобы применить self.V\n",
        "    # До применения self.V оценка была бы (размер батча, макс.длина слов на входе, количество нейронов в слое)\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # К полученной оценке применим Софтмакс, который покажет вероятность полезности от 0 до 1 для каждого слова в фразе для декодера\n",
        "    # Форма оценки score - (размер батча, макс.длина слов на входе, 1); Софтмакс применяем к оси \"макс.длина слов\"\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # Построим вектор контекста \n",
        "    context_vector = attention_weights * values # Веса внимания перемножим со значениями(выхода из кодировщика)\n",
        "    # Сумму также применяем по оси \"макс.длина слов на входе\"\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1) # Размеры вектора контекста после суммирования будут (размер батча, размер слоя)\n",
        "\n",
        "    # Возвращает вектор контекста и веса внимания\n",
        "    return context_vector, attention_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8sMHv-wU_oD"
      },
      "source": [
        "Создадим экземпляр класса BahdanauAttention. Здесь 10 - число нейронов в первом dense слое"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUv-DSsDDKGl",
        "outputId": "bc52c541-f82b-4d93-dc06-8fc82124555a"
      },
      "source": [
        "# Проверим, как работает слой\n",
        "attention_layer = BahdanauAttention(10)\n",
        "\n",
        "# Подадим на вход слою внимания выход из Encodera и его состояние, и получим значение и веса внимания\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Размеры значения внимания: (размер батча, размер слоя) {}\".format(attention_result.shape))\n",
        "print(\"Размеры весов внимания: (размер батча, длина последовательности, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеры значения внимания: (размер батча, размер слоя) (256, 1024)\n",
            "Размеры весов внимания: (размер батча, длина последовательности, 1) (256, 16, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK4api1fVM3N"
      },
      "source": [
        "Создаем класс декодера с attention. Декодер принимает обущающую фразу, прогоняет через embedding. Далее склеивает с вектором контента и подает на GRU.\n",
        "На выходе dense слой с числом нейронов равному размеру словаря."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZHTEgDoDNBC"
      },
      "source": [
        "class Decoder(Model):\n",
        "\n",
        "  # Создадим конструктор класса\n",
        "  def __init__(self,   \n",
        "               vocab_size,    # Размер словаря\n",
        "               embedding_dim, # Размерность пространства эмбеддинга\n",
        "               dec_units,     # Число нейронов в GRU\n",
        "               batch_sz):     # Размер батча\n",
        "    super(Decoder, self).__init__()                       # Даем возможность использовать и исполнять методы класса-родителя в классе потомке \n",
        "    self.batch_sz = batch_sz                              # Атрибут возвращает размер батча\n",
        "    self.dec_units = dec_units                            # Атрибут возвращает размер слоя в декодере(кол-во нейронов)\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim) # Атрибут эмбеддинга - слой Кераса с размером словаря на входе и (dim=256) на выходе\n",
        "\n",
        "    # Реккурентной сетью выберем GRU, указываем размер слоя, вывод из слоя в виде последовательностей, \n",
        "    # и метод инициализации весов 'glorot_uniform'(или метод Ксавьера) для упрощения прохождения сигнала при распростр-ии ошибки    \n",
        "    self.gru = GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    self.fc = Dense(vocab_size) # Атрибут вызовет полносвязный слой с размером словаря\n",
        "\n",
        "    self.attention = BahdanauAttention(self.dec_units) #атрибут подключит механизм внимания, описанный ранее\n",
        "\n",
        "\n",
        "  def call(self, \n",
        "           x,           # Начальный токен\n",
        "           hidden,      # Состояние  энкодера\n",
        "           enc_output): # Выход энкодера\n",
        "\n",
        "    # Enc_output размеры (batch_size, max_length, hidden_size - размер батча, макс.длина фраз, разм.скр.слоя)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # Входящий тензор слова пропускаем через эмбеддинг (получаем размеры batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # Дальше конкатенируем с вектором контекста (получаем размеры batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # Сконкатенированный вектор передаем  в GRU и получаем выход с декодера и состояние\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # Output размеры (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # Пропускаем через полносвязный слой\n",
        "    x = self.fc(output) #output размеры (batch_size, vocab)\n",
        "\n",
        "    # Вернем выходную фразу, вектор состояния, веса внимания\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b1yEPu3DPqp",
        "outputId": "c40faf16-2354-47e1-9d6e-9fef7fb085e1"
      },
      "source": [
        "# Проверим работу декодера, подав на вход случайный массив с нужной размерностью\n",
        "# Создали декодер с параметрами(размер анг.словаря, размерность эмбеддинга, кол-во нейронов, размер батча)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# Подаём на вход случайный массив с нужной размерностью, состояние и выход с кодировщика\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((256, 1)), sample_hidden, sample_output)\n",
        "print ('Размер выхода с декодера: (размер батча, размер словаря) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер выхода с декодера: (размер батча, размер словаря) (256, 5235)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h7uiC6LDVRK"
      },
      "source": [
        "# Выбираем оптимайзер Adam\n",
        "optimizer = Adam() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qw4cgWJlDgW"
      },
      "source": [
        "Наша функция потерь называется  `loss_function` - сначала она уберет из расчетов нулевые элементы в истинной и предсказанной фразе. \n",
        "\n",
        "Длина фразы может быть меньше максимально допустимой или фраза может быть сформирована не полностью. Просто не будем учитывать мусор в конце фразы.\n",
        "\n",
        "Далее применим стандартную для Kerasa функцию потерь  SparseCategoricalCrossentropy. По сравнению CategoricalCrossentropy работает также, но позволяет нам не хранить слова в виде OneHotEncoding, что существенно экономить память.\n",
        "\n",
        "На выходе получаем среднее значение потерь:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YVxy08qDR-5"
      },
      "source": [
        "# Используем SparseCategoricalCrossentropy, к-я может работать с некатегориальными лейблами\n",
        "loss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none') # Выбираем функцию потерь\n",
        "\n",
        "def loss_function(real, pred):                       # Запишем функцию потерь, на вход подаем фактический и предсказанный результат\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) # Найдем маску, которая уберет нулевые значения индексов в конце фразы\n",
        "  loss_ = loss_object(real, pred)                    # Фактические и предсказанные результаты передаем в SparseCategoricalCrossentropy и получаем ошибку\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)            # Согласуем тип маски с типом потерь\n",
        "  loss_ *= mask                                      # Накидываем \"маску\" которая оставит для работы ненулевые значения\n",
        "  \n",
        "  # Вернем reduce_mean - среднее любого выбранного тензора\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHr21E05q0NN"
      },
      "source": [
        "# Сохраняем процесс обучения модели чекпоинтами тензорфлоу\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'                                               # Даем ссылку на директорию\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")                                # Добавляем префикс \"ckpt\"\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder) # Сохраняем состояния/показатели оптимизатора и моделей"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFb7r1SjYf7i"
      },
      "source": [
        "Создадим функцию для обучения модели. На входе - исходная фраза, конечная фраза, начальное состояния кодера. Подаем сразу батчем. На выходе потери на этом батче"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCNvA66Jq7nE"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp,         # Входная фраза\n",
        "               targ,        # Точный перевод\n",
        "               enc_hidden): # Состояния энкодера\n",
        "\n",
        "  # Создаем переменную, в которую будем записывать ошибку\n",
        "  loss = 0                             \n",
        "\n",
        "  # Все операции по вычислению градиента записываются на ленту(tape) и мы получаем к ним доступ\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    # Передаем тензор и начальное состояние в кодировщик и получим выход и состояние на выходе\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    # Передадим это состояние декодеру\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    # Передаем в качестве входа в декодер индекс токена \"<start>\"\n",
        "    dec_input = tf.expand_dims([targ_language_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Техника \"Teacher forcing\" - подаем предыдущее выходное слово на вход следущего в декодере. Targ.shape[64, 9]\n",
        "\n",
        "    for t in range(1, targ.shape[1]): #для каждого слова из английской фразы\n",
        "\n",
        "      # Передаем в обработку декодеру начальный токен, состояние на выходе из кодера, и выход из кодера\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output) # Получаем от декодера предсказание и обновленное состояние\n",
        "\n",
        "      # Обновляем ошибку для текущих предсказаний\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # Используем \"Teacher forcing\"\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  # Получаем ошибку на батче . Targ.shape[64, 9]. Делим на 9\n",
        "  batch_loss = (loss / int(targ.shape[1])) \n",
        "\n",
        "  # Создаем список переменных, для которых TensorFlow будет вычислять градиенты\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables # создаем переменные, для которых TensorFlow будет вычислять градиенты\n",
        "\n",
        "  # Отслеживаем градиент\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  # Корректируем веса\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Функция обучения вернет ошибку на батче\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GwOr3sEYiW_"
      },
      "source": [
        "Обучаем сеть. 30 эпох. На каждой эпохе прогоняем весь набор данных через функцию обучения. Считаем лоссы. Сохраняем статистику каждые 10 эпох"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Tpy6Cxq-V3",
        "outputId": "55756d9b-2c04-4446-d4e9-45699e451c0a"
      },
      "source": [
        "EPOCHS = 30 # устанавливаем количество эпох\n",
        "\n",
        "for epoch in range(EPOCHS): # Цикл по каждой эпохе\n",
        "  start = time.time() # Запомним время начала эпохи\n",
        "\n",
        "  progbar = tf.keras.utils.Progbar(target=steps_per_epoch, stateful_metrics=[\n",
        "                                     'batch_loss'], unit_name='batch')        # Создадим индикатор прогресс обучения\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state() # Задаем начальное состояние на скрытом слое encodera \n",
        "  total_loss = 0                                 # Начальное значение итоговой ошибки\n",
        "\n",
        "  # Для батча, входного и выходного тензора на каждом шаге эпохи\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden) # Передадим в функцию тензоры и состояние в кодировщике, обучим и получим ошибку на батче\n",
        "    total_loss += batch_loss                       # Добавим ее в итоговую ошибку\n",
        "    progbar.update(                                # Обновим состояние индикатора обучения\n",
        "            batch + 1, values=[('batch_loss', batch_loss)])\n",
        "\n",
        "\n",
        "  # Каждые 10 эпох будем сохранять чекпоинты\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  # Выведем показатели после каждой эпохи\n",
        "  print('Эпоха {} Ошибка {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch)) # Выведем номер эпохи и потери\n",
        "  print('Время на 1 эпоху {} сек'.format(round(time.time() - start), 1))          # Выведем длительность обучения этой эпохи"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 38s 190ms/batch - batch_loss: 1.9779\n",
            "Эпоха 1 Ошибка 2.4769\n",
            "Время на 1 эпоху 38 сек\n",
            "125/125 [==============================] - 21s 166ms/batch - batch_loss: 1.6075\n",
            "Эпоха 2 Ошибка 1.7359\n",
            "Время на 1 эпоху 21 сек\n",
            "125/125 [==============================] - 21s 168ms/batch - batch_loss: 1.4024\n",
            "Эпоха 3 Ошибка 1.4668\n",
            "Время на 1 эпоху 21 сек\n",
            "125/125 [==============================] - 21s 171ms/batch - batch_loss: 1.1500\n",
            "Эпоха 4 Ошибка 1.2340\n",
            "Время на 1 эпоху 21 сек\n",
            "125/125 [==============================] - 21s 169ms/batch - batch_loss: 0.9464\n",
            "Эпоха 5 Ошибка 1.0078\n",
            "Время на 1 эпоху 21 сек\n",
            "125/125 [==============================] - 21s 170ms/batch - batch_loss: 0.7586\n",
            "Эпоха 6 Ошибка 0.8086\n",
            "Время на 1 эпоху 21 сек\n",
            "125/125 [==============================] - 21s 172ms/batch - batch_loss: 0.6295\n",
            "Эпоха 7 Ошибка 0.6380\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 174ms/batch - batch_loss: 0.5403\n",
            "Эпоха 8 Ошибка 0.5018\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 174ms/batch - batch_loss: 0.3800\n",
            "Эпоха 9 Ошибка 0.3979\n",
            "Время на 1 эпоху 41 сек\n",
            "125/125 [==============================] - 22s 173ms/batch - batch_loss: 0.3061\n",
            "Эпоха 10 Ошибка 0.3203\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 175ms/batch - batch_loss: 0.2550\n",
            "Эпоха 11 Ошибка 0.2628\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 174ms/batch - batch_loss: 0.2267\n",
            "Эпоха 12 Ошибка 0.2168\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 173ms/batch - batch_loss: 0.1982\n",
            "Эпоха 13 Ошибка 0.1813\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 174ms/batch - batch_loss: 0.1775\n",
            "Эпоха 14 Ошибка 0.1537\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 176ms/batch - batch_loss: 0.1372\n",
            "Эпоха 15 Ошибка 0.1318\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 178ms/batch - batch_loss: 0.1197\n",
            "Эпоха 16 Ошибка 0.1168\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 178ms/batch - batch_loss: 0.1142\n",
            "Эпоха 17 Ошибка 0.1043\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 177ms/batch - batch_loss: 0.0907\n",
            "Эпоха 18 Ошибка 0.0934\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 176ms/batch - batch_loss: 0.0902\n",
            "Эпоха 19 Ошибка 0.0849\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 178ms/batch - batch_loss: 0.0830\n",
            "Эпоха 20 Ошибка 0.0770\n",
            "Время на 1 эпоху 23 сек\n",
            "125/125 [==============================] - 22s 177ms/batch - batch_loss: 0.0998\n",
            "Эпоха 21 Ошибка 0.0715\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 177ms/batch - batch_loss: 0.0763\n",
            "Эпоха 22 Ошибка 0.0680\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 179ms/batch - batch_loss: 0.0598\n",
            "Эпоха 23 Ошибка 0.0634\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 178ms/batch - batch_loss: 0.0805\n",
            "Эпоха 24 Ошибка 0.0600\n",
            "Время на 1 эпоху 41 сек\n",
            "125/125 [==============================] - 22s 172ms/batch - batch_loss: 0.0746\n",
            "Эпоха 25 Ошибка 0.0585\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 173ms/batch - batch_loss: 0.0543\n",
            "Эпоха 26 Ошибка 0.0556\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 176ms/batch - batch_loss: 0.0535\n",
            "Эпоха 27 Ошибка 0.0537\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 177ms/batch - batch_loss: 0.0678\n",
            "Эпоха 28 Ошибка 0.0517\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 175ms/batch - batch_loss: 0.0656\n",
            "Эпоха 29 Ошибка 0.0517\n",
            "Время на 1 эпоху 22 сек\n",
            "125/125 [==============================] - 22s 178ms/batch - batch_loss: 0.0647\n",
            "Эпоха 30 Ошибка 0.0515\n",
            "Время на 1 эпоху 23 сек\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzCVG3YhYj0O"
      },
      "source": [
        "Данная функция собирает модель кодера, декодера и attention для работы в режиме перевода (предсказания).\n",
        "\n",
        "На входе переводимое русское предложение, на выходе его английский перевод"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX4koS1irAnJ"
      },
      "source": [
        "def evaluate(sentence):\n",
        "\n",
        "    # Создаем начальные настройки графика внимания\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp)) \n",
        "    \n",
        "    # Предобрабатываем предложение\n",
        "    sentence = preprocess_sentence(sentence) \n",
        "\n",
        "    inputs = [inp_language_tokenizer.word_index[i] for i in sentence.split(' ')]   # Преобразовываем в послед-ть индексов\n",
        "    inputs = pad_sequences([inputs], maxlen=max_length_inp, padding='post')        # Делаем паддинг\n",
        "    inputs = tf.convert_to_tensor(inputs)                                          # Конвертируем в тф тензор\n",
        "\n",
        "    result = ''                                                                    # Сюда запишем результат\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]                                                # Задаем начальное состояние\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)                                  # Передаем его и входной тензор и получаем выход с кодера и состояние\n",
        "\n",
        "    dec_hidden = enc_hidden                                                        # Состояние кодера передаем в декодер\n",
        "    dec_input = tf.expand_dims([targ_language_tokenizer.word_index['<start>']], 0) # Передаем на вход декодеру <start> в виде индекса\n",
        "\n",
        "    for t in range(max_length_targ):                                               # Идем по макс.длине фраз выходного языка(анг)\n",
        "        # Прогоняем через декодер входящий тензор, состояние с выхода кодера, выход с кодера\n",
        "        # Получаем результат предсказания, обновленное состояние, и веса внимания\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        # Сохраняем веса внимания для графика\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        # Аргмаксом вытаскиваем предсказанное слово\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        # Результат конвертируем из индекса в слово и сохраняем в result = ''\n",
        "        result += targ_language_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        # Если предсказанное слово - <end>, то останавливаемся, возвращаем результаты, выводим на графике\n",
        "        if targ_language_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # Педсказанное значение подается обратно в модель\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    # Вернем перевод, входную фразу и веса внимания\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP7AnPSBcC9D"
      },
      "source": [
        "Нам интересно как связаны слова в исходной фразе и в ее переведе. Функция отрисовывает веса внимания в виде 2D матрицы, соотносит каждую пару  слов  ее весом  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It8ZVMbHrFYj"
      },
      "source": [
        "def plot_attention(attention,           # Веса внимания\n",
        "                   sentence,            # Исходная фраза\n",
        "                   predicted_sentence): # Предсказаные перевод\n",
        "  \n",
        "    fig = plt.figure(figsize=(10,10))                                   # Зададим размер \n",
        "    ax = fig.add_subplot(1, 1, 1)                                       # Добавим 1 картинку\n",
        "    ax.matshow(attention, cmap='viridis')                               # Нарисуем 2d матрицу\n",
        "    fontdict = {'fontsize': 14}                                         # Зададим размер надписей\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90) # Добавим надпись по горизонтальной оси\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)    # Добавим надпись по вертикальной оси\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))               # Зададим форматирование делений на осях графиков\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))               # Зададим форматирование делений на осях графиков\n",
        "    plt.show()                                                          # Отрисуем изображение"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXrttZ_Ccd--"
      },
      "source": [
        "Соберем написанные ранее функции вместе. Будем переводить фразы и строить матрицы внимания(attention)  - смотреть связи слов в предложении"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7afFCab-N_Xf"
      },
      "source": [
        "Создадим функцию для перевода фраз с визуализацией матрицы внимания"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH8G96tWrHmn"
      },
      "source": [
        "def translate(sentence): # Функция принимает предложение и выводит результат с визуализацией\n",
        "    result, sentence, attention_plot = evaluate(sentence)  # Отдадим фразу. Получим перевод, входную фразу,  веса внимания\n",
        "\n",
        "    print('Входящая фраза: %s' % (sentence))          # Выведем входную фразу \n",
        "    print('Предсказанный перевод: {}'.format(result)) # Выведем полученный перевод\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))] # Возьмем весы внимания, только для слов во фразах. Хвосты не смотрим\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))              # Выведем веса внимания"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vsbPAP5rJle",
        "outputId": "0c1a0092-0729-47d7-edd7-8807a139cc01"
      },
      "source": [
        "# Воспроизведём последний сохранённый чекпоинт\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fcaa1a181c0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcH-0rkFPNeU"
      },
      "source": [
        "И, наконец, переведём предложение и выведем визуализацию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "bBi0SqkJrMeK",
        "outputId": "b29d6a11-8443-4d77-9378-bced6f7e3140"
      },
      "source": [
        "translate('geht es dir gut')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> geht es dir gut <end>\n",
            "Предсказанный перевод: get you okay . <end> \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a16ba1e9d77a>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90) # Добавим надпись по горизонтальной оси\n",
            "<ipython-input-34-a16ba1e9d77a>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)    # Добавим надпись по вертикальной оси\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "X2VVb9LHrOv8",
        "outputId": "5aeb6049-2b0c-4dfe-b977-39b5bd49d574"
      },
      "source": [
        "translate('alles ist gut?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> alles ist gut ? <end>\n",
            "Предсказанный перевод: is it all right ? <end> \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a16ba1e9d77a>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90) # Добавим надпись по горизонтальной оси\n",
            "<ipython-input-34-a16ba1e9d77a>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)    # Добавим надпись по вертикальной оси\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAJwCAYAAAAk4XMZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg00lEQVR4nO3de7StdV3v8c9XNkKIaCoimoiphGliuL3lESHyknocw8uwvEJ25GiZpEfraKknCz2allqNlPKGWFp2PN7yggreumhe6uAFRMVUUiERREQEvuePObcuF3vjXpv9W8+ca71eY+yx55zP3HN91zMWa755brO6OwAAu9s1ph4AANiYRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyFhAVXWrqnpvVf3M1LMAwK4SGYvpmCRHJnnMxHMAwC4rH5C2WKqqkpyd5JQk/zXJjbv78kmHAoBdYEvG4jkyybWTPDHJZUnuO+k0ALCLRMbiOSbJG7r74iSvm98HgKVjd8kCqaprJfmPJPfr7g9U1e2T/GOSA7v7m1POBgBrZUvGYnlwkvO6+wNJ0t2fSPLZJL885VAATKeqrlVVj66q60w9y1qJjMXyqCQnr3rs5CTHrv8oACyIhyZ5ZWbvEUvF7pIFUVU3TfKFJLfu7s+uePwnMjvb5Ke7+8yJxgNgIlV1apIDklzc3VunnmctRAYALKiqOjjJmUnulOSfkhze3Z+adKg1sLtkgVTVQfPrZGx32XrPA8DkHpXkA/Nj9P4+S3bGochYLF9Isv/qB6vq+vNlAGwuj07ymvnt1yZ5xI7+Z3QRiYzFUkm2t/9q3ySXrPMsAEyoqn4uyYFJ3jB/6C1J9knyC5MNtUZbph6ApKpeMr/ZSZ5bVRevWLxHZvviPrHecwEwqWOSvKm7L0qS7r60qv4mszMOT5lysJ0lMhbDtk9brSS3TnLpimWXJvlYkhes91AATKOq9srs1NWHrVp0cpJ3VtW+2+JjkTm7ZEHM97H9TZLHdPe3pp4HgOlU1Q0y++yqk7v7ilXLHpnk3d391UmGWwORsSCqao/Mjrs4bJlOTwKAHXHg54KYf5z7F5Ncc+pZAGB3sCVjgVTVMZntf3tkd5839TwArK+q+kK2f5bhlXT3Tw4e52pz4OdieUqSmyf5SlV9Ocm3Vy7s7ttNMhUA6+VPV9zeN8mTk3w4s0/kTpK7ZnbG4QvXea5dIjIWyxt+9FMA2Ki6+/vxUFWvSvK87n7OyudU1dOS3GadR9sldpcAwAKqqgsz+6ySs1Y9fsskH+vu/aaZbOc58JOlVlUPrap7rbj/zKr6clW9s6oOnHI2gKvp20mO3M7jRya5eDuPLxyRsUCq6ppV9XtVdWZVXVJVl6/8M/V8C+p/bbtRVYcneXqSlyTZM0uyzxJgB/44yZ9V1Uur6tj5n5cm+ZP5soXnmIzF8vtJfinJczP7AXpqkoOT/HKSZ0w31kK7WZIz5rcfmOT/dvfzq+pdSd453VgAV8/8d9nZSY7P7OqfSfLpJMd0999MNtgaOCZjgcxPXXp8d7+jqr6V5Pbd/bmqenySo7v7IROPuHCq6j+T3KO7T6+qf0jyiu7+y6q6eZJPdvc+E48IsGnZkrFYDkiy7WqfFyW57vz2O5I8b4qBlsAHkrywqj6YZGuSbSF2SJIvTTYVwG5UVdfNqkMcuvsb00yz8xyTsVj+PcmN57fPSnLv+e27JvnOJBMtvidk9iFyD0nyuO4+Z/74L8buEmCJVdXNqurtVfWdJP+Z5Nz5n/Pmfy88u0sWSFU9N8lF3X1CVT0kyV8n+XKSmyT5w+7+nUkHBGDdVNV7M9ui/YIk52TVlUC7+30TjLUmImOBVdWdk9wtyZnd/dap51lUVbV3kvsnuUWSl3X3N6vqFknOX4bNiQDbU1UXJblLd58+9Sy7yjEZC6SqjkjyD919WZJ09z8n+eeq2lJVR3T3+6edcPHML0rz7swuv3vdJH+b5JtJHj+//98mGg3g6vpCkr2mHuLqcEzGYjk1yfW28/h15su4shcleVdmB82uPG7lzUmOmmIgNq75NWtuuJ3Hr+9aNgxwfJLnzv9nainZkrFYKtv/9L3rZ9WHpfF9P5fZ5sTLq2rl4ysPooXdpXbw+F6ZHYAMu9ObMvvZOqOqvpvkspULl+Gy4iJjAVTVm+c3O8nJ8x+mbfZIctsk/7Dugy2PPbfz2EFJLljvQdiYqurJ85ud5HHzfeXb7JHk7kk+s+6DsdE9YeoBri6RsRj+c/53JTk/P7zZ/9IkH0zyF+s91JJ4V2Yfhfyr8/tdVfsl+b0kb5tsKjaa35j/XZkd57Ny18ilSc5O8rh1nokNrrtfPfUMV5ezSxZIVT0ryQu6266RnVRVN84Pjlf5ySQfT3LLJF9LckR3L8W55CyHqjo1yYO6+/ypZ2FzqKoDkjwqs7PnntHd51XV3ZKc091fmHa6H01kLJCqukaSdPcV8/s3yuzUzE91t90lO1BVP5bkYUkOz+xg5o8leW13u4AZsLSq6g5J3pPZWSa3SXJod3++qv5XkkO6++FTzrczRMYCqaq3J3lHd7+4qvbNbB/vtTI7PfNXu/ukSQeETa6qXnJVy7v7ies1CxvffMvZ+7v7WfPPszpsHhl3TfK67r7ZxCP+SI7JWCxbk/zW/PaDklyY5OZJHpHkKUlERpKqetDOPre7/8/IWZZZVT0zs91zF696/MeSPLW7nz3NZAvtZ1bd3zPJoZkd/Pnx9R+HDe4O+cHxZiv9R2an7S88kbFY9s3sQlJJcq8kb+zu780vLftnk021eN6wk8/rzH75s33PSvLSJBevenyf+TKRsUp3X+naK/Mrzr48sw/rg93pO0l+fDuPH5rk6+s8yy5xMa7F8u9J7lZV18rsw9FOmT9+vVz5jWDT6u5r7OQfgXHVdnRdlp9N4nLsO6m7L0nynCQ+W4jd7U1JnlVV26762VV1cGafyv13k021BrZkLJY/SvKazD7m/YtJtl1G/Igk/2+qodhY5vt2e/7n81W1MjT2SLJ3Zls42Hk3yGxLJOxOT0ny95l94uo+mV3O4IDMrpv0uxPOtdMc+Llg5kcTH5TklO6+aP7Y/ZJ8s7s/NOlwC8IxGVdPVR2T2VaMVyT5zfzwRcsuTXJ2d//jBKMtvBUX5fr+Q0kOzOy4qfd29yPWfyo2uqr6+aw4e6673z3xSDtNZCyIqrpOktt195X2687Pif6Uc/NnquqKnXxq22WyY1V1jyQf2vaBfPxoVbX6ugRXZPZ/me9N8tzu/tb6T8VGtFHeE0TGgqiqa2d2xPC9V26xqKrDknw4yU26+7yp5mPjqaqfTnJ5d58xv3/PJMck+WSS53e3D/yCiWyU9wTHZCyI7v5WVb0pyaOTrNwt8qgk71yGH6apVNWWJHfKbDfTNVcs6u5+zTRTLYVXZPYptmdU1U0zO8jstCS/nmS/JE+bbLIFVVWv2MGiTnJJkrOSvL67z1m/qdiINsp7gi0ZC6Sq7p3kr5PcqLsvnV8B9MtJnuDYgu2rqkOTvCWz64lUZp8psSXJ95J8dxk+pXAqVfXNJHfq7jOr6klJHtDdR1XVUUle2d0HTzrgAqqqt2T2YWhXJDl9/vBtM/vZ+2hmV2XcN8ndu/sTU8zIxrER3hOcwrpYTsnsvOj7z+8fndn/mb9lsokW34sy++V+ncxO8711Zhc1+0SSB0821XLYIz/4ePKjMzuKPUk+lyW50M8EPpTk7Ul+oruP6O4jkvxEZuvuXUlultkH871wuhEXS1Xdv6p+c/4xCazN0r8niIwFMv/MkpMz2zyWzDaLvb67vzfdVAvvjkn+YP6hclck2dLdH8vsyql+0V+105M8vqruntkvr3fMH79JkqXYFDuB45M8e+VVUue3T0jypO6+NLNrGNx+mvEWS1X9zyRvTPLUJP9aVauvmMpV2AjvCSJj8ZyU5D5VdVCSByZZ+o/6HazygwuVnZvZG2Qy26R4y0kmWh6/neSxSd6X5K+7e9u1WB6Q2YFlXNm+mZ2yutqN8oPrZFwYx7tt82uZfe7STZK8OMkpVXWvqjqoqrZU1YHz33Xs2FK/J/gPYcF09yer6vQkr03y5e72y/6qnZ7ksCSfz+yN8ber6vLM3jzPmnKwRdfd76+q/ZPst+pUuJcl+fZEYy26NyZ5eVX9VpKPzB+7Y5LnJ9m2j/xOSc6cYLZFdL3MLyrY3c+ZH1Pw9vmyO2b2e+6QuPz/Di37e4LIWEwnZXasgcsU/2gnZPZJtcnsCnhvS3JqZpv7HzrVUIuqqt6c5JHdfeH89rbHt/f0B6zbYMvjcZldmffk/OD352WZnanzlPn9T2cWucxi66eTnJ0k3f0HVfXyzLYGfTqz3QD7TDbd8lja9wRnlyygqrpekt9I8rLu/urU8yyb+fo7v/1wX0lVvTLJE+enx73yqp7b3b+yTmMtnfnnC91ifvdz82OCWKWqnpDkqO52EPbVsMzvCSIDABjCgZ8AwBAiAwAYQmQssKo6buoZlpH1tnbW2a6x3naN9bZ2y7rORMZiW8ofqgVgva2ddbZrrLddY72t3VKuM5EBAAyx6c8uuWbt1Xt//zILi+V7+W72zF5Tj7F0rLe1s852jfW2a6y3tVvkdfatnH9ed++/vWWb/mJce+dauXMdPfUYALCU3t1v+OKOltldAgAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGCIpY6MqnpVVb116jkAgCvbMvUAV9PxSWrqIQCAK1vqyOjuC6aeAQDYvg2zu6Sqjqiqf6qqi6rqgqr6cFXdduoZAWCzWuotGdtU1ZYkb0ry8iSPSLJnksOTXD7lXACwmW2IyEiyX5LrJnlLd39u/thndvTkqjouyXFJsnf2GT4cAGxGS727ZJvu/kaSVyV5Z1W9raqeXFUHXcXzT+zurd29dc/stW5zAsBmsiEiI0m6+1eS3DnJ+5M8IMkZVXXvaacCgM1rw0RGknT3v3b387r7yCSnJTlm2okAYPPaEJFRVTevqv9dVT9XVTerqqOS3C7Jp6aeDQA2q41y4OfFSQ5J8rdJbpDka0lem+R5Uw4FAJvZUkdGdx+74u6DppoDALiyDbG7BABYPCIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMMSWqQdg+Vx+1OFTj7CU3v3aV0w9wlK63x3uM/UIS6cvvXTqEZZS7XutqUdYTmfveJEtGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAbIjKq6lVV9dap5wAAfmDL1APsJscnqSSpqtOSnN7dT5h0IgDY5DZEZHT3BVPPAAD8sA0RGVX1qiQ3SHJeknskuUdV/fp88c27++yJRgOATWtDRMYKxyc5JMlnkjx9/ti5040DAJvXhoqM7r6gqi5NcnF3f3VHz6uq45IclyR7Z5/1Gg8ANpUNcXbJWnX3id29tbu37pm9ph4HADakTRkZAMB4GzEyLk2yx9RDAMBmtxEj4+wkd6qqg6vqBlW1Eb9HAFh4G/EN+AWZbc34VGZnlhw07TgAsDltiLNLuvvYFbfPTHLX6aYBAJKNuSUDAFgAIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwxJapB1gIVVNPsFTOv9VeU4+wlG510uOnHmEp7fVo/32uVfXUEyynm5xywdQjLKezd7zIlgwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADLFhIqOquqoesqP7AMD62jCRAQAsFpEBAAyxNJFRVfepqg9U1flV9Y2qemdV3XrquQCA7VuayEhyrSQvSnKnJEcmuSDJW6rqmhPOBADswJapB9hZ3f13K+9X1a8kuTCz6PjgWl6rqo5LclyS7J19dteIAMAKS7Mlo6puUVV/VVWfq6oLk3wts/kPWutrdfeJ3b21u7fumb12+6wAwBJtyUjy1iRfTvLfk3wlyWVJPpXE7hIAWEBLERlVdf0khyb5te4+df7Y4VmS+QFgM1qWN+nzk5yX5LFV9aUkN0nyh5ltzQAAFtBSHJPR3Vck+aUkt0tyepI/S/KMJN+dci4AYMeWZUtGuvu9SW676uF9VyyvVc+vAACTWYotGQDA8hEZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCG2TD0Ay+eA074+9QhL6YBTe+oRltKxb3vP1CMsnee98OFTj7CULjj02lOPsJw+tuNFtmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYIjJIqOqzq6qp6zh+QdXVVfV1pFzAQC7x5YJv/Ydk3x7d75gVR2Z5NQk+3f3ebvztQGAtZkkMqrqmt197hRfGwBYH+uyu6SqTquqP6+qF1TVuUk+tHp3SVUdUlXvq6pLquqMqrpvVV1UVceuermbVdUpVXVxVX2qqu45//cHZ7YVI0nOne9aedU6fHsAwHas5zEZj0xSSe6e5NErF1TVNZK8McllSe6S5Ngkz0qy13Ze54QkL0lyWJKPJHldVe2b5EtJHjx/zm2SHJjk+N39TQAAO2c9d5d8obv/x7Y7VbVy2T2T/FSSe3X3V+bLn5TkQ9t5nT/u7rfMn/P0zILl9t39war6xvw5X7+qYzKq6rgkxyXJ3tln178jAGCH1nNLxkevYtmhSc7ZFhhzH0lyxXae+28rbp8z//uGaxmku0/s7q3dvXXP7W4sAQCurvWMjN11Jsn3tt3o7p7fdL0PAFgwi/Lm/JkkN66qG694bGvWPt+l87/32C1TAQC7bFEi45QkZyR5dVUdVlV3SfJHmR0I2lf5L3/YF+fPv19V7T8/IBQAmMBCREZ3X5HkgZmdTfLhJK/O7CySTnLJGl7nK5mdlXJCkq8l+dPdPiwAsFPW5eyS7j5yO48dvOr+mUmO2Ha/qg5LsmeSs+bLz87sFNjVr1Or7v9+kt+/+lMDAFfHlJcV/yFV9cDMDg79bJKDM9td8q9JPjbhWADALlqYyEhy7STPS3LTJOcnOS3Jk1acQQIALJGFiYzuPinJSVPPAQDsHgtx4CcAsPGIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIbZMPcBC6J56gqVy+Zmfm3oENpHfeePDpx5h6VzvO1NPsJx++9knTz3CUnrwX+14mS0ZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhiQ0VGVT2hqj5eVd+uqi9V1dOmngkANqstUw+wmx2d5JlJPpnkiCR/WVWf7O43TzsWAGw+GyoyuvuBK+5+vqqek+SWU80DAJvZhtpdslJVPT3JnkleN/UsALAZbagtGdtU1e8meWKSe3b3OdtZflyS45Jk7+yzztMBwOaw4SKjqm6c5NlJ7tfdn9jec7r7xCQnJsl+db1ev+kAYPPYiLtLDkxSST499SAAsJltxMj4dJI7JrnSbhIAYP1sxMi4bZKTk+w/9SAAsJltxMjYJ8lPZXZmCQAwkQ134Gd3n5bZMRkAwIQ24pYMAGABiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAEFumHgDgqhzyx5+feoTls/deU0+wlP7834+ceoQl9YkdLrElAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDLE1kVNVTqursqecAAHbO0kQGALBcdktkVNV+VXXd3fFaa/ia+1fV3uv5NQGAnbfLkVFVe1TVvavqr5J8Nclh88evU1UnVtXXq+pbVfW+qtq64t8dW1UXVdXRVXV6VX27qk6tqpuvev3fqqqvzp97UpJ9V41w3yRfnX+tu+3q9wEAjLHmyKiq21TV85N8Kcnrk3w7yX2SvL+qKsnbktwkyf2T/GyS9yd5b1UduOJl9krytCSPSXLXJNdN8tIVX+OhSf4gybOSHJ7kjCRPXjXKa5M8PMm1k5xSVWdV1TNXxwoAMI2dioyqun5VPbGqPprk40kOTXJ8kht192O7+/3d3UmOSnL7JA/p7g9391nd/Ywkn0/yqBUvuSXJr8+f829JXpDkyHmkJMlvJnl1d7+su8/s7hOSfHjlTN19WXf/fXc/LMmNkjxn/vU/W1WnVdVjqmr11o9t389xVfUvVfUv38t3d2YVAABrtLNbMn4jyYuTXJLkkO5+QHf/bXdfsup5d0iyT5Jz57s5Lqqqi5LcNsktVjzvu919xor75yS5ZpIfn9+/dZJ/XPXaq+9/X3df2N2v6O6jktwxyQFJXp7kITt4/ondvbW7t+6Zva7i2wYAdtWWnXzeiUm+l+TRSU6vqjcmeU2S93T35Sued40kX0ty9+28xoUrbl+2almv+PdrVlV7ZbZ75pGZHavxycy2hrxpV14PALj6dupNvbvP6e4TuvunkvxCkouSvC7Jl6vqhVV1+/lTP5bZVoQr5rtKVv75+hrm+nSSu6x67Ifu18x/qaqXZXbg6Z8kOSvJHbr78O5+cXefv4avCQDsRmvectDd/9Tdj09yYGa7UQ5J8pGqunuSdyf5UJI3VdUvVtXNq+quVfV78+U768VJjqmqx1bVrarqaUnuvOo5j0zyriT7JXlYkpt291O7+/S1fk8AwO63s7tLrqS7v5vkDUneUFU3THJ5d3dV3TezM0P+IskNM9t98qEkJ63htV9fVT+Z5ITMjvF4c5I/SnLsiqe9J7MDTy+88isAAFOr2Ukhm9d+db2+cx099RjADmy50QFTj7B89nZA+6647OVXTD3CUnr3z7/oo929dXvLXFYcABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACG2DL1AABX5bKvfm3qEdgsjp56gI3HlgwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBBbph5gClV1XJLjkmTv7DPxNACwMW3KLRndfWJ3b+3urXtmr6nHAYANaVNGBgAwnsgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAEOIDABgCJEBAAwhMgCAIUQGADCEyAAAhhAZAMAQIgMAGEJkAABDiAwAYAiRAQAMITIAgCFEBgAwhMgAAIYQGQDAECIDABhCZAAAQ4gMAGAIkQEADCEyAIAhRAYAMITIAACGEBkAwBAiAwAYQmQAAENUd089w6Sq6twkX5x6jh24QZLzph5iCVlva2ed7RrrbddYb2u3yOvsZt29//YWbPrIWGRV9S/dvXXqOZaN9bZ21tmusd52jfW2dsu6zuwuAQCGEBkAwBAiY7GdOPUAS8p6WzvrbNdYb7vGelu7pVxnjskAAIawJQMAGEJkAABDiAwAYAiRAQAMITIAgCH+P3E060EYdhVQAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "uWC8-1DDrPQ1",
        "outputId": "85febe54-ada3-43d3-c5e3-075346ce515c"
      },
      "source": [
        "translate('das wetter ist da')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> das wetter ist da <end>\n",
            "Предсказанный перевод: that s october th . <end> \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a16ba1e9d77a>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90) # Добавим надпись по горизонтальной оси\n",
            "<ipython-input-34-a16ba1e9d77a>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)    # Добавим надпись по вертикальной оси\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sahW4uQD51Rv"
      },
      "source": [
        "Что можно сказать. Как переводчик сеть не очень. Но связи слов в предложениях уже находит. Ноутбук отлично справился с другой базой (перевод с немецкого на английский) , достаточно было ее заменить. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUboNys8E1AX"
      },
      "source": [
        "**Содержание темы**\n",
        "\n",
        "\n",
        "1. [Теория](https://colab.research.google.com/drive/1f2RV3yzZIqRoGpP9y-b45NgnivaIT-4q?usp=sharing)\n",
        "\n",
        "2. Практика\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}