{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10100111/Display-of-HW1/blob/main/95_%D0%A1%D0%B5%D1%82%D0%B8_%D1%81_%D0%B2%D0%BD%D0%B8%D0%BC%D0%B0%D0%BD%D0%B8%D0%B5%D0%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание Ultra Lite\n",
        "\n",
        "Макс 10 баллов\n",
        "\n",
        "Перепишите ноутбук-переводчик из вебинара. Код желательно писать по памяти своими руками. Однако в ноутбук занятия подглядывать можно."
      ],
      "metadata": {
        "id": "tYZ3N_8O7I3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка библиотек\n"
      ],
      "metadata": {
        "id": "PDsn3-BSAQnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files # модуль для загрузки файлов в colab\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # загружаем токенайзер кераса для предобработки текстовыз данных\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # метод для формирования послдовательностей одинаковой длины\n",
        "from tensorflow.keras.models import Model # загружаем абстрактный класс базовой модели сети\n",
        "from tensorflow.keras.layers import Dense, Embedding, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Библиотеки для визуализации данных\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker # модуль для определения форматирования и местоположения делений на осях графиков\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "import re # модуль для работы с регулярными выражениями\n",
        "import time\n",
        "import os\n",
        "import gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzr4PSx2APm1",
        "outputId": "e46019f8-40f2-4c50-ac47-651709a10f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка и парсинг данных"
      ],
      "metadata": {
        "id": "Sdb6eIbFD-34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузить по ссылке с гугл драйва\n",
        "# path_to_text = tf.keras.utils.get_file('eng_rus_dictionary.txt', origin = 'https://drive.google.com/uc?export=download&id=1phlxAS_QBq65_WmadLLIeTqqHArXQbSR')\n",
        "# path_to_file = os.path.dirname(path_to_text)+'/eng-rus_dictionary.txt'"
      ],
      "metadata": {
        "id": "DeE_AWVUD9KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/advanced/l3/rus-eng.zip', None, quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a-OL9FAPn9Yj",
        "outputId": "4679bc04-204c-40f6-fd94-462d6df0d700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rus-eng.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o rus-eng.zip "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqPc7VIAoRdj",
        "outputId": "52dd5103-49d6-4757-b260-6c9a3d72e8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим распакованные файлы\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIjYj_ieqADE",
        "outputId": "6de4988c-5722-42df-c7a4-e442c66414ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_about.txt  rus-eng.zip  rus.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Указываем путь к загруженному файлу\n",
        "path_to_file = \"/content/rus.txt\""
      ],
      "metadata": {
        "id": "blJpoR8nCqvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Предобработка предложений, очищаем от мусора, формируем нужную структуру слов и фраз\n",
        "def preprocess_sentence(phrases): # функция принимает содержимое словаря\n",
        "  # Разделяем пробелами слова и знаки препинания (\"А как насчет тебя? -> А как насчет тебя ? \")\n",
        "  phrases = re.sub(r\"([?.!,:;])\", r\" \\1 \", phrases) # r\" \\1 \" берет значения 1й группы в скобках; обрамляем указанные символы пробелами\"\n",
        "\n",
        "  # Заменяем все на пробелы, за исключением (a-zA-Za-яёА-ЯЁ?.!,;:)\n",
        "  phrases = re.sub(r\"[^a-zA-Za-яёА-ЯЁ?.!,;:]+\", \" \", phrases) # (а-zA-Za-яёА-ЯЁ) - английский и русский алфавит\n",
        "\n",
        "  phrases = phrases.rstrip().strip() # .rstrip() удаляем пробелы с конца строки = в конце фраз\n",
        "  phrases = \"<start> \" + phrases + \" <end>\" # обозначаем тегами начало и конец строки\n",
        "  return phrases # функция возвращает предобработанные фразы\n",
        "\n",
        "print(\"Фразы после обработки функцией с т.з. пунктуации примут вид: \")\n",
        "print(preprocess_sentence(\"What about you?\"))\n",
        "print(preprocess_sentence(\"А как на счет тебя?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNkit4vTC1mm",
        "outputId": "75c5e142-5a38-4f9b-9851-064a09199515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фразы после обработки функцией с т.з. пунктуации примут вид: \n",
            "<start> What about you ? <end>\n",
            "<start> А как на счет тебя ? <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция создания датасета\n",
        "\n",
        "def create_dataset(path,          # Путь к файлу\n",
        "                   num_examples): # Необходимый размер датасета \n",
        "\n",
        "  # Открываем файл и разбиваем фразы на отдельные строчки\n",
        "  lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  # В каждой строке словаря разделяем английскую фразу от русской, и пропускаем через функцию предобработки данных\n",
        "  word_pairs = [[preprocess_sentence(phrases) for phrases in l.split('\\t')[0:2]]  for l in lines[:num_examples]]\n",
        "\n",
        "  # Вернем пары фраз в виде [по-английски, по-русски]\n",
        "  return zip(*word_pairs)"
      ],
      "metadata": {
        "id": "w5661daEK2Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Взглянем на пример пары фраз на выходе функции:\")\n",
        "\n",
        "english, russian = create_dataset(path_to_file,40000) # Вызовем функцию для демонстрации\n",
        "print(english[-1])                                    # Выведем последний элемент из списка английских фраз\n",
        "print(russian[-1])                                    # Выведем последний элемент из списка русских фраз"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXC89L-nojhY",
        "outputId": "54b9e1ce-56ba-404b-efc6-32a78d38eaad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Взглянем на пример пары фраз на выходе функции:\n",
            "<start> Don t be too long . <end>\n",
            "<start> Не тяните . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим функцию для получения максимльной длины фразы из списка. На вход принимает список фраз. Перебираем список, выбираем максимальное значение."
      ],
      "metadata": {
        "id": "uILX9m_Zq88V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим мини-функцию, возвращающую максимальную длину тензора\n",
        "def max_length(tensor): # на вход принимает тензор (фразы в виде последовательности индексов)\n",
        "  return max(len(t) for t in tensor) # вернет значение максимальной длины его элемента"
      ],
      "metadata": {
        "id": "zDFXIxirqv4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция преобразовывает тексты в последовательности индексов. Используем стандартный токенвайзер из модуля Керас. На вход принимает текст, обучаеь на нем токенайзер. Переводит текст в токеныю Отдает полученные токены и токенайзер. "
      ],
      "metadata": {
        "id": "VB0m_Oi6IHUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция принимает текст одного из языков\n",
        "def tokenize(language):\n",
        "\n",
        "  language_tokenizer = Tokenizer(filters=\"\")         # вызываем класс токенизатора\n",
        "  language_tokenizer.fit_on_texts(language)          # скармливаем ему тексты для обработки и сборки словаря частотности\n",
        "  tensor = language_tokenizer.texts_to_sequences(language) # разбиваем текст фраз на последовательности индексов\n",
        "  tensor = pad_sequences(tensor, padding=\"post\")           # делаем последовательности одинаковой длины, заполняя нулями более короткие фразы\n",
        "\n",
        "  # Возвращаем последовательность индексов (назовем ее тензор) и токенизатор\n",
        "  return tensor, language_tokenizer"
      ],
      "metadata": {
        "id": "XPsKx7PxIeev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция, формирующая готовый датасет, получает на вход путь к файлу с текстами и необходимый размер готового датасета."
      ],
      "metadata": {
        "id": "UlCDNL04NvMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path, num_examples):\n",
        "\n",
        "  # Из исходного текста делаем датасет пар фраз, причем входным языком для НС сделаем русский\n",
        "  targ_language, inp_language = create_dataset(path, num_examples)\n",
        "\n",
        "  # Разбиваем текст на последовательность индексов (назовем ее тензор)\n",
        "  input_tensor, inp_language_tokenizer = tokenize(inp_language)    # формируем тезоры и токенайзер для русского языка\n",
        "  target_tensor, targ_language_tokenizer = tokenize(targ_language) # формируем тезоры и токенайзер для русского языка\n",
        "  \n",
        "  return input_tensor, target_tensor, inp_language_tokenizer, targ_language_tokenizer"
      ],
      "metadata": {
        "id": "7cGe2tRCKH6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формируем датасет заданного объема - 40 000 (в зависимости от приоритета скорости перед качеством обучения), используем ранее написанные функции:"
      ],
      "metadata": {
        "id": "SMDWNtkIQJyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_examples = 40000 # выберем 40 000 строк (всего в базе 360 К строк, в которых по паре фраз)\n",
        "\n",
        "input_tensor, target_tensor, inp_language_tokenizer, targ_language_tokenizer = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Вычислим максимальные длины тензоров для английского и русского языков, используя ранее заданную функцию.\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
        "\n",
        "# Создаем тренировочную и тестовую выборки по формуле 80/20\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "metadata": {
        "id": "JAJYSGCnP3MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим вспомогательную функцию для вывода слова фразы и его индекса. На вход подаются токенайзер и фраза:"
      ],
      "metadata": {
        "id": "9ZIG6bMEZXA-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6tkpocE6X_3"
      },
      "source": [
        "Посмотрим на примеры\n",
        "В первом блоке выведем русскую фразу и ее токен\n",
        "Во втором аглийскую.\n",
        "\n",
        "Далее выводим статистику по датасету"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализируем собранные данные\n",
        "\n",
        "def convert(language_tokenizer,  # Токенайзер\n",
        "            tensor):             # Список индексов слов\n",
        "            \n",
        "  #  Цикл по токенам во фразе\n",
        "  for t in tensor:  \n",
        "    if t!=0:                                                        # Если токен не 0. Т.е. не мусор в конце фразы\n",
        "      print (\"%d ----> %s\" % (t, language_tokenizer.index_word[t])) # Выводи токен и соответствующее слово"
      ],
      "metadata": {
        "id": "P6X_dCeWaa03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2XeriQf5fVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9830b1-c739-4cb0-f6c0-d246dce38995"
      },
      "source": [
        "print (\"Фраза на русском языке; соответствие индекса и слова\")   \n",
        "convert(inp_language_tokenizer, input_tensor_train[0])           # Выведем нулевую пару из русского датасета\n",
        "print ()    \n",
        "\n",
        "print (\"Фраза на английском языке; соответствие индекса и слова\")\n",
        "convert(targ_language_tokenizer, target_tensor_train[0])         # Выведем нулевую пару из агнлийского датасета\n",
        "print ()   \n",
        "                                                      \n",
        "print(\"Рус.яз. тренировочная: \" , len(input_tensor_train), \"фраз; \", \"Анг.яз. тренировочная: \", len(target_tensor_train), \"фраз\")# Выведем статистику по обучающей выборке\n",
        "print(\"Рус.яз. тестовая: \", len(input_tensor_val), \"фраз; \", \"Анг.яз. тестовая: \", len(target_tensor_val), \"фраз\")               # Выведем статистику по тестовой выборке"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фраза на русском языке; соответствие индекса и слова\n",
            "1 ----> <start>\n",
            "8 ----> это\n",
            "4 ----> я\n",
            "15 ----> !\n",
            "2 ----> <end>\n",
            "\n",
            "Фраза на английском языке; соответствие индекса и слова\n",
            "1 ----> <start>\n",
            "8 ----> it\n",
            "9 ----> s\n",
            "16 ----> me\n",
            "32 ----> !\n",
            "2 ----> <end>\n",
            "\n",
            "Рус.яз. тренировочная:  32000 фраз;  Анг.яз. тренировочная:  32000 фраз\n",
            "Рус.яз. тестовая:  8000 фраз;  Анг.яз. тестовая:  8000 фраз\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3AgPtOj83H9"
      },
      "source": [
        "Создаем `tf.data` датасет (Раздел `tf.data.Dataset API` предлагает построить готовый конвейер для обучения моделей)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuEJJsHy9rp5"
      },
      "source": [
        "# Определим постоянные \n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)                     # Укажем что случайно сэмплировать будем по всей длине обучающейся выборки\n",
        "BATCH_SIZE = 256                                          # Указываем размер батча\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE     # Укажем количество шагов в одной эпохе\n",
        "embedding_dim = 256                                       # Размерность эмбеддинга, векторного пространства\n",
        "units = 1024                                              # Задаем размер слоя(количество нейронов в слое) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB82awfvDB6o"
      },
      "source": [
        "# Задаем размер русского словаря\n",
        "vocab_inp_size = len(inp_language_tokenizer.word_index)+1 \n",
        "\n",
        "# Задаем размер английского словаря\n",
        "vocab_tar_size = len(targ_language_tokenizer.word_index)+1 \n",
        "\n",
        "# Создаём датасет из массивов Numpy(рус и анг тренировочные фразы) со случайной подачей тренировочных сэмплов в процессе обучения\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "# Передаем в датасет размер батча и указываем, что если в тренировке последний батч окажется неполным, то опустим его (drop_remainder=True)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDgb_Z7y98ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da227b7-2faf-4e29-b5a8-27f6e2abe743"
      },
      "source": [
        "# Посмотрим на форму примеров полученных батчей\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([256, 12]), TensorShape([256, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZE7WSCKQ4-H"
      },
      "source": [
        "Вспомним нашу схему - сеть состоит из кодера, декодера и блока attention.\n",
        "\n",
        "Давайте начнем оформлять кодер в виде класса. В этом примере кодер состоит из блоков `Embedding` и `GRU`. Обратим внимание на `return_sequences=True`, `return_state=True` - мы требуем состояния кодера на каждом шаге работы. \n",
        "\n",
        "На вход принимает фразу для перевода и начальное состояние. Отдает выход GRU и вектор скрытых состояний"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJwqiGRCDCu1"
      },
      "source": [
        "class Encoder(Model):\n",
        "\n",
        "  # Конструктор класса \n",
        "  def __init__(self, \n",
        "               vocab_size,    # Размер словаря\n",
        "               embedding_dim, # Размер пространсва эмбеддинга\n",
        "               enc_units,     # Число нейронов в GRU\n",
        "               batch_sz):     # Размер батча\n",
        "\n",
        "    super(Encoder, self).__init__()                                   # Даем возможность использовать и исполнять методы класса-родителя в классе потомке \n",
        "    self.batch_sz = batch_sz                                          # Атрибут возвращает размер батча\n",
        "    self.enc_units = enc_units                                        # Атрибут возвращает размер слоя в кодировщике\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim)             # Атрибут эмбеддинга - слой Кераса с размером словаря на входе и с dim=256\n",
        "\n",
        "    # Реккурентной сетью выберем GRU, указываем размер слоя, вывод из слоя в виде последовательностей, \n",
        "    # и метод инициализации весов 'glorot_uniform'(или метод Ксавьера) для упрощения прохождения сигнала при распростр-ии ошибки\n",
        "    self.gru = GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  # Метод принимает входную фразу и начальное состояние\n",
        "  def call(self, \n",
        "           x,       # Входная фраза\n",
        "           hidden): # Начальное энкодера\n",
        "    x = self.embedding(x) # входящие тензоры преобразовываются в эмбеддинг\n",
        "    output, state = self.gru(x, initial_state = hidden) #затем пропускаются через GRU и получаем выход + новое состояние\n",
        "\n",
        "    # Выход сети GRU и состояние на выходе\n",
        "    return output, state \n",
        "\n",
        "  # Создаем метод инициализации состояний на скрытых слоях\n",
        "  def initialize_hidden_state(self):\n",
        "\n",
        "    # Вернем тензор из нулей размер батча на размер слоя, итсполбьзуем как начальное состояние энкодера\n",
        "    return tf.zeros((self.batch_sz, self.enc_units)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BoTUmLPSsha"
      },
      "source": [
        "Создаем экземпляр класса Encoder. Используем далее как готовый модуль при построении модели сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgR4bQIKDFXF"
      },
      "source": [
        "# Создадим модель кодировщика по уже заданным параметрам \n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXH74Z-B_Mmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5c2307-27df-48af-9137-4a1b6788f13b"
      },
      "source": [
        "# Подадим в качестве примера какой-то сэмпл(Тензор[64, 12]) на вход Encoder'у и визуализируем, что получим\n",
        "sample_hidden = encoder.initialize_hidden_state() #инициализируем начальное скрытое состояние\n",
        "\n",
        "# Даем Encoder'у сэмпл и начальное состояние, и получим выход из сети GRU и состояние на выходе (вызывается метод call класса Encoder)\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Размеры выхода из кодировщика: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Размеры скрытого состояния: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеры выхода из кодировщика: (batch size, sequence length, units) (256, 12, 1024)\n",
            "Размеры скрытого состояния: (batch size, units) (256, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKRwq1d-S86R"
      },
      "source": [
        "Создадим класс модуля `attenton`, как предписывал Bahdanau. Разбор работы данного модуля мы прошли чуть ранее. На входе состояния кодера `hidden_state` и `values` - выход предыдущего декодера с предыдущего шага. На выходе вектор контекста и веса `attention`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWDTK8eqDHu0"
      },
      "source": [
        "class BahdanauAttention(Model): # Название класса именем создателя механизма Дмитрия Богданова(Bahdanau)\n",
        "\n",
        "  # Создаем конструктор класса\n",
        "  def __init__(self, \n",
        "               units):                        # Число нейронов \n",
        "\n",
        "    super(BahdanauAttention, self).__init__() # Даем возможность использовать и исполнять методы класса-родителя в классе потомке\n",
        "    self.W1 = Dense(units)                    # Создаем Dense с заданным числом нейронов\n",
        "    self.W2 = Dense(units)                    # Создаем Dense с заданным числом нейронов\n",
        "    self.V =  Dense(1)                        # Создаем Dense с числом нейронов =1\n",
        "\n",
        "  # Метод принимает состояние и выход энкодера ----------------------------------\n",
        "  \n",
        "  def call(self, \n",
        "           hidden_state, # Состояние энкодера\n",
        "           values):      # Выход энкодера\n",
        "    # Форма состояния на скрытом слое (batch_size, hidden size)\n",
        "    # Форму состояния на каждом такте увеличим до (batch_size, 1, hidden size)\n",
        "    # Добавляем это для того, чтобы получить оценку\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden_state, 1)\n",
        "\n",
        "    # Форма оценки score (размер батча, макс.длина слов на входе, 1), однёрка в конце, чтобы применить self.V\n",
        "    # До применения self.V оценка была бы (размер батча, макс.длина слов на входе, количество нейронов в слое)\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # К полученной оценке применим Софтмакс, который покажет вероятность полезности от 0 до 1 для каждого слова в фразе для декодера\n",
        "    # Форма оценки score - (размер батча, макс.длина слов на входе, 1); Софтмакс применяем к оси \"макс.длина слов\"\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # Построим вектор контекста \n",
        "    context_vector = attention_weights * values # Веса внимания перемножим со значениями(выхода из кодировщика)\n",
        "    # Сумму также применяем по оси \"макс.длина слов на входе\"\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1) # Размеры вектора контекста после суммирования будут (размер батча, размер слоя)\n",
        "\n",
        "    # Возвращает вектор контекста и веса внимания\n",
        "    return context_vector, attention_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8sMHv-wU_oD"
      },
      "source": [
        "Создадим экземпляр класса BahdanauAttention. Здесь 10 - число нейронов в первом dense слое"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUv-DSsDDKGl",
        "outputId": "8b285263-079f-46b2-b6be-1b6eb3ba62c1"
      },
      "source": [
        "# Проверим, как работает слой\n",
        "attention_layer = BahdanauAttention(10)\n",
        "\n",
        "# Подадим на вход слою внимания выход из Encodera и его состояние, и получим значение и веса внимания\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Размеры значения внимания: (размер батча, размер слоя) {}\".format(attention_result.shape))\n",
        "print(\"Размеры весов внимания: (размер батча, длина последовательности, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеры значения внимания: (размер батча, размер слоя) (256, 1024)\n",
            "Размеры весов внимания: (размер батча, длина последовательности, 1) (256, 12, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK4api1fVM3N"
      },
      "source": [
        "Создаем класс декодера с attention. Декодер принимает обущающую фразу, прогоняет через embedding. Далее склеивает с вектором контента и подает на GRU.\n",
        "На выходе dense слой с числом нейронов равному размеру словаря."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZHTEgDoDNBC"
      },
      "source": [
        "class Decoder(Model):\n",
        "\n",
        "  # Создадим конструктор класса\n",
        "  def __init__(self,   \n",
        "               vocab_size,    # Размер словаря\n",
        "               embedding_dim, # Размерность пространства эмбеддинга\n",
        "               dec_units,     # Число нейронов в GRU\n",
        "               batch_sz):     # Размер батча\n",
        "    super(Decoder, self).__init__()                       # Даем возможность использовать и исполнять методы класса-родителя в классе потомке \n",
        "    self.batch_sz = batch_sz                              # Атрибут возвращает размер батча\n",
        "    self.dec_units = dec_units                            # Атрибут возвращает размер слоя в декодере(кол-во нейронов)\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim) # Атрибут эмбеддинга - слой Кераса с размером словаря на входе и (dim=256) на выходе\n",
        "\n",
        "    # Реккурентной сетью выберем GRU, указываем размер слоя, вывод из слоя в виде последовательностей, \n",
        "    # и метод инициализации весов 'glorot_uniform'(или метод Ксавьера) для упрощения прохождения сигнала при распростр-ии ошибки    \n",
        "    self.gru = GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    self.fc = Dense(vocab_size) # Атрибут вызовет полносвязный слой с размером словаря\n",
        "\n",
        "    self.attention = BahdanauAttention(self.dec_units) #атрибут подключит механизм внимания, описанный ранее\n",
        "\n",
        "\n",
        "  def call(self, \n",
        "           x,           # Начальный токен\n",
        "           hidden,      # Состояние  энкодера\n",
        "           enc_output): # Выход энкодера\n",
        "\n",
        "    # Enc_output размеры (batch_size, max_length, hidden_size - размер батча, макс.длина фраз, разм.скр.слоя)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # Входящий тензор слова пропускаем через эмбеддинг (получаем размеры batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # Дальше конкатенируем с вектором контекста (получаем размеры batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # Сконкатенированный вектор передаем  в GRU и получаем выход с декодера и состояние\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # Output размеры (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # Пропускаем через полносвязный слой\n",
        "    x = self.fc(output) #output размеры (batch_size, vocab)\n",
        "\n",
        "    # Вернем выходную фразу, вектор состояния, веса внимания\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b1yEPu3DPqp",
        "outputId": "8d62092d-96c5-4d0c-8539-0c6656f54135"
      },
      "source": [
        "# Проверим работу декодера, подав на вход случайный массив с нужной размерностью\n",
        "# Создали декодер с параметрами(размер анг.словаря, размерность эмбеддинга, кол-во нейронов, размер батча)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# Подаём на вход случайный массив с нужной размерностью, состояние и выход с кодировщика\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((256, 1)), sample_hidden, sample_output)\n",
        "print ('Размер выхода с декодера: (размер батча, размер словаря) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер выхода с декодера: (размер батча, размер словаря) (256, 4271)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h7uiC6LDVRK"
      },
      "source": [
        "# Выбираем оптимайзер Adam\n",
        "optimizer = Adam() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qw4cgWJlDgW"
      },
      "source": [
        "Наша функция потерь называется  `loss_function` - сначала она уберет из расчетов нулевые элементы в истинной и предсказанной фразе. \n",
        "\n",
        "Длина фразы может быть меньше максимально допустимой или фраза может быть сформирована не полностью. Просто не будем учитывать мусор в конце фразы.\n",
        "\n",
        "Далее применим стандартную для Kerasa функцию потерь  SparseCategoricalCrossentropy. По сравнению CategoricalCrossentropy работает также, но позволяет нам не хранить слова в виде OneHotEncoding, что существенно экономить память.\n",
        "\n",
        "На выходе получаем среднее значение потерь:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YVxy08qDR-5"
      },
      "source": [
        "# Используем SparseCategoricalCrossentropy, к-я может работать с некатегориальными лейблами\n",
        "loss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none') # Выбираем функцию потерь\n",
        "\n",
        "def loss_function(real, pred):                       # Запишем функцию потерь, на вход подаем фактический и предсказанный результат\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) # Найдем маску, которая уберет нулевые значения индексов в конце фразы\n",
        "  loss_ = loss_object(real, pred)                    # Фактические и предсказанные результаты передаем в SparseCategoricalCrossentropy и получаем ошибку\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)            # Согласуем тип маски с типом потерь\n",
        "  loss_ *= mask                                      # Накидываем \"маску\" которая оставит для работы ненулевые значения\n",
        "  \n",
        "  # Вернем reduce_mean - среднее любого выбранного тензора\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHr21E05q0NN"
      },
      "source": [
        "# Сохраняем процесс обучения модели чекпоинтами тензорфлоу\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'                                               # Даем ссылку на директорию\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")                                # Добавляем префикс \"ckpt\"\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder) # Сохраняем состояния/показатели оптимизатора и моделей"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFb7r1SjYf7i"
      },
      "source": [
        "Создадим функцию для обучения модели. На входе - исходная фраза, конечная фраза, начальное состояния кодера. Подаем сразу батчем. На выходе потери на этом батче"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCNvA66Jq7nE"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp,         # Входная фраза\n",
        "               targ,        # Точный перевод\n",
        "               enc_hidden): # Состояния энкодера\n",
        "\n",
        "  # Создаем переменную, в которую будем записывать ошибку\n",
        "  loss = 0                             \n",
        "\n",
        "  # Все операции по вычислению градиента записываются на ленту(tape) и мы получаем к ним доступ\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    # Передаем тензор и начальное состояние в кодировщик и получим выход и состояние на выходе\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    # Передадим это состояние декодеру\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    # Передаем в качестве входа в декодер индекс токена \"<start>\"\n",
        "    dec_input = tf.expand_dims([targ_language_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Техника \"Teacher forcing\" - подаем предыдущее выходное слово на вход следущего в декодере. Targ.shape[64, 9]\n",
        "\n",
        "    for t in range(1, targ.shape[1]): #для каждого слова из английской фразы\n",
        "\n",
        "      # Передаем в обработку декодеру начальный токен, состояние на выходе из кодера, и выход из кодера\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output) # Получаем от декодера предсказание и обновленное состояние\n",
        "\n",
        "      # Обновляем ошибку для текущих предсказаний\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # Используем \"Teacher forcing\"\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  # Получаем ошибку на батче . Targ.shape[64, 9]. Делим на 9\n",
        "  batch_loss = (loss / int(targ.shape[1])) \n",
        "\n",
        "  # Создаем список переменных, для которых TensorFlow будет вычислять градиенты\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables # создаем переменные, для которых TensorFlow будет вычислять градиенты\n",
        "\n",
        "  # Отслеживаем градиент\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  # Корректируем веса\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Функция обучения вернет ошибку на батче\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GwOr3sEYiW_"
      },
      "source": [
        "Обучаем сеть. 30 эпох. На каждой эпохе прогоняем весь набор данных через функцию обучения. Считаем лоссы. Сохраняем статистику каждые 10 эпох"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Tpy6Cxq-V3",
        "outputId": "298772db-ca77-4997-9d25-1472c681acde"
      },
      "source": [
        "EPOCHS = 30 # устанавливаем количество эпох\n",
        "\n",
        "for epoch in range(EPOCHS): # Цикл по каждой эпохе\n",
        "  start = time.time() # Запомним время начала эпохи\n",
        "\n",
        "  progbar = tf.keras.utils.Progbar(target=steps_per_epoch, stateful_metrics=[\n",
        "                                     'batch_loss'], unit_name='batch')        # Создадим индикатор прогресс обучения\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state() # Задаем начальное состояние на скрытом слое encodera \n",
        "  total_loss = 0                                 # Начальное значение итоговой ошибки\n",
        "\n",
        "  # Для батча, входного и выходного тензора на каждом шаге эпохи\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden) # Передадим в функцию тензоры и состояние в кодировщике, обучим и получим ошибку на батче\n",
        "    total_loss += batch_loss                       # Добавим ее в итоговую ошибку\n",
        "    progbar.update(                                # Обновим состояние индикатора обучения\n",
        "            batch + 1, values=[('batch_loss', batch_loss)])\n",
        "\n",
        "\n",
        "  # Каждые 10 эпох будем сохранять чекпоинты\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  # Выведем показатели после каждой эпохи\n",
        "  print('Эпоха {} Ошибка {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch)) # Выведем номер эпохи и потери\n",
        "  print('Время на 1 эпоху {} сек'.format(round(time.time() - start), 1))          # Выведем длительность обучения этой эпохи"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 35s 158ms/batch - batch_loss: 1.9895\n",
            "Эпоха 1 Ошибка 2.4738\n",
            "Время на 1 эпоху 41 сек\n",
            "125/125 [==============================] - 17s 136ms/batch - batch_loss: 1.5108\n",
            "Эпоха 2 Ошибка 1.6893\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 138ms/batch - batch_loss: 1.2970\n",
            "Эпоха 3 Ошибка 1.3577\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 137ms/batch - batch_loss: 1.0794\n",
            "Эпоха 4 Ошибка 1.1341\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 18s 142ms/batch - batch_loss: 0.9483\n",
            "Эпоха 5 Ошибка 0.9418\n",
            "Время на 1 эпоху 18 сек\n",
            "125/125 [==============================] - 17s 138ms/batch - batch_loss: 0.7272\n",
            "Эпоха 6 Ошибка 0.7685\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 135ms/batch - batch_loss: 0.6205\n",
            "Эпоха 7 Ошибка 0.6184\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 135ms/batch - batch_loss: 0.4942\n",
            "Эпоха 8 Ошибка 0.4907\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 138ms/batch - batch_loss: 0.3708\n",
            "Эпоха 9 Ошибка 0.3865\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 139ms/batch - batch_loss: 0.3204\n",
            "Эпоха 10 Ошибка 0.3015\n",
            "Время на 1 эпоху 18 сек\n",
            "125/125 [==============================] - 17s 138ms/batch - batch_loss: 0.2759\n",
            "Эпоха 11 Ошибка 0.2364\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 137ms/batch - batch_loss: 0.1940\n",
            "Эпоха 12 Ошибка 0.1849\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 17s 135ms/batch - batch_loss: 0.1696\n",
            "Эпоха 13 Ошибка 0.1469\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 140ms/batch - batch_loss: 0.1353\n",
            "Эпоха 14 Ошибка 0.1190\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 138ms/batch - batch_loss: 0.1172\n",
            "Эпоха 15 Ошибка 0.1006\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 17s 135ms/batch - batch_loss: 0.1209\n",
            "Эпоха 16 Ошибка 0.0864\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 138ms/batch - batch_loss: 0.0913\n",
            "Эпоха 17 Ошибка 0.0780\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 138ms/batch - batch_loss: 0.0870\n",
            "Эпоха 18 Ошибка 0.0699\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 136ms/batch - batch_loss: 0.0809\n",
            "Эпоха 19 Ошибка 0.0647\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 136ms/batch - batch_loss: 0.0767\n",
            "Эпоха 20 Ошибка 0.0618\n",
            "Время на 1 эпоху 18 сек\n",
            "125/125 [==============================] - 17s 137ms/batch - batch_loss: 0.0675\n",
            "Эпоха 21 Ошибка 0.0590\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 137ms/batch - batch_loss: 0.0646\n",
            "Эпоха 22 Ошибка 0.0571\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 138ms/batch - batch_loss: 0.0765\n",
            "Эпоха 23 Ошибка 0.0540\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 139ms/batch - batch_loss: 0.0701\n",
            "Эпоха 24 Ошибка 0.0526\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 139ms/batch - batch_loss: 0.0579\n",
            "Эпоха 25 Ошибка 0.0520\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 137ms/batch - batch_loss: 0.0588\n",
            "Эпоха 26 Ошибка 0.0514\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 138ms/batch - batch_loss: 0.0584\n",
            "Эпоха 27 Ошибка 0.0549\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 137ms/batch - batch_loss: 0.0706\n",
            "Эпоха 28 Ошибка 0.0561\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 138ms/batch - batch_loss: 0.0709\n",
            "Эпоха 29 Ошибка 0.0543\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 137ms/batch - batch_loss: 0.0580\n",
            "Эпоха 30 Ошибка 0.0518\n",
            "Время на 1 эпоху 18 сек\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzCVG3YhYj0O"
      },
      "source": [
        "Данная функция собирает модель кодера, декодера и attention для работы в режиме перевода (предсказания).\n",
        "\n",
        "На входе переводимое русское предложение, на выходе его английский перевод"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX4koS1irAnJ"
      },
      "source": [
        "def evaluate(sentence):\n",
        "\n",
        "    # Создаем начальные настройки графика внимания\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp)) \n",
        "    \n",
        "    # Предобрабатываем предложение\n",
        "    sentence = preprocess_sentence(sentence) \n",
        "\n",
        "    inputs = [inp_language_tokenizer.word_index[i] for i in sentence.split(' ')]   # Преобразовываем в послед-ть индексов\n",
        "    inputs = pad_sequences([inputs], maxlen=max_length_inp, padding='post')        # Делаем паддинг\n",
        "    inputs = tf.convert_to_tensor(inputs)                                          # Конвертируем в тф тензор\n",
        "\n",
        "    result = ''                                                                    # Сюда запишем результат\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]                                                # Задаем начальное состояние\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)                                  # Передаем его и входной тензор и получаем выход с кодера и состояние\n",
        "\n",
        "    dec_hidden = enc_hidden                                                        # Состояние кодера передаем в декодер\n",
        "    dec_input = tf.expand_dims([targ_language_tokenizer.word_index['<start>']], 0) # Передаем на вход декодеру <start> в виде индекса\n",
        "\n",
        "    for t in range(max_length_targ):                                               # Идем по макс.длине фраз выходного языка(анг)\n",
        "        # Прогоняем через декодер входящий тензор, состояние с выхода кодера, выход с кодера\n",
        "        # Получаем результат предсказания, обновленное состояние, и веса внимания\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        # Сохраняем веса внимания для графика\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        # Аргмаксом вытаскиваем предсказанное слово\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        # Результат конвертируем из индекса в слово и сохраняем в result = ''\n",
        "        result += targ_language_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        # Если предсказанное слово - <end>, то останавливаемся, возвращаем результаты, выводим на графике\n",
        "        if targ_language_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # Педсказанное значение подается обратно в модель\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    # Вернем перевод, входную фразу и веса внимания\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP7AnPSBcC9D"
      },
      "source": [
        "Нам интересно как связаны слова в исходной фразе и в ее переведе. Функция отрисовывает веса внимания в виде 2D матрицы, соотносит каждую пару  слов  ее весом  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It8ZVMbHrFYj"
      },
      "source": [
        "def plot_attention(attention,           # Веса внимания\n",
        "                   sentence,            # Исходная фраза\n",
        "                   predicted_sentence): # Предсказаные перевод\n",
        "  \n",
        "    fig = plt.figure(figsize=(10,10))                                   # Зададим размер \n",
        "    ax = fig.add_subplot(1, 1, 1)                                       # Добавим 1 картинку\n",
        "    ax.matshow(attention, cmap='viridis')                               # Нарисуем 2d матрицу\n",
        "    fontdict = {'fontsize': 14}                                         # Зададим размер надписей\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90) # Добавим надпись по горизонтальной оси\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)    # Добавим надпись по вертикальной оси\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))               # Зададим форматирование делений на осях графиков\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))               # Зададим форматирование делений на осях графиков\n",
        "    plt.show()                                                          # Отрисуем изображение"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXrttZ_Ccd--"
      },
      "source": [
        "Соберем написанные ранее функции вместе. Будем переводить фразы и строить матрицы внимания(attention)  - смотреть связи слов в предложении"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7afFCab-N_Xf"
      },
      "source": [
        "Создадим функцию для перевода фраз с визуализацией матрицы внимания"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH8G96tWrHmn"
      },
      "source": [
        "def translate(sentence): # Функция принимает предложение и выводит результат с визуализацией\n",
        "    result, sentence, attention_plot = evaluate(sentence)  # Отдадим фразу. Получим перевод, входную фразу,  веса внимания\n",
        "\n",
        "    print('Входящая фраза: %s' % (sentence))          # Выведем входную фразу \n",
        "    print('Предсказанный перевод: {}'.format(result)) # Выведем полученный перевод\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))] # Возьмем весы внимания, только для слов во фразах. Хвосты не смотрим\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))              # Выведем веса внимания"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vsbPAP5rJle",
        "outputId": "abc948ff-0e52-4b24-b08e-d34cdc3b139a"
      },
      "source": [
        "# Воспроизведём последний сохранённый чекпоинт\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fedcb7d72e0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcH-0rkFPNeU"
      },
      "source": [
        "И, наконец, переведём предложение и выведем визуализацию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "bBi0SqkJrMeK",
        "outputId": "9a91ecf0-66f7-4d68-a801-4f41cf62c995"
      },
      "source": [
        "translate('давайте дружить')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> давайте дружить <end>\n",
            "Предсказанный перевод: let s be long . <end> \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-a16ba1e9d77a>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90) # Добавим надпись по горизонтальной оси\n",
            "<ipython-input-32-a16ba1e9d77a>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)    # Добавим надпись по вертикальной оси\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "X2VVb9LHrOv8",
        "outputId": "1c81dd55-edd5-450d-c326-20ef118c879e"
      },
      "source": [
        "translate('у тебя всё хорошо')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> у тебя всё хорошо <end>\n",
            "Предсказанный перевод: you re so good . <end> \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-a16ba1e9d77a>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90) # Добавим надпись по горизонтальной оси\n",
            "<ipython-input-32-a16ba1e9d77a>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)    # Добавим надпись по вертикальной оси\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "uWC8-1DDrPQ1",
        "outputId": "bbf3d95b-b751-4b58-f7e2-2f107c54bac9"
      },
      "source": [
        "translate('у тебя всё хорошо?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> у тебя всё хорошо ? <end>\n",
            "Предсказанный перевод: do you have it right ? <end> \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-a16ba1e9d77a>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90) # Добавим надпись по горизонтальной оси\n",
            "<ipython-input-32-a16ba1e9d77a>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)    # Добавим надпись по вертикальной оси\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sahW4uQD51Rv"
      },
      "source": [
        "Что можно сказать. Как переводчик сеть не очень. Но связи слов в предложениях уже находит"
      ]
    }
  ]
}