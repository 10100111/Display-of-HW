{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10100111/Display-of-HW1/blob/main/59_Pro_%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D1%8F_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание Pro\n",
        "\n",
        "Макс 10 баллов\n",
        "\n",
        "Попробуйте улучшить текущий скрипт чат-бота, внедрив блок кода для присвоения словам вне словаря (out-of-vocabulary) метки «unknown» так, чтобы, встретив в запросе незнакомое слово, исполнение кода не останавливалось, а продолжалось, игнорируя «unknown» слова."
      ],
      "metadata": {
        "id": "LR3SEK1FE-NY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g-tBeFP38Rp"
      },
      "source": [
        "# **Import библиотек**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=10s\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j1Wpkvc3Q2s"
      },
      "source": [
        "from google.colab import files # модуль для загрузки файлов в colab\n",
        "import numpy as np # библиотека для работы с массивами данных\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model # из кераса подгружаем абстрактный класс базовой модели, метод загрузки предобученной модели\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input # из кераса загружаем необходимые слои для нейросети\n",
        "from tensorflow.keras.optimizers import RMSprop, Adadelta # из кераса загружаем выбранный оптимизатор\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # загружаем метод ограничения последовательности заданной длиной\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # загружаем токенизатор кераса для обработки текста\n",
        "from tensorflow.keras import utils # загружаем утилиты кераса для one hot кодировки\n",
        "from tensorflow.keras.utils import plot_model # удобный график для визуализации архитектуры модели\n",
        "\n",
        "import yaml # импортируем модуль для удобной работы с файлами"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "200dSPOYZE7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eebfa9a0-a385-4242-b97d-5b47af50736f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxdi0Fqeg1LH"
      },
      "source": [
        "# **Парсинг данных**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=87s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEA8TR_oerov"
      },
      "source": [
        "######################\n",
        "# Открываем файл с диалогами\n",
        "######################\n",
        "corpus = open('/content/drive/MyDrive/Базы/Диалоги(рассказы)_censored.yml', 'r') # открываем файл с диалогами в режиме чтения\n",
        "document = yaml.safe_load(corpus) # загружаем файл *глоссарий\n",
        "conversations = document['разговоры'] # загружаем диалоги из файла и заносим в conversations \n",
        "print('Количество пар вопрос-ответ : {}'.format(len(conversations)))\n",
        "print('Пример диалога : {}'.format(conversations[123]))\n",
        "corpus.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYg8z8Vj76bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12edf356-627b-443e-d16c-3f8f8b141d55"
      },
      "source": [
        "######################\n",
        "# Разбираем вопросы-ответы с проставлением тегов ответам\n",
        "######################\n",
        "# Собираем вопросы и ответы в списки\n",
        "questions = list() # здесь будет список вопросов\n",
        "answers = list() # здесь будет список ответов\n",
        "\n",
        "# В каждом диалоге берем фразу и добавляем в лист\n",
        "# Если в ответе не одна фраза - то сцепляем сколько есть\n",
        "for con in conversations: # для каждой пары вопрос-ответ\n",
        "  if len(con) > 2 : # если ответ содержит более двух предложений (кол-во реплик, кол-во вариантов ответа)\n",
        "    questions.append(con[0]) # то вопросительную реплику отправляем в список вопросов\n",
        "    replies = con[1:] # а ответную составляем из последующих строк\n",
        "    ans = '' # здесь соберем ответ\n",
        "    for rep in replies: # каждую реплику в ответной реплике\n",
        "      ans += ' ' + rep \n",
        "    answers.append(ans) #добавим в список ответов\n",
        "  elif len(con)> 1: # если на 1 вопрос приходится 1 ответ\n",
        "    questions.append(con[0]) # то вопросительную реплику отправляем в список вопросов\n",
        "    answers.append(con[1]) # а ответную в список ответов\n",
        "\n",
        "# Очищаем строки с неопределенным типом ответов\n",
        "answersCleaned = list()\n",
        "for i in range(len(answers)):\n",
        "  if type(answers[i]) == str:\n",
        "    answersCleaned.append(answers[i]) #если тип - строка, то добавляем в ответы\n",
        "  else:\n",
        "    questions.pop(i) # если не строка, то ответ не добавился, и плюс убираем соответствующий вопрос\n",
        "\n",
        "# Сделаем теги-метки для начала и конца ответов\n",
        "answers = list()\n",
        "for i in range(len(answersCleaned)):\n",
        "  answers.append( '<START> ' + answersCleaned[i] + ' <END>' )\n",
        "\n",
        "# Выведем обновленные данные на экран\n",
        "print('Вопрос : {}'.format(questions[200]))\n",
        "print('Ответ : {}'.format(answers[200]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вопрос : Около сотни...\n",
            "Ответ : <START> Точнее! <END>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvn1jvRd9tep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc8aa91-10ed-4102-bcee-6cd71c483516"
      },
      "source": [
        "######################\n",
        "# Подключаем керасовский токенизатор и собираем словарь индексов\n",
        "######################\n",
        "tokenizer = Tokenizer(oov_token='unknown') # присваиваем словам вне словаря метку 'unknown'\n",
        "tokenizer.fit_on_texts(questions + answers) # загружаем в токенизатор список вопросов-ответов для сборки словаря частотности\n",
        "vocabularyItems = list(tokenizer.word_index.items()) # список с cодержимым словаря\n",
        "vocabularySize = len(vocabularyItems)+1 # размер словаря\n",
        "print( 'Фрагмент словаря : {}'.format(vocabularyItems[:50]))\n",
        "print( 'Размер словаря : {}'.format(vocabularySize))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фрагмент словаря : [('unknown', 1), ('start', 2), ('end', 3), ('что', 4), ('не', 5), ('я', 6), ('а', 7), ('ты', 8), ('это', 9), ('да', 10), ('в', 11), ('нет', 12), ('как', 13), ('и', 14), ('вы', 15), ('ну', 16), ('с', 17), ('на', 18), ('же', 19), ('так', 20), ('он', 21), ('у', 22), ('кто', 23), ('где', 24), ('все', 25), ('мы', 26), ('то', 27), ('мне', 28), ('тебя', 29), ('меня', 30), ('здесь', 31), ('еще', 32), ('почему', 33), ('о', 34), ('тебе', 35), ('там', 36), ('есть', 37), ('его', 38), ('за', 39), ('куда', 40), ('вот', 41), ('ничего', 42), ('вас', 43), ('знаю', 44), ('чем', 45), ('но', 46), ('она', 47), ('они', 48), ('ли', 49), ('чего', 50)]\n",
            "Размер словаря : 15093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# протестируем словарь частотности\n",
        "print('Интересующее слово имет индекс: ', tokenizer.word_index[input('Уточните слово: ')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_aamuwtbALI",
        "outputId": "9ef76e4e-e2af-4e85-e10a-674f0a597fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Уточните слово: unknown\n",
            "Интересующее слово имет индекс:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabularyItems"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfmZCsrIt9kn",
        "outputId": "617528b0-e830-444f-bc95-ae640e94d9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('unknown', 1),\n",
              " ('start', 2),\n",
              " ('end', 3),\n",
              " ('что', 4),\n",
              " ('не', 5),\n",
              " ('я', 6),\n",
              " ('а', 7),\n",
              " ('ты', 8),\n",
              " ('это', 9),\n",
              " ('да', 10),\n",
              " ('в', 11),\n",
              " ('нет', 12),\n",
              " ('как', 13),\n",
              " ('и', 14),\n",
              " ('вы', 15),\n",
              " ('ну', 16),\n",
              " ('с', 17),\n",
              " ('на', 18),\n",
              " ('же', 19),\n",
              " ('так', 20),\n",
              " ('он', 21),\n",
              " ('у', 22),\n",
              " ('кто', 23),\n",
              " ('где', 24),\n",
              " ('все', 25),\n",
              " ('мы', 26),\n",
              " ('то', 27),\n",
              " ('мне', 28),\n",
              " ('тебя', 29),\n",
              " ('меня', 30),\n",
              " ('здесь', 31),\n",
              " ('еще', 32),\n",
              " ('почему', 33),\n",
              " ('о', 34),\n",
              " ('тебе', 35),\n",
              " ('там', 36),\n",
              " ('есть', 37),\n",
              " ('его', 38),\n",
              " ('за', 39),\n",
              " ('куда', 40),\n",
              " ('вот', 41),\n",
              " ('ничего', 42),\n",
              " ('вас', 43),\n",
              " ('знаю', 44),\n",
              " ('чем', 45),\n",
              " ('но', 46),\n",
              " ('она', 47),\n",
              " ('они', 48),\n",
              " ('ли', 49),\n",
              " ('чего', 50),\n",
              " ('вам', 51),\n",
              " ('бы', 52),\n",
              " ('может', 53),\n",
              " ('по', 54),\n",
              " ('к', 55),\n",
              " ('из', 56),\n",
              " ('нибудь', 57),\n",
              " ('надо', 58),\n",
              " ('сейчас', 59),\n",
              " ('зачем', 60),\n",
              " ('нас', 61),\n",
              " ('конечно', 62),\n",
              " ('хорошо', 63),\n",
              " ('можно', 64),\n",
              " ('сэр', 65),\n",
              " ('тоже', 66),\n",
              " ('случилось', 67),\n",
              " ('только', 68),\n",
              " ('если', 69),\n",
              " ('тогда', 70),\n",
              " ('тут', 71),\n",
              " ('когда', 72),\n",
              " ('очень', 73),\n",
              " ('теперь', 74),\n",
              " ('быть', 75),\n",
              " ('уже', 76),\n",
              " ('значит', 77),\n",
              " ('нам', 78),\n",
              " ('дело', 79),\n",
              " ('такое', 80),\n",
              " ('откуда', 81),\n",
              " ('будет', 82),\n",
              " ('товарищ', 83),\n",
              " ('хочешь', 84),\n",
              " ('их', 85),\n",
              " ('сколько', 86),\n",
              " ('от', 87),\n",
              " ('какой', 88),\n",
              " ('делать', 89),\n",
              " ('могу', 90),\n",
              " ('ее', 91),\n",
              " ('было', 92),\n",
              " ('спасибо', 93),\n",
              " ('просто', 94),\n",
              " ('для', 95),\n",
              " ('правда', 96),\n",
              " ('порядке', 97),\n",
              " ('разве', 98),\n",
              " ('кого', 99),\n",
              " ('сам', 100),\n",
              " ('знаешь', 101),\n",
              " ('или', 102),\n",
              " ('сегодня', 103),\n",
              " ('точно', 104),\n",
              " ('мой', 105),\n",
              " ('тобой', 106),\n",
              " ('ладно', 107),\n",
              " ('был', 108),\n",
              " ('ни', 109),\n",
              " ('этого', 110),\n",
              " ('до', 111),\n",
              " ('ж', 112),\n",
              " ('нужно', 113),\n",
              " ('сюда', 114),\n",
              " ('ведь', 115),\n",
              " ('ага', 116),\n",
              " ('хочу', 117),\n",
              " ('ему', 118),\n",
              " ('сказал', 119),\n",
              " ('этом', 120),\n",
              " ('зовут', 121),\n",
              " ('лучше', 122),\n",
              " ('думаю', 123),\n",
              " ('будем', 124),\n",
              " ('больше', 125),\n",
              " ('верно', 126),\n",
              " ('сказать', 127),\n",
              " ('со', 128),\n",
              " ('пока', 129),\n",
              " ('себя', 130),\n",
              " ('раз', 131),\n",
              " ('такой', 132),\n",
              " ('кажется', 133),\n",
              " ('командир', 134),\n",
              " ('знаете', 135),\n",
              " ('мной', 136),\n",
              " ('много', 137),\n",
              " ('хотите', 138),\n",
              " ('думаешь', 139),\n",
              " ('чтобы', 140),\n",
              " ('видишь', 141),\n",
              " ('можешь', 142),\n",
              " ('пошли', 143),\n",
              " ('ах', 144),\n",
              " ('один', 145),\n",
              " ('именно', 146),\n",
              " ('видел', 147),\n",
              " ('об', 148),\n",
              " ('капитан', 149),\n",
              " ('уж', 150),\n",
              " ('скоро', 151),\n",
              " ('совсем', 152),\n",
              " ('всего', 153),\n",
              " ('мама', 154),\n",
              " ('этот', 155),\n",
              " ('пойдем', 156),\n",
              " ('какие', 157),\n",
              " ('какое', 158),\n",
              " ('туда', 159),\n",
              " ('ним', 160),\n",
              " ('давай', 161),\n",
              " ('мистер', 162),\n",
              " ('ка', 163),\n",
              " ('должен', 164),\n",
              " ('знать', 165),\n",
              " ('дела', 166),\n",
              " ('твой', 167),\n",
              " ('пожалуйста', 168),\n",
              " ('была', 169),\n",
              " ('него', 170),\n",
              " ('какая', 171),\n",
              " ('два', 172),\n",
              " ('иди', 173),\n",
              " ('даже', 174),\n",
              " ('потому', 175),\n",
              " ('давно', 176),\n",
              " ('э', 177),\n",
              " ('дома', 178),\n",
              " ('вами', 179),\n",
              " ('господин', 180),\n",
              " ('кем', 181),\n",
              " ('привет', 182),\n",
              " ('нельзя', 183),\n",
              " ('далеко', 184),\n",
              " ('эти', 185),\n",
              " ('ещё', 186),\n",
              " ('похоже', 187),\n",
              " ('домой', 188),\n",
              " ('неужели', 189),\n",
              " ('оно', 190),\n",
              " ('одна', 191),\n",
              " ('хотел', 192),\n",
              " ('без', 193),\n",
              " ('вижу', 194),\n",
              " ('буду', 195),\n",
              " ('про', 196),\n",
              " ('готов', 197),\n",
              " ('будешь', 198),\n",
              " ('уверен', 199),\n",
              " ('сделал', 200),\n",
              " ('ваше', 201),\n",
              " ('моя', 202),\n",
              " ('м', 203),\n",
              " ('завтра', 204),\n",
              " ('черт', 205),\n",
              " ('всё', 206),\n",
              " ('ней', 207),\n",
              " ('какого', 208),\n",
              " ('время', 209),\n",
              " ('через', 210),\n",
              " ('под', 211),\n",
              " ('отсюда', 212),\n",
              " ('нравится', 213),\n",
              " ('эй', 214),\n",
              " ('делаешь', 215),\n",
              " ('человек', 216),\n",
              " ('нормально', 217),\n",
              " ('никто', 218),\n",
              " ('сказала', 219),\n",
              " ('опять', 220),\n",
              " ('ваша', 221),\n",
              " ('тот', 222),\n",
              " ('наверное', 223),\n",
              " ('плохо', 224),\n",
              " ('боюсь', 225),\n",
              " ('три', 226),\n",
              " ('правильно', 227),\n",
              " ('дальше', 228),\n",
              " ('потом', 229),\n",
              " ('видели', 230),\n",
              " ('отец', 231),\n",
              " ('прошу', 232),\n",
              " ('папа', 233),\n",
              " ('идет', 234),\n",
              " ('люди', 235),\n",
              " ('нами', 236),\n",
              " ('жив', 237),\n",
              " ('наш', 238),\n",
              " ('день', 239),\n",
              " ('никогда', 240),\n",
              " ('такие', 241),\n",
              " ('понимаю', 242),\n",
              " ('надеюсь', 243),\n",
              " ('вон', 244),\n",
              " ('происходит', 245),\n",
              " ('сами', 246),\n",
              " ('мое', 247),\n",
              " ('боже', 248),\n",
              " ('каком', 249),\n",
              " ('идти', 250),\n",
              " ('немного', 251),\n",
              " ('этим', 252),\n",
              " ('всегда', 253),\n",
              " ('генерал', 254),\n",
              " ('ваш', 255),\n",
              " ('какую', 256),\n",
              " ('пора', 257),\n",
              " ('эту', 258),\n",
              " ('им', 259),\n",
              " ('того', 260),\n",
              " ('знает', 261),\n",
              " ('говоришь', 262),\n",
              " ('вроде', 263),\n",
              " ('ребята', 264),\n",
              " ('ко', 265),\n",
              " ('виду', 266),\n",
              " ('них', 267),\n",
              " ('помочь', 268),\n",
              " ('никак', 269),\n",
              " ('понятно', 270),\n",
              " ('пять', 271),\n",
              " ('таки', 272),\n",
              " ('скажи', 273),\n",
              " ('дай', 274),\n",
              " ('друг', 275),\n",
              " ('хоть', 276),\n",
              " ('сделать', 277),\n",
              " ('почти', 278),\n",
              " ('понял', 279),\n",
              " ('дом', 280),\n",
              " ('кому', 281),\n",
              " ('имя', 282),\n",
              " ('место', 283),\n",
              " ('возможно', 284),\n",
              " ('самый', 285),\n",
              " ('дядя', 286),\n",
              " ('разрешите', 287),\n",
              " ('говорю', 288),\n",
              " ('лет', 289),\n",
              " ('мои', 290),\n",
              " ('хватит', 291),\n",
              " ('мог', 292),\n",
              " ('мать', 293),\n",
              " ('эта', 294),\n",
              " ('дверь', 295),\n",
              " ('босс', 296),\n",
              " ('ой', 297),\n",
              " ('свои', 298),\n",
              " ('были', 299),\n",
              " ('во', 300),\n",
              " ('смотри', 301),\n",
              " ('всех', 302),\n",
              " ('пойду', 303),\n",
              " ('слушай', 304),\n",
              " ('случае', 305),\n",
              " ('моему', 306),\n",
              " ('отлично', 307),\n",
              " ('лейтенант', 308),\n",
              " ('самом', 309),\n",
              " ('насчет', 310),\n",
              " ('слишком', 311),\n",
              " ('нашел', 312),\n",
              " ('при', 313),\n",
              " ('готовы', 314),\n",
              " ('том', 315),\n",
              " ('вообще', 316),\n",
              " ('подожди', 317),\n",
              " ('прекрасно', 318),\n",
              " ('ясно', 319),\n",
              " ('десять', 320),\n",
              " ('наши', 321),\n",
              " ('ними', 322),\n",
              " ('долго', 323),\n",
              " ('разумеется', 324),\n",
              " ('трудно', 325),\n",
              " ('кое', 326),\n",
              " ('твоя', 327),\n",
              " ('себе', 328),\n",
              " ('умер', 329),\n",
              " ('здорово', 330),\n",
              " ('будете', 331),\n",
              " ('говорят', 332),\n",
              " ('можете', 333),\n",
              " ('деле', 334),\n",
              " ('думал', 335),\n",
              " ('поздно', 336),\n",
              " ('скажешь', 337),\n",
              " ('наверно', 338),\n",
              " ('слово', 339),\n",
              " ('назад', 340),\n",
              " ('возьми', 341),\n",
              " ('прямо', 342),\n",
              " ('иван', 343),\n",
              " ('времени', 344),\n",
              " ('говорит', 345),\n",
              " ('двадцать', 346),\n",
              " ('живы', 347),\n",
              " ('сынок', 348),\n",
              " ('такая', 349),\n",
              " ('четыре', 350),\n",
              " ('слышишь', 351),\n",
              " ('пришли', 352),\n",
              " ('дорогой', 353),\n",
              " ('произошло', 354),\n",
              " ('этой', 355),\n",
              " ('посмотреть', 356),\n",
              " ('над', 357),\n",
              " ('дживз', 358),\n",
              " ('нужны', 359),\n",
              " ('иду', 360),\n",
              " ('давайте', 361),\n",
              " ('интересно', 362),\n",
              " ('видите', 363),\n",
              " ('будут', 364),\n",
              " ('хочет', 365),\n",
              " ('здравствуйте', 366),\n",
              " ('должны', 367),\n",
              " ('доктор', 368),\n",
              " ('ей', 369),\n",
              " ('спать', 370),\n",
              " ('вопрос', 371),\n",
              " ('хочется', 372),\n",
              " ('мальчик', 373),\n",
              " ('люблю', 374),\n",
              " ('раньше', 375),\n",
              " ('бабушка', 376),\n",
              " ('пожалуй', 377),\n",
              " ('руки', 378),\n",
              " ('сын', 379),\n",
              " ('живой', 380),\n",
              " ('говорил', 381),\n",
              " ('готово', 382),\n",
              " ('идем', 383),\n",
              " ('сразу', 384),\n",
              " ('говори', 385),\n",
              " ('видеть', 386),\n",
              " ('снова', 387),\n",
              " ('сама', 388),\n",
              " ('ох', 389),\n",
              " ('говорить', 390),\n",
              " ('слышал', 391),\n",
              " ('другой', 392),\n",
              " ('равно', 393),\n",
              " ('действительно', 394),\n",
              " ('собой', 395),\n",
              " ('вчера', 396),\n",
              " ('людей', 397),\n",
              " ('сделали', 398),\n",
              " ('вперед', 399),\n",
              " ('известно', 400),\n",
              " ('минут', 401),\n",
              " ('ушел', 402),\n",
              " ('будь', 403),\n",
              " ('пришел', 404),\n",
              " ('город', 405),\n",
              " ('пусть', 406),\n",
              " ('извини', 407),\n",
              " ('ш', 408),\n",
              " ('тридцать', 409),\n",
              " ('посмотри', 410),\n",
              " ('ранен', 411),\n",
              " ('ваши', 412),\n",
              " ('взял', 413),\n",
              " ('гм', 414),\n",
              " ('вместе', 415),\n",
              " ('твое', 416),\n",
              " ('нем', 417),\n",
              " ('всем', 418),\n",
              " ('добрый', 419),\n",
              " ('могли', 420),\n",
              " ('поговорить', 421),\n",
              " ('нужен', 422),\n",
              " ('угу', 423),\n",
              " ('р', 424),\n",
              " ('лойош', 425),\n",
              " ('спок', 426),\n",
              " ('понимаешь', 427),\n",
              " ('извините', 428),\n",
              " ('обязательно', 429),\n",
              " ('нужна', 430),\n",
              " ('деньги', 431),\n",
              " ('хо', 432),\n",
              " ('корабль', 433),\n",
              " ('чуть', 434),\n",
              " ('брат', 435),\n",
              " ('влад', 436),\n",
              " ('видно', 437),\n",
              " ('полковник', 438),\n",
              " ('найти', 439),\n",
              " ('глаза', 440),\n",
              " ('скажу', 441),\n",
              " ('работа', 442),\n",
              " ('шесть', 443),\n",
              " ('думаете', 444),\n",
              " ('майор', 445),\n",
              " ('забыл', 446),\n",
              " ('вполне', 447),\n",
              " ('ждать', 448),\n",
              " ('первый', 449),\n",
              " ('помню', 450),\n",
              " ('умеешь', 451),\n",
              " ('дети', 452),\n",
              " ('знал', 453),\n",
              " ('вовсе', 454),\n",
              " ('слышу', 455),\n",
              " ('нее', 456),\n",
              " ('хотела', 457),\n",
              " ('мисс', 458),\n",
              " ('узнать', 459),\n",
              " ('величество', 460),\n",
              " ('та', 461),\n",
              " ('благодарю', 462),\n",
              " ('скорее', 463),\n",
              " ('хотели', 464),\n",
              " ('смысле', 465),\n",
              " ('вилф', 466),\n",
              " ('приехал', 467),\n",
              " ('дать', 468),\n",
              " ('воды', 469),\n",
              " ('свою', 470),\n",
              " ('придется', 471),\n",
              " ('больно', 472),\n",
              " ('таком', 473),\n",
              " ('угодно', 474),\n",
              " ('простите', 475),\n",
              " ('слушаю', 476),\n",
              " ('нашли', 477),\n",
              " ('идите', 478),\n",
              " ('сказали', 479),\n",
              " ('две', 480),\n",
              " ('спрашиваю', 481),\n",
              " ('пришла', 482),\n",
              " ('чём', 483),\n",
              " ('одного', 484),\n",
              " ('такого', 485),\n",
              " ('господи', 486),\n",
              " ('стоит', 487),\n",
              " ('вечером', 488),\n",
              " ('можем', 489),\n",
              " ('наша', 490),\n",
              " ('дней', 491),\n",
              " ('вернулся', 492),\n",
              " ('дедушка', 493),\n",
              " ('парень', 494),\n",
              " ('делаете', 495),\n",
              " ('быстро', 496),\n",
              " ('море', 497),\n",
              " ('утром', 498),\n",
              " ('серьезно', 499),\n",
              " ('неплохо', 500),\n",
              " ('жить', 501),\n",
              " ('чувствуешь', 502),\n",
              " ('жизнь', 503),\n",
              " ('её', 504),\n",
              " ('лес', 505),\n",
              " ('боишься', 506),\n",
              " ('ночью', 507),\n",
              " ('госпожа', 508),\n",
              " ('весь', 509),\n",
              " ('говорила', 510),\n",
              " ('магистр', 511),\n",
              " ('прав', 512),\n",
              " ('никаких', 513),\n",
              " ('говорили', 514),\n",
              " ('должно', 515),\n",
              " ('прости', 516),\n",
              " ('увидеть', 517),\n",
              " ('бывает', 518),\n",
              " ('страшно', 519),\n",
              " ('месте', 520),\n",
              " ('спишь', 521),\n",
              " ('знали', 522),\n",
              " ('должна', 523),\n",
              " ('мало', 524),\n",
              " ('порядок', 525),\n",
              " ('мою', 526),\n",
              " ('письмо', 527),\n",
              " ('звать', 528),\n",
              " ('немедленно', 529),\n",
              " ('другое', 530),\n",
              " ('чему', 531),\n",
              " ('здоров', 532),\n",
              " ('час', 533),\n",
              " ('скажите', 534),\n",
              " ('те', 535),\n",
              " ('гарри', 536),\n",
              " ('мертв', 537),\n",
              " ('пойти', 538),\n",
              " ('совершенно', 539),\n",
              " ('стало', 540),\n",
              " ('самое', 541),\n",
              " ('моей', 542),\n",
              " ('особенного', 543),\n",
              " ('войти', 544),\n",
              " ('прощения', 545),\n",
              " ('па', 546),\n",
              " ('добро', 547),\n",
              " ('этих', 548),\n",
              " ('рядом', 549),\n",
              " ('саша', 550),\n",
              " ('стой', 551),\n",
              " ('холодно', 552),\n",
              " ('нету', 553),\n",
              " ('хороший', 554),\n",
              " ('смотрите', 555),\n",
              " ('тихо', 556),\n",
              " ('имею', 557),\n",
              " ('сержант', 558),\n",
              " ('посмотрим', 559),\n",
              " ('твои', 560),\n",
              " ('убили', 561),\n",
              " ('огонь', 562),\n",
              " ('живет', 563),\n",
              " ('тяжело', 564),\n",
              " ('виноват', 565),\n",
              " ('находится', 566),\n",
              " ('скорей', 567),\n",
              " ('получил', 568),\n",
              " ('собираетесь', 569),\n",
              " ('нечего', 570),\n",
              " ('жена', 571),\n",
              " ('ноги', 572),\n",
              " ('ума', 573),\n",
              " ('узнал', 574),\n",
              " ('голос', 575),\n",
              " ('идешь', 576),\n",
              " ('бог', 577),\n",
              " ('умею', 578),\n",
              " ('одно', 579),\n",
              " ('достаточно', 580),\n",
              " ('жизни', 581),\n",
              " ('весьма', 582),\n",
              " ('сударь', 583),\n",
              " ('побери', 584),\n",
              " ('погоди', 585),\n",
              " ('ричард', 586),\n",
              " ('убил', 587),\n",
              " ('веришь', 588),\n",
              " ('хуже', 589),\n",
              " ('самолет', 590),\n",
              " ('часов', 591),\n",
              " ('часа', 592),\n",
              " ('ночь', 593),\n",
              " ('идут', 594),\n",
              " ('рад', 595),\n",
              " ('рано', 596),\n",
              " ('решил', 597),\n",
              " ('вернусь', 598),\n",
              " ('немцы', 599),\n",
              " ('молодец', 600),\n",
              " ('спросил', 601),\n",
              " ('отца', 602),\n",
              " ('сильно', 603),\n",
              " ('голову', 604),\n",
              " ('дайте', 605),\n",
              " ('друзья', 606),\n",
              " ('говорите', 607),\n",
              " ('помощь', 608),\n",
              " ('против', 609),\n",
              " ('машина', 610),\n",
              " ('удалось', 611),\n",
              " ('вдруг', 612),\n",
              " ('видела', 613),\n",
              " ('слова', 614),\n",
              " ('ищу', 615),\n",
              " ('алло', 616),\n",
              " ('наконец', 617),\n",
              " ('братец', 618),\n",
              " ('жду', 619),\n",
              " ('свете', 620),\n",
              " ('знакомы', 621),\n",
              " ('имеешь', 622),\n",
              " ('ого', 623),\n",
              " ('король', 624),\n",
              " ('важно', 625),\n",
              " ('работы', 626),\n",
              " ('неважно', 627),\n",
              " ('подождите', 628),\n",
              " ('внизу', 629),\n",
              " ('несколько', 630),\n",
              " ('джим', 631),\n",
              " ('луиза', 632),\n",
              " ('осталось', 633),\n",
              " ('старший', 634),\n",
              " ('руку', 635),\n",
              " ('лесу', 636),\n",
              " ('попали', 637),\n",
              " ('своей', 638),\n",
              " ('болит', 639),\n",
              " ('каких', 640),\n",
              " ('сердце', 641),\n",
              " ('свой', 642),\n",
              " ('столько', 643),\n",
              " ('слышите', 644),\n",
              " ('старый', 645),\n",
              " ('т', 646),\n",
              " ('такую', 647),\n",
              " ('капитана', 648),\n",
              " ('стороны', 649),\n",
              " ('ждет', 650),\n",
              " ('всю', 651),\n",
              " ('другие', 652),\n",
              " ('школу', 653),\n",
              " ('землю', 654),\n",
              " ('меньше', 655),\n",
              " ('взять', 656),\n",
              " ('скажете', 657),\n",
              " ('голова', 658),\n",
              " ('вечер', 659),\n",
              " ('спит', 660),\n",
              " ('попробую', 661),\n",
              " ('твоему', 662),\n",
              " ('неправда', 663),\n",
              " ('сделала', 664),\n",
              " ('готова', 665),\n",
              " ('каким', 666),\n",
              " ('твою', 667),\n",
              " ('итак', 668),\n",
              " ('знаем', 669),\n",
              " ('тише', 670),\n",
              " ('хозяин', 671),\n",
              " ('собираешься', 672),\n",
              " ('никакой', 673),\n",
              " ('пор', 674),\n",
              " ('красивый', 675),\n",
              " ('ха', 676),\n",
              " ('кровь', 677),\n",
              " ('дорогая', 678),\n",
              " ('этому', 679),\n",
              " ('знала', 680),\n",
              " ('пошел', 681),\n",
              " ('чьи', 682),\n",
              " ('фамилия', 683),\n",
              " ('сможешь', 684),\n",
              " ('около', 685),\n",
              " ('твоей', 686),\n",
              " ('кофе', 687),\n",
              " ('оба', 688),\n",
              " ('гости', 689),\n",
              " ('чаю', 690),\n",
              " ('помнишь', 691),\n",
              " ('невозможно', 692),\n",
              " ('муж', 693),\n",
              " ('минутку', 694),\n",
              " ('устал', 695),\n",
              " ('работать', 696),\n",
              " ('решили', 697),\n",
              " ('спросить', 698),\n",
              " ('вопросы', 699),\n",
              " ('имеете', 700),\n",
              " ('начнем', 701),\n",
              " ('приказ', 702),\n",
              " ('довольно', 703),\n",
              " ('сестра', 704),\n",
              " ('узнали', 705),\n",
              " ('который', 706),\n",
              " ('чья', 707),\n",
              " ('недалеко', 708),\n",
              " ('считаешь', 709),\n",
              " ('хотелось', 710),\n",
              " ('часто', 711),\n",
              " ('жаль', 712),\n",
              " ('ночи', 713),\n",
              " ('узнаешь', 714),\n",
              " ('никуда', 715),\n",
              " ('расскажу', 716),\n",
              " ('штука', 717),\n",
              " ('н', 718),\n",
              " ('п', 719),\n",
              " ('имеет', 720),\n",
              " ('двух', 721),\n",
              " ('показалось', 722),\n",
              " ('делал', 723),\n",
              " ('вода', 724),\n",
              " ('пути', 725),\n",
              " ('скажем', 726),\n",
              " ('никого', 727),\n",
              " ('после', 728),\n",
              " ('бери', 729),\n",
              " ('называется', 730),\n",
              " ('одну', 731),\n",
              " ('увидишь', 732),\n",
              " ('мэм', 733),\n",
              " ('правду', 734),\n",
              " ('мадам', 735),\n",
              " ('вашей', 736),\n",
              " ('выпить', 737),\n",
              " ('уверена', 738),\n",
              " ('бен', 739),\n",
              " ('богу', 740),\n",
              " ('собственно', 741),\n",
              " ('садись', 742),\n",
              " ('комиссар', 743),\n",
              " ('начальник', 744),\n",
              " ('уехал', 745),\n",
              " ('попал', 746),\n",
              " ('чувствую', 747),\n",
              " ('делает', 748),\n",
              " ('мастер', 749),\n",
              " ('делают', 750),\n",
              " ('здравствуй', 751),\n",
              " ('ушли', 752),\n",
              " ('согласен', 753),\n",
              " ('уверены', 754),\n",
              " ('жива', 755),\n",
              " ('легче', 756),\n",
              " ('малыш', 757),\n",
              " ('сталин', 758),\n",
              " ('чей', 759),\n",
              " ('собираюсь', 760),\n",
              " ('приехала', 761),\n",
              " ('года', 762),\n",
              " ('будто', 763),\n",
              " ('среди', 764),\n",
              " ('недавно', 765),\n",
              " ('странно', 766),\n",
              " ('дам', 767),\n",
              " ('слышала', 768),\n",
              " ('хотим', 769),\n",
              " ('чубо', 770),\n",
              " ('искать', 771),\n",
              " ('ответ', 772),\n",
              " ('большое', 773),\n",
              " ('вика', 774),\n",
              " ('слава', 775),\n",
              " ('игра', 776),\n",
              " ('той', 777),\n",
              " ('немножко', 778),\n",
              " ('дождь', 779),\n",
              " ('ужасно', 780),\n",
              " ('нашей', 781),\n",
              " ('близко', 782),\n",
              " ('любишь', 783),\n",
              " ('читать', 784),\n",
              " ('очки', 785),\n",
              " ('узнаем', 786),\n",
              " ('человека', 787),\n",
              " ('оружие', 788),\n",
              " ('кролик', 789),\n",
              " ('послушай', 790),\n",
              " ('наверху', 791),\n",
              " ('бойся', 792),\n",
              " ('вниз', 793),\n",
              " ('выйти', 794),\n",
              " ('бежим', 795),\n",
              " ('прошло', 796),\n",
              " ('спроси', 797),\n",
              " ('дня', 798),\n",
              " ('лишь', 799),\n",
              " ('сначала', 800),\n",
              " ('забыли', 801),\n",
              " ('пару', 802),\n",
              " ('увидимся', 803),\n",
              " ('леди', 804),\n",
              " ('пожаловать', 805),\n",
              " ('ушла', 806),\n",
              " ('думать', 807),\n",
              " ('сэм', 808),\n",
              " ('иногда', 809),\n",
              " ('возьмем', 810),\n",
              " ('аэродром', 811),\n",
              " ('машины', 812),\n",
              " ('новый', 813),\n",
              " ('работу', 814),\n",
              " ('садитесь', 815),\n",
              " ('думали', 816),\n",
              " ('слышали', 817),\n",
              " ('случайно', 818),\n",
              " ('иначе', 819),\n",
              " ('общем', 820),\n",
              " ('начинать', 821),\n",
              " ('желаю', 822),\n",
              " ('б', 823),\n",
              " ('владимир', 824),\n",
              " ('цел', 825),\n",
              " ('погиб', 826),\n",
              " ('доме', 827),\n",
              " ('связь', 828),\n",
              " ('двое', 829),\n",
              " ('неужто', 830),\n",
              " ('пойдешь', 831),\n",
              " ('поедем', 832),\n",
              " ('чувствуете', 833),\n",
              " ('понятия', 834),\n",
              " ('сможем', 835),\n",
              " ('получилось', 836),\n",
              " ('понимаете', 837),\n",
              " ('честь', 838),\n",
              " ('идете', 839),\n",
              " ('шеф', 840),\n",
              " ('старшина', 841),\n",
              " ('утра', 842),\n",
              " ('земля', 843),\n",
              " ('обычно', 844),\n",
              " ('открыть', 845),\n",
              " ('люк', 846),\n",
              " ('оттуда', 847),\n",
              " ('нос', 848),\n",
              " ('убить', 849),\n",
              " ('восемь', 850),\n",
              " ('ту', 851),\n",
              " ('нашла', 852),\n",
              " ('денег', 853),\n",
              " ('дитя', 854),\n",
              " ('пойдет', 855),\n",
              " ('пойдём', 856),\n",
              " ('уйти', 857),\n",
              " ('плавать', 858),\n",
              " ('посмотрите', 859),\n",
              " ('птица', 860),\n",
              " ('играть', 861),\n",
              " ('вероятно', 862),\n",
              " ('чай', 863),\n",
              " ('хотят', 864),\n",
              " ('хотя', 865),\n",
              " ('собака', 866),\n",
              " ('дал', 867),\n",
              " ('школы', 868),\n",
              " ('женщина', 869),\n",
              " ('воду', 870),\n",
              " ('министр', 871),\n",
              " ('понравится', 872),\n",
              " ('эх', 873),\n",
              " ('оставь', 874),\n",
              " ('рада', 875),\n",
              " ('пахнет', 876),\n",
              " ('приятель', 877),\n",
              " ('берти', 878),\n",
              " ('смешно', 879),\n",
              " ('великий', 880),\n",
              " ('хм', 881),\n",
              " ('моих', 882),\n",
              " ('смерти', 883),\n",
              " ('вернемся', 884),\n",
              " ('прочь', 885),\n",
              " ('хорошая', 886),\n",
              " ('самая', 887),\n",
              " ('сделано', 888),\n",
              " ('позже', 889),\n",
              " ('заткнись', 890),\n",
              " ('сир', 891),\n",
              " ('милорд', 892),\n",
              " ('тем', 893),\n",
              " ('ральф', 894),\n",
              " ('д', 895),\n",
              " ('билл', 896),\n",
              " ('рал', 897),\n",
              " ('тысяча', 898),\n",
              " ('часы', 899),\n",
              " ('ма', 900),\n",
              " ('ждут', 901),\n",
              " ('дорога', 902),\n",
              " ('ближе', 903),\n",
              " ('хорошее', 904),\n",
              " ('ноль', 905),\n",
              " ('оказались', 906),\n",
              " ('документы', 907),\n",
              " ('книгу', 908),\n",
              " ('милый', 909),\n",
              " ('сожалению', 910),\n",
              " ('танцевать', 911),\n",
              " ('штурман', 912),\n",
              " ('воздухе', 913),\n",
              " ('пятнадцать', 914),\n",
              " ('моего', 915),\n",
              " ('вставай', 916),\n",
              " ('зайти', 917),\n",
              " ('нему', 918),\n",
              " ('короче', 919),\n",
              " ('сидеть', 920),\n",
              " ('понимает', 921),\n",
              " ('горит', 922),\n",
              " ('вашу', 923),\n",
              " ('упал', 924),\n",
              " ('ехать', 925),\n",
              " ('смогу', 926),\n",
              " ('кино', 927),\n",
              " ('неизвестно', 928),\n",
              " ('улице', 929),\n",
              " ('миша', 930),\n",
              " ('узнаете', 931),\n",
              " ('выяснить', 932),\n",
              " ('годится', 933),\n",
              " ('звали', 934),\n",
              " ('попробовать', 935),\n",
              " ('профессор', 936),\n",
              " ('смотрит', 937),\n",
              " ('потерял', 938),\n",
              " ('сидит', 939),\n",
              " ('живешь', 940),\n",
              " ('лучший', 941),\n",
              " ('следует', 942),\n",
              " ('выбраться', 943),\n",
              " ('пятьдесят', 944),\n",
              " ('постараюсь', 945),\n",
              " ('уходить', 946),\n",
              " ('свет', 947),\n",
              " ('сплю', 948),\n",
              " ('фу', 949),\n",
              " ('взглянуть', 950),\n",
              " ('работает', 951),\n",
              " ('внутри', 952),\n",
              " ('платок', 953),\n",
              " ('жалко', 954),\n",
              " ('сошел', 955),\n",
              " ('таким', 956),\n",
              " ('ребенок', 957),\n",
              " ('знак', 958),\n",
              " ('поехали', 959),\n",
              " ('инспектор', 960),\n",
              " ('девочка', 961),\n",
              " ('следующий', 962),\n",
              " ('особенно', 963),\n",
              " ('гляди', 964),\n",
              " ('наверняка', 965),\n",
              " ('места', 966),\n",
              " ('сударыня', 967),\n",
              " ('поесть', 968),\n",
              " ('умереть', 969),\n",
              " ('утро', 970),\n",
              " ('образом', 971),\n",
              " ('тех', 972),\n",
              " ('ради', 973),\n",
              " ('вернуться', 974),\n",
              " ('придумал', 975),\n",
              " ('честное', 976),\n",
              " ('съесть', 977),\n",
              " ('покое', 978),\n",
              " ('голоден', 979),\n",
              " ('удовольствием', 980),\n",
              " ('мадемуазель', 981),\n",
              " ('конец', 982),\n",
              " ('никому', 983),\n",
              " ('покажи', 984),\n",
              " ('миссис', 985),\n",
              " ('поближе', 986),\n",
              " ('новости', 987),\n",
              " ('х', 988),\n",
              " ('джон', 989),\n",
              " ('идея', 990),\n",
              " ('ответил', 991),\n",
              " ('увидите', 992),\n",
              " ('миледи', 993),\n",
              " ('касается', 994),\n",
              " ('синклер', 995),\n",
              " ('уоррен', 996),\n",
              " ('поди', 997),\n",
              " ('вашему', 998),\n",
              " ('петя', 999),\n",
              " ('новая', 1000),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsUqzEBXg9Mu"
      },
      "source": [
        "# **Подготовка выборки**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=305s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4nNBJUQgebF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47d0700-0c92-4697-e417-f3029d8ee487"
      },
      "source": [
        "######################\n",
        "# Устанавливаем закодированные входные данные(вопросы) https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=310s\n",
        "######################\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions) # разбиваем текст вопросов на последовательности индексов\n",
        "maxLenQuestions = max([ len(x) for x in tokenizedQuestions]) # уточняем длину самого большого вопроса\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие вопросы\n",
        "paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "encoderForInput = paddedQuestions\n",
        "print('Пример оригинального вопроса на вход : {}'.format(questions[100])) \n",
        "print('Пример кодированного вопроса на вход : {}'.format(encoderForInput[100])) \n",
        "print('Размеры закодированного массива вопросов на вход : {}'.format(encoderForInput.shape)) \n",
        "print('Установленная длина вопросов на вход : {}'.format(maxLenQuestions)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального вопроса на вход : Какая же мораль?\n",
            "Пример кодированного вопроса на вход : [ 171   19 5704    0    0    0    0    0    0    0    0]\n",
            "Размеры закодированного массива вопросов на вход : (11888, 11)\n",
            "Установленная длина вопросов на вход : 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tjvhMuzqFJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea3ca55b-0d6f-4f35-916b-6cee75e50c5a"
      },
      "source": [
        "######################\n",
        "# Устанавливаем раскодированные входные данные(ответы) https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=375s\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers]) # уточняем длину самого большого ответа\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "decoderForInput = paddedAnswers # переводим в numpy массив\n",
        "print('Пример оригинального ответа на вход: {}'.format(answers[100])) \n",
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[200])) \n",
        "print('Размеры раскодированного массива ответов на вход : {}'.format(decoderForInput.shape)) \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального ответа на вход: <START> Никакой. Так просто вспомнилось. <END>\n",
            "Пример раскодированного ответа на вход : [   2 1744    3    0    0    0    0    0    0    0    0    0    0]\n",
            "Размеры раскодированного массива ответов на вход : (11888, 13)\n",
            "Установленная длина ответов на вход : 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwsKk9dzNeqI"
      },
      "source": [
        "######################\n",
        "# Раскодированные выходные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "for i in range(len(tokenizedAnswers)) : # для разбитых на последовательности ответов\n",
        "  tokenizedAnswers[i] = tokenizedAnswers[i][1:] # избавляемся от тега <START>\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers , padding='post')\n",
        "\n",
        "oneHotAnswers = utils.to_categorical(paddedAnswers, vocabularySize) # переводим в one hot vector\n",
        "decoderForOutput = np.array(oneHotAnswers) # и сохраняем в виде массива numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRl1k7SVaA6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e59acdc-80c6-4dad-9060-a3f1ba675609"
      },
      "source": [
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[100][:21]))  \n",
        "print('Пример раскодированного ответа на выход : {}'.format(decoderForOutput[100][4][:21])) \n",
        "print('Размеры раскодированного массива ответов на выход : {}'.format(decoderForOutput.shape))\n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример раскодированного ответа на вход : [    2   673    20    94 10548     3     0     0     0     0     0     0\n",
            "     0]\n",
            "Пример раскодированного ответа на выход : [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Размеры раскодированного массива ответов на выход : (11888, 13, 15093)\n",
            "Установленная длина вопросов на выход : 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0KR6Mh_hp1f"
      },
      "source": [
        "# **Параметры нейросети и модель обучения**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=915s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRKDr4rhXcZ"
      },
      "source": [
        "######################\n",
        "# Первый входной слой, кодер, выходной слой https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=915s\n",
        "######################\n",
        "encoderInputs = Input(shape=(None , )) # размеры на входе сетки (здесь будет encoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "encoderEmbedding = Embedding(vocabularySize, 200 , mask_zero=True) (encoderInputs)\n",
        "# Затем выход с Embedding пойдёт в LSTM слой, на выходе у которого будет два вектора состояния - state_h , state_c\n",
        "# Вектора состояния - state_h , state_c зададутся в LSTM слое декодера в блоке ниже\n",
        "encoderOutputs, state_h , state_c = LSTM(200, return_state=True)(encoderEmbedding)\n",
        "encoderStates = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_yv8Y6QWX2D"
      },
      "source": [
        "######################\n",
        "# Второй входной слой, декодер, выходной слой https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1048s\n",
        "######################\n",
        "decoderInputs = Input(shape=(None, )) # размеры на входе сетки (здесь будет decoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "# mask_zero=True - игнорировать нулевые padding при передаче в LSTM. Предотвратит вывод ответа типа: \"У меня все хорошо PAD PAD PAD PAD PAD PAD..\"\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True) (decoderInputs) \n",
        "# Затем выход с Embedding пойдёт в LSTM слой, которому передаются вектора состояния - state_h , state_c\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)\n",
        "decoderOutputs , _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates)\n",
        "# И от LSTM'а сигнал decoderOutputs пропускаем через полносвязный слой с софтмаксом на выходе\n",
        "decoderDense = Dense(vocabularySize, activation='softmax') \n",
        "output = decoderDense (decoderOutputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYnTen_UWc5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "outputId": "6455fec2-c789-49a7-c205-02e3534400ca"
      },
      "source": [
        "######################\n",
        "# Собираем тренировочную модель нейросети https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1220s\n",
        "######################\n",
        "model = Model([encoderInputs, decoderInputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "print(model.summary()) # выведем на экран информацию о построенной модели нейросети\n",
        "plot_model(model, to_file='model.png') # и построим график для визуализации слоев и связей между ними"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 200)    3018600     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    3018600     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 15093)  3033693     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,712,493\n",
            "Trainable params: 9,712,493\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdEAAAHBCAYAAAA2FYEAAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdeVxU9f4/8NfMMDCLMm4IXhUVzDWXq1mI4nrrppYbq1vpveaWuSda3q630rQ0NVP7lubt3voim2ma/axUTAPNa265pZiaoaKCoIAwwPv3R1/nRijCYZjDzLyej8f8wZlzPp/3nHNmXpxdIyICIiIiqqh4rdoVEBEROSuGKBERkUIMUSIiIoUYokRERAp52LvB8PBwezdJVO117doVM2bMULsMInIwu2+JJiQk4NKlS/Zu1u1cunQJCQkJapdB5bBv3z6kpKSoXQYRqcDuW6IAMH36dERERFRF024jLi4OkZGRiI+PV7sUegDufSFyXzwmSkREpBBDlIiISCGGKBERkUIMUSIiIoUYokRERAoxRImIiBRiiBIRESnEECUiIlKIIUpERKQQQ5SIiEghhigREZFCDFEiIiKFGKJEREQKMUSJiIgUUj1Et23bBovFgi1btqhdil0UFxdj2bJlCA4Odmi/+/btQ+vWraHVaqHRaODr64vXX3/doTU8SGJiIgICAqDRaKDRaODn54eRI0eqXRYRkWJV8jzRihARtUuwmzNnzmDMmDH49ttv0aFDB4f2HRQUhJMnT+LJJ5/E9u3bcfr0adSqVcuhNTxIaGgoQkND0bx5c1y/fh1XrlxRuyQiokpRfUt0wIAByMrKwtNPP612KcjLy1O8BXnkyBHMmTMHEydORMeOHe1cmXOqzPwkInIGqododbJu3Tqkp6crmrZDhw5ITEzEiBEj4OXlZefKnFNl5icRkTNQNUT37t0Lf39/aDQavPvuuwCA1atXw2w2w2QyYfPmzejXrx+8vb3RqFEjxMTE2KZ95513YDAYUL9+fUyYMAENGjSAwWBAcHAw9u/fbxtvypQp8PT0hJ+fn23Y888/D7PZDI1Gg+vXrwMApk2bhpkzZyI1NRUajQbNmzd30FyoWs4+P/fs2YM2bdrAYrHAYDCgXbt22L59OwBg7NixtuOrgYGBOHToEABgzJgxMJlMsFgs+OyzzwAARUVFeOWVV+Dv7w+j0Yj27dsjNjYWAPDmm2/CZDKhZs2aSE9Px8yZM9GwYUOcPn1aUc1E5EbEzgBIbGxsucf/+eefBYCsXLnSNuzll18WALJjxw7JysqS9PR0CQkJEbPZLAUFBbbxxo8fL2azWU6cOCF37tyR48ePS5cuXaRmzZpy8eJF23gjRowQX1/fEv2+9dZbAkCuXbtmGxYaGiqBgYFKPnYJjz32mHTo0KFSbcTGxoqSxfPnP/9ZAEhmZqZtWHWbn4GBgWKxWMr1eeLj42X+/PmSkZEhN27ckKCgIKlbt26JPnQ6nfzyyy8lphs+fLh89tlntr9nzZolXl5ekpCQIJmZmfLSSy+JVquVAwcOlJhHU6dOlZUrV8rQoUPl5MmT5aoxLCxMwsLCyjUuEbmUuGq9Ozc4OBje3t7w8fFBVFQUcnJycPHixRLjeHh4oHXr1vDy8kKbNm2wevVq3Lp1C+vXr1ep6urLGednWFgY/v73v6N27dqoU6cOBg4ciBs3buDatWsAgIkTJ6KoqKhEfdnZ2Thw4AD69+8PALhz5w5Wr16NIUOGIDQ0FLVq1cK8efOg1+tLfa5FixZh8uTJSExMRKtWrRz3QYnIKVXrEP0tT09PAIDVai1zvEceeQQmkwmnTp1yRFlOy1nnp16vB/Dr7lkA6NOnD1q0aIEPP/zQdqb3hg0bEBUVBZ1OBwA4ffo0cnNz8fDDD9vaMRqN8PPzqzafi4ick9OEaEV4eXnZtlSo8tScn59//jl69eoFHx8feHl5Yfbs2SXe12g0mDBhAs6dO4cdO3YAAP71r3/hr3/9q22cnJwcAMC8efNsx1A1Gg0uXLiA3Nxcx30YInI5LheiVqsVN2/eRKNGjdQuxSU4en5+8803WLZsGQDg4sWLGDJkCPz8/LB//35kZWVh8eLFpaYZPXo0DAYD1q5di9OnT8Pb2xtNmjSxve/j4wMAWLZsGUSkxCslJcUhn4uIXJPqN1uwt6SkJIgIgoKCbMM8PDweuNuS7s3R8/PgwYMwm80AgGPHjsFqtWLSpEkICAgA8OuW5+/Vrl0bkZGR2LBhA2rWrInnnnuuxPuNGzeGwWDA4cOHq6RmInJfTr8lWlxcjMzMTBQWFuLo0aOYNm0a/P39MXr0aNs4zZs3R0ZGBjZt2gSr1Ypr167hwoULpdqqU6cO0tLScP78edy6dcstg1et+Wm1WnH16lUkJSXZQtTf3x8A8PXXX+POnTs4c+ZMicttfmvixInIz8/H1q1bS924w2AwYMyYMYiJicHq1auRnZ2NoqIiXLp0CZcvX67oLCIi+i97n++LClzisnLlSvHz8xMAYjKZZODAgbJq1SoxmUwCQB566CFJTU2V999/X7y9vQWANGnSRH788UcR+fWSDL1eLw0bNhQPDw/x9vaWwYMHS2pqaol+bty4Ib179xaDwSDNmjWTF154QV588UUBIM2bN7ddvvH9999LkyZNxGg0Svfu3eXKlSvl/twpKSnSrVs3adCggQAQAOLn5yfBwcGye/fucrdzV0Uvcdm3b5+0bdtWtFqtre8FCxZUq/m5Zs0aCQwMtM2f+702btxo6ys6Olrq1KkjtWrVkvDwcHn33XcFgAQGBpa47EZE5I9//KPMnTv3nvMnPz9foqOjxd/fXzw8PMTHx0dCQ0Pl+PHjsnjxYjEajQJAGjduLP/+97/LPd9FeIkLkRuL04jY9+a1Go0GsbGxiIiIsGez9zRhwgTEx8fjxo0bVd6Xo8XFxSEyMtKh9xZ29vk5YMAAvPvuu2jWrJlD+w0PDwcAxMfHO7RfIlJdvNPvzr17qQPZhzPNz9/uHj569CgMBoPDA5SI3JvTh2hVOXXqVInLIe73ioqKUrtUtxUdHY0zZ87gxx9/xJgxY/Daa6+pXRIRuRmnDdGXXnoJ69evR1ZWFpo1a4aEhAS7tt+qVatSl0Pc67Vhwwa79quWqp6fVcFkMqFVq1b405/+hPnz56NNmzZql0REbsapj4m6MjWOiZIyPCZK5Lac/5goERGRWhiiRERECjFEiYiIFGKIEhERKcQQJSIiUoghSkREpBBDlIiISCGGKBERkUIMUSIiIoUYokRERAoxRImIiBRiiBIRESnEECUiIlLIoyoaXbZsGZ9oUUmXLl0C8N8nhFD1tW/fPgQFBaldBhGpwO5bomFhYWjUqJG9m3U7jRo1QlhYWLnHT0tLw2effVaFFdH9BAUFoWvXrmqXQUQqsPvzREkdfP4oEZHD8XmiRERESjFEiYiIFGKIEhERKcQQJSIiUoghSkREpBBDlIiISCGGKBERkUIMUSIiIoUYokRERAoxRImIiBRiiBIRESnEECUiIlKIIUpERKQQQ5SIiEghhigREZFCDFEiIiKFGKJEREQKMUSJiIgUYogSEREpxBAlIiJSiCFKRESkEEOUiIhIIYYoERGRQgxRIiIihRiiRERECjFEiYiIFGKIEhERKcQQJSIiUoghSkREpBBDlIiISCGGKBERkUIMUSIiIoUYokRERAp5qF0AVdwvv/yCp59+Glar1TYsJycHNWrUQLt27UqM27FjR/z73/92dIlERG6BIeqEGjZsiDt37uDkyZOl3vvhhx9K/B0ZGemosoiI3A535zqpZ555Bh4eD/4fiCFKRFR1GKJOavjw4SgqKrrv+xqNBp06dcJDDz3kwKqIiNwLQ9RJ+fv7o0uXLtBq770IdTodnnnmGQdXRUTkXhiiTuyZZ56BRqO553tFRUUIDw93cEVERO6FIerEIiIi7jlcp9OhZ8+e+MMf/uDgioiI3AtD1In5+PigV69e0Ol0pd4bNWqUChUREbkXhqiTGzVqFESkxDCtVouhQ4eqVBERkftgiDq5oUOHlrjUxcPDA/369UOtWrVUrIqIyD0wRJ1czZo18dRTT0Gv1wP49YSikSNHqlwVEZF7YIi6gBEjRqCwsBAAYDAY8NRTT6lcERGRe2CIuoD+/fvDZDIBAEJDQ2E0GlWuiIjIPZS6b9ylS5eQnJysRi1UCV26dEFSUhIaN26MuLg4tcuhCrrf5Ur2kJKSgp9//rnK2ieqrqrye3WXRn53amdcXBzvt0rkYL8/w9qewsPDkZCQUGXtE1VXVfm9+j/x992dKyJ8OcErNjYWAFBYWIhXX31V9Xr4Urb8qlpYWJjqn9UVXgAQGxureh18lf1y1PcK4DFRl6HT6TB37ly1yyAicisMURdSnkejERGR/TBEiYiIFGKIEhERKcQQJSIiUoghSkREpBBDlIiISCGGKBERkUIMUSIiIoUYokRERAoxRImIiBRiiBIRESnEECUiIlKIIUpERKRQtQ7RLl26QKfToWPHjnZve+zYsahZsyY0Gg0OHz5c4fG2bdsGi8WCLVu22L22qpSYmIiAgABoNJr7vpo2bWqXvrj8nJerzJ9XX30Vbdq0gbe3N7y8vNC8eXPMnj0bt2/frvK+9+3bh9atW0Or1UKj0cDX1xevv/56lfdbEb//PfDz88PIkSPVLsupVOsQPXDgAHr37l0lba9duxYffPCB4vHuPlvQ2YSGhuLcuXMIDAyExWKxPX+vsLAQubm5uHr1Kkwmk1364vJzXq4yf3bu3InJkyfj/PnzuH79OhYuXIjly5cjPDy8yvsOCgrCyZMn8cQTTwAATp8+jXnz5lV5vxXx+9+DK1eu4OOPP1a7LKfiFM/O0mg0apdQyoABA5CVlaV2GXaj0+lgNBphNBrRokULu7bN5ed8qtP8ycvLQ9++fZGcnFzhaWvUqIHx48dDp9MBACIiIpCYmIi4uDj8/PPPaNy4sb3LrdYqMy/p3qr1luhder2+Stot74+7I0JARBAfH4/333+/yvt6kE2bNtm1PS4/qox169YhPT1d0bRbt261Behd9erVAwDk5uZWujZnU5l5SfdmlxAtKirCK6+8An9/fxiNRrRv3x6xsbEAgOXLl8NsNkOr1aJz587w9fWFXq+H2WxGp06dEBISgsaNG8NgMKBWrVqYPXt2qfbPnj2LVq1awWw2w2g0IiQkBHv37i13DcCvP3JvvfUWWrZsCS8vL1gsFrz44oul+irPeHv37oW/vz80Gg3effddAMDq1athNpthMpmwefNm9OvXD97e3mjUqBFiYmJK1bpw4UK0bNkSRqMR9erVQ7NmzbBw4UJEREQoWwhVhMvPuZefEpWZP++88w4MBgPq16+PCRMmoEGDBjAYDAgODsb+/ftt402ZMgWenp7w8/OzDXv++edhNpuh0Whw/fp1AMC0adMwc+ZMpKamQqPRoHnz5pX+fL/88guMRiOaNWtW6baUcPZ5uWfPHrRp0wYWiwUGgwHt2rXD9u3bAfx6DsLd46uBgYE4dOgQAGDMmDEwmUywWCz47LPPAJT9nX/zzTdhMplQs2ZNpKenY+bMmWjYsCFOnz6tqOYqJb8TGxsr9xhcplmzZomXl5ckJCRIZmamvPTSS6LVauXAgQMiIvL3v/9dAMj+/fslJydHrl+/Lk8++aQAkM8//1yuXbsmOTk5MmXKFAEghw8ftrXdt29fCQgIkJ9++kmsVqv88MMP8thjj4nBYJAff/yx3DW8/PLLotFoZOnSpZKZmSm5ubmyatUqASCHDh2ytVPe8X7++WcBICtXriwxLQDZsWOHZGVlSXp6uoSEhIjZbJaCggLbeAsWLBCdTiebN2+W3NxcOXjwoPj6+kqvXr0qNN9FlC0vEZHAwECxWCwlhk2dOlWOHTtWalwuv+q3/CoiLCxMwsLCKjRNZebP+PHjxWw2y4kTJ+TOnTty/Phx6dKli9SsWVMuXrxoG2/EiBHi6+tbot+33npLAMi1a9dsw0JDQyUwMLCiH/uecnJypGbNmjJlyhRF0wOQ2NjYCk3z5z//WQBIZmambVh1m5f3+j24n/j4eJk/f75kZGTIjRs3JCgoSOrWrVuiD51OJ7/88kuJ6YYPHy6fffaZ7e/yfOcByNSpU2XlypUydOhQOXnyZLlqdMT36v/EVTpE8/LyxGQySVRUlG1Ybm6ueHl5yaRJk0Tkvz/Ct27dso3z0UcfCYASP9rfffedAJANGzbYhvXt21c6dOhQos+jR48KAJk1a1a5asjNzRWTySSPP/54iXZiYmJK/LiWdzyRsn9k8vLybMPu/oCfPXvWNqxLly7y6KOPluhj3LhxotVqJT8/XyqiMiEKoNSrrBDl8vtVdVh+FWHvEH3Q/Bk/fnypH+QDBw4IAPnHP/5hG6ZGiL788svSokULyc7OVjS9vUO0uszLioTo7y1cuFAASHp6uoiIfP311wJAXn/9dds4WVlZ8tBDD0lhYaGIlC837jWPysuRIVrp3bmnT59Gbm4uHn74Ydswo9EIPz8/nDp16r7TeXp6AgAKCwttw+4eO7NarWX22a5dO1gsFhw9erRcNZw9exa5ubno27dvme2Wd7yKuPs5f/uZ7ty5U+rsx6KiIuj1+lLHb6rSb8/OFRFMnTq13NNy+am//KqDe82fe3nkkUdgMpnK/E2oahs3bkRcXBy2b9+OmjVrqlbH/TjTvPytu9/7oqIiAECfPn3QokULfPjhh7bvyYYNGxAVFWX7fijNjeqo0iGak5MDAJg3b16Jaw0vXLhQpQfu9Xq9bWV7UA2XLl0CAPj4+JTZZnnHq6z+/fvj4MGD2Lx5M/Ly8vCf//wHmzZtwlNPPaXqj/Dy5ctLrNRVicvP/Xh5eeHatWuq9L1hwwYsWrQISUlJdrsOWk1qzsvPP/8cvXr1go+PD7y8vEqdB6HRaDBhwgScO3cOO3bsAAD861//wl//+lfbOGrlRlWodIje/cFatmxZia0aEUFKSkqlC7yXwsJCZGRkwN/fv1w1GAwGAEB+fn6Z7ZZ3vMqaP38++vTpg9GjR8Pb2xtDhw5FREREua57dAVcfu7HarXi5s2baNSokcP7XrlyJT7++GPs3LkTf/jDHxzev705el5+8803WLZsGQDg4sWLGDJkCPz8/LB//35kZWVh8eLFpaYZPXo0DAYD1q5di9OnT8Pb2xtNmjSxva9GblSVSofo3TMzy7prjL3t2rULxcXF6NSpU7lqePjhh6HVarF79+4y2y3veJV1/PhxpKam4tq1a7Barbh48SJWr16N2rVrV2m/5XX58mWMGTOmytrn8nM/SUlJEBEEBQXZhnl4eDxw12VliAiio6Nx7NgxbNq0CTVq1KiyvhzJ0fPy4MGDMJvNAIBjx47BarVi0qRJCAgIgMFguOclZLVr10ZkZCQ2bdqEJUuW4Lnnnivxvhq5UVUqHaIGgwFjxoxBTEwMVq9ejezsbBQVFeHSpUu4fPmyPWpEQUEBsrKyUFhYiO+//x5TpkxBkyZNMHr06HLV4OPjg9DQUCQkJGDdunXIzs7G0aNHS13TV97xKmvy5Mnw9/d3yK3HKkJEkJeXh8TERHh7e9utXS4/91NcXIzMzEwUFhbi6NGjmDZtGvz9/W3LHACaN2+OjIwMbNq0CVarFdeuXcOFCxdKtVWnTh2kpaXh/PnzuHXrVrnD4sSJE3jzzTfxwQcfQK/Xl7q95ZIlS+z1cauUWvPSarXi6tWrSEpKsoXo3b1HX3/9Ne7cuYMzZ86UuNzmtyZOnIj8/Hxs3boVTz/9dIn3HJEbDvP7U42UnNWUn58v0dHR4u/vLx4eHuLj4yOhoaFy/PhxWb58uZhMJgEgTZs2lT179siiRYvEYrEIAPH19ZVPPvlENmzYIL6+vgJAateuLTExMSIisn79eundu7fUr19fPDw8pG7dujJs2DC5cOFCuWsQEbl165aMHTtW6tatKzVq1JDu3bvLK6+8IgCkUaNGcuTIkXKPt3LlSvHz8xMAYjKZZODAgbJq1Srb53zooYckNTVV3n//ffH29hYA0qRJE9slHTt37pS6deuWOCtWr9dL69atJTExsULzvqLLa+PGjfc9M/e3r3nz5omIcPlVs+WnREXPzq3s/Bk/frzo9Xpp2LCheHh4iLe3twwePFhSU1NL9HPjxg3p3bu3GAwGadasmbzwwgvy4osvCgBp3ry57RKO77//Xpo0aSJGo1G6d+8uV65cKdfnOHbsWJnr+FtvvVXueXIXKnB27r59+6Rt27ai1WoFgPj5+cmCBQuq1bxcs2ZNuX4PNm7caOsrOjpa6tSpI7Vq1ZLw8HB59913BYAEBgaWuOxGROSPf/yjzJ07957zp6zv/OLFi8VoNAoAady4sfz73/8u9zIScbJLXKjiVq1aJdOmTSsxLD8/X6ZPny5eXl6Sm5tb7ra4vBzP2ZafkktcKmP8+PFSp04dh/XnSBUJUXtw9nnZv39/OXfunMP7dWSIOsW9c13JlStXMGXKlFLHAjw9PeHv7w+r1Qqr1Qqj0ahShVQWLr/yuXu5A1WeM81Lq9Vqu+Tl6NGjMBgMqt0ZylGc4t65rsRoNEKv12PdunW4evUqrFYr0tLSsHbtWrzyyiuIioqy6/FIsi8uP3WdOnWqzMf43X1FRUWpXapbio6OxpkzZ/Djjz9izJgxeO2119QuqcoxRB3MYrHgyy+/xA8//IAWLVrAaDSiTZs2WL9+PRYtWoSPPvpI7RKpDFx+ZXvppZewfv16ZGVloVmzZkhISLBr+61atSp1ScS9Xhs2bLBrv2qo6nlZFUwmE1q1aoU//elPmD9/Ptq0aaN2SVWOu3NVEBISgq+++krtMkghLr/7W7hwIRYuXKh2GS7BGefl66+/Xu0ePF7VuCVKRESkEEOUiIhIIYYoERGRQgxRIiIihRiiRERECjFEiYiIFGKIEhERKcQQJSIiUoghSkREpBBDlIiISCGGKBERkUIMUSIiIoUYokRERArd9ykucXFxjqyDFEpJSQHA5eWs7i6/qnbp0iWuI3biqGVGyjlyGWlERH47IC4uDpGRkQ4rgIiA330N7So8PNwpnkVJZG9V+b36P/GlQpScX7169fDqq69i0qRJapdC5JbWr1+PqVOnIjs7W+1SqGrF85ioC2rQoAGuXLmidhlEbisrKwve3t5ql0EOwBB1QX5+frh8+bLaZRC5rezsbIaom2CIuqAGDRowRIlUdOvWLYaom2CIuiA/Pz/uziVSEbdE3QdD1AVxS5RIXQxR98EQdUF+fn5IT09HcXGx2qUQuSWGqPtgiLqgBg0aoLCwENevX1e7FCK3xBB1HwxRF+Tn5wcA3KVLpBKGqPtgiLqgBg0aAABPLiJSSXZ2NmrWrKl2GeQADFEXZLFYYDKZuCVKpBJuiboPhqiL8vX15ZYokUp4naj7YIi6KN76j0gdubm5sFqtDFE3wRB1Ubz1H5E67t50niHqHhiiLoo3XCBSB0PUvTBEXRRv/UekDoaoe2GIuihuiRKpgyHqXhiiLsrPzw+3b9/G7du31S6FyK3cDVFeJ+oeGKIuijdcIFJHdnY2jEYjPD091S6FHIAh6qJ46z8idfBGC+6FIeqi6tevD51Oxy1RIgdjiLoXhqiL8vDwQL169bglSuRgvFuRe2GIujBe5kLkeNwSdS8MURfGW/8ROR5D1L0wRF0Yb/1H5HgMUffCEHVh3BIlcjyGqHthiLowbokSOR5D1L0wRF2Yn58frl27hsLCQrVLIXIb2dnZvFuRG2GIurAGDRqguLgY6enpapdC5DaysrJgsVjULoMchCHqwnjrPyLH4+5c98IQdWF3Q5THRYkco6CgAPn5+QxRN8IQdWFmsxk1atTgliiRg2RlZQHgY9DcCUPUxfG5okSOw2eJuh+GqIvjrf+IHIch6n481C6A7O/27dv45ZdfcPXqVVitVuzduxdz5szB5cuX8csvvyAtLQ0TJkzAlClT1C6VyGndunULI0aMQI0aNeDt7Y1atWrhxo0bAIAvvvgCDRs2tA339vZGixYtVK6YqoJGRETtIsg+EhMTMXLkSNy5c8c2TKPRwMPDA1qtFoWFhSgqKgIAJCUloWfPnmqVSuQS2rRpg5MnT0Kv10Or/XXHXnFxMYqLi23fNQDo0aMHdu/erVaZVHXiuTvXhQwYMABms7nEMBGB1WpFfn6+7Uut1+vx2GOPqVEikUsZPHgwPD09bd+x/Px8WK3WEgGq0WgwceJEFaukqsQQdSEGgwEzZsyAh0fZe+kfeeQRGAwGB1VF5Lr69euHgoKCMsepU6cOhg4d6qCKyNEYoi7m+eefh5eX133f9/T0xJ/+9CcHVkTkuoKDg8u8xZ9er8eECRPg6enpwKrIkRiiLsZisWD8+PHQ6/X3fL+goIDHQonsRKfT4cknn7zv3p+ioiKMHTvWwVWRIzFEXdCMGTNwv/PFdDodgoKCHFwRkesaMGAAiouLSw338PBA//790bRpU8cXRQ7DEHVBDRs2xPDhw++5NdqpU6dSJx8RkXL9+/e/5z+thYWFmDx5sgoVkSMxRF3UnDlzSj0CjcdDiezPx8cHHTp0KDXc398fjz/+uAoVkSMxRF1U69at8ec//7nE1mhBQQF69OihYlVErmnQoEElvmt6vR4vvPCC7dpRcl282YIL2717N3r16mX7W6fTISMjg7ckI7Kz7777rsS113q9Hr/88gt8fHxUrIocgDdbcGU9e/bEI488Ap1OBwB4+OGHGaBEVeCRRx5BnTp1APwaoJGRkQxQN8EQdXFz585FcXExdDodj4cSVRGtVosBAwZAq9XCarVi0qRJapdEDsIQdXGDBw9GYGAgioqKSuzaJSL76t+/P4qLi9GmTRt07dpV7XLIQdzqmGh4eDgSEhLULoOqAUev9nFxcYiMjHRon0RkX/f43Yh3u0ehBQUFYfr06WqXYXeRkZGYNm3aPf8DtlqtWLp0KebMmaNCZdVLSkoKli9frlr/sbGxqvVNVW/x4sWYNm1aqVtv3l3vuPydU1m/G24Xoo0aNUJERITaZdhdZGQkunbtet/P1gEKuIwAACAASURBVLNnTzRq1MjBVVVPaoaoK6579F/BwcH3/Z4tX76cy9+J3e93g8dE3QQDlKjq8XvmfhiiRERECjFEiYiIFGKIEhERKcQQJSIiUoghSkREpBBDlIiISCGGKBERkUIMUSIiIoUYokRERAoxRImIiBRiiBIRESnEECUiIlKIIUpERKQQQ7QMS5YsQf369aHRaPDee++pXY7dJCYmIiAgABqNBhqNBn5+fhg5cuQDpzty5AiioqLQrFkzeHl5oV69eujQoQNef/112zhRUVG2dh/02rp1a6la/va3v5VZw9tvvw2NRgOtVotWrVrhm2++qfT8cDddunSBTqdDx44d7d722LFjUbNmTWg0Ghw+fLjC423btg0WiwVbtmyxe21KFRcXY9myZQgODnZYn7//Xtzr1bRpU7v0xfWhchiiZZg1axaSk5PVLsPuQkNDce7cOQQGBsJiseDKlSv4+OOPy5zm2LFjCA4Ohp+fH3bt2oWsrCwkJyfjySefRFJSUolxv/zyS9y8eRNWqxWXL18GAAwcOBAFBQXIyclBeno6nnvuuVK1AMDatWthtVrvWUNRURHeeecdAECfPn1w6tQp9OjRozKzwi0dOHAAvXv3rpK2165diw8++EDxeCJSFWUpdubMGfTo0QMzZsxAbm6uw/r9/XdURCAiKCwsRG5uLq5evQqTyWSXvrg+VA5D1M7y8vIc+h+royxZsgS1atXC8uXL0bRpUxgMBrRo0QKvvfYajEajbTyNRoNu3brBYrHAw8OjxHC9Xg+TyQQfHx907ty5VB+dO3fGlStXsGnTpnvWkJiYiIYNG9r/w7kpjUajdgmlDBgwAFlZWXj66afVLgVHjhzBnDlzMHHixCrZSlNCp9PBaDSifv36aNGihV3b5vqgDEPUztatW4f09HS1y7C7GzduICsrCxkZGSWGe3p6ltjVEhMTU67/kMePH4+nnnqqxLBJkyYBANasWXPPad5++23MnDmzoqXTfej1+ippt7w/xo740RYRxMfH4/3336/wtB06dEBiYiJGjBgBLy+vKqiucu73z6ZSXB+UYYgqsHv3bjz66KMwmUzw9vZGu3btkJ2djWnTpmHmzJlITU2FRqNB8+bNsXz5cpjNZmi1WnTu3Bm+vr7Q6/Uwm83o1KkTQkJC0LhxYxgMBtSqVQuzZ89W++PdU5cuXZCTk4M+ffrg22+/rZI++vTpg9atW2PXrl04ffp0ife+/fZb5Obm4oknnqiSvqujoqIivPLKK/D394fRaET79u0RGxsLAHZZr86ePYtWrVrBbDbDaDQiJCQEe/fuLXcNwK8/Sm+99RZatmwJLy8vWCwWvPjii6X6Ks94e/fuhb+/PzQaDd59910AwOrVq2E2m2EymbB582b069cP3t7eaNSoEWJiYkrVunDhQrRs2RJGoxH16tVDs2bNsHDhQkRERChbCE6C64OK64O4kbCwMAkLC6vQNGfOnBEAsmbNGhERuX37tnh7e8vixYslLy9Prly5IkOHDpVr166JiEhoaKgEBgaWaOPvf/+7AJD9+/dLTk6OXL9+XZ588kkBIJ9//rlcu3ZNcnJyZMqUKQJADh8+XOHPBkBiY2MrNE1gYKBYLJZyjZubmyuPPPKIABAA0qZNG1m8eLHcuHGjzOkuX74sAGTQoEEPrOWnn36SFStWCACZNm1aifeHDBki69evl1u3bgkA6du3b7nq/r3Y2FhRY7VX0u+sWbPEy8tLEhISJDMzU1566SXRarVy4MABEancetW3b18JCAiQn376SaxWq/zwww/y2GOPicFgkB9//LHcNbz88sui0Whk6dKlkpmZKbm5ubJq1SoBIIcOHbK1U97xfv75ZwEgK1euLDEtANmxY4dkZWVJenq6hISEiNlsloKCAtt4CxYsEJ1OJ5s3b5bc3Fw5ePCg+Pr6Sq9evSo03+/lsccekw4dOiieXul6d6/v6NSpU+XYsWOlxuX6UHXrQxnLL44h+gC/D9EffvhBAMjWrVvvOX5ZIXrr1i3bsI8++kgAlPgyfPfddwJANmzYUKEaRao+REVECgoKZMWKFdKqVStbmNavX1+SkpLuO01FQ/TmzZtiNpuldu3akpubKyIiqamp0qhRI8nPz3ebEM3LyxOTySRRUVG2Ybm5ueLl5SWTJk0SkcqtV3379i0VCkePHhUAMmvWrHLVkJubKyaTSR5//PES7cTExJT4MSzveCJl/2jm5eXZht39wT179qxtWJcuXeTRRx8t0ce4ceNEq9VKfn6+VIaaIXr3u/bbV1khyvXhV/ZcH8oKUe7OraCAgADUr18fI0eOxPz583H+/HlF7Xh6egIACgsLbcPuHpO439mpatPr9ZgyZQpOnjyJffv2YfDgwUhPT0d4eDgyMzPt0ofFYsHw4cORmZmJDRs2AACWLVuGSZMm2eaZOzh9+jRyc3Px8MMP24YZjUb4+fnh1KlT952uMutVu3btYLFYcPTo0XLVcPbsWeTm5qJv375ltlve8Sri7uf87We6c+dOqbM5i4qKoNfrodPp7Na3o/327FwRwdSpU8s9LdeHql8fGKIVZDQasXPnTnTv3h0LFixAQEAAoqKikJeXp3ZpDvXYY4/h008/xcSJE3Ht2jXs2rXLbm3fPcHovffew82bNxEfH48JEybYrX1nkJOTAwCYN29eiWsDL1y4UKWXWuj1etsP0YNquHTpEgDAx8enzDbLO15l9e/fHwcPHsTmzZuRl5eH//znP9i0aROeeuoppw7R31u+fHmJIKtKXB8ejCGqQNu2bbFlyxakpaUhOjoasbGxWLJkidpl2dU333yDZcuW2f4ODQ0t8d/sXaNGjQIAu/6wd+zYEUFBQfjuu+8wfvx4hIeHo3bt2nZr3xnc/YFZtmxZia0QEUFKSkqV9FlYWIiMjAz4+/uXqwaDwQAAyM/PL7Pd8o5XWfPnz0efPn0wevRoeHt7Y+jQoYiIiCjXdYpUGteH8mGIVlBaWhpOnDgB4NeV6o033kCnTp1sw1zFwYMHYTabbX/n5+ff8zPePYu2ffv2du3/7tZoQkICpk+fbte2ncHdMynLusuLve3atQvFxcXo1KlTuWp4+OGHodVqsXv37jLbLe94lXX8+HGkpqbi2rVrsFqtuHjxIlavXu2y/4BdvnwZY8aMqbL2uT6UD0O0gtLS0jBhwgScOnUKBQUFOHToEC5cuICgoCAAQJ06dZCWlobz58/j1q1b1fb45v1YrVZcvXoVSUlJJUIUAIYMGYK4uDjcvHkTWVlZ2Lx5M+bMmYNBgwbZPUQjIiJQr149DBkyBAEBAXZt2xkYDAaMGTMGMTExWL16NbKzs1FUVIRLly7Z7gJVWQUFBcjKykJhYSG+//57TJkyBU2aNMHo0aPLVYOPjw9CQ0ORkJCAdevWITs7G0ePHi11DV55x6usyZMnw9/fH7dv37Zru9WNiCAvLw+JiYnw9va2W7tcHxSq0ClKTq6iZ+cuXbpUfH19BYCYzWYZOnSonD9/XoKDg6V27dqi0+nkD3/4g7z88stSWFgoIiLff/+9NGnSRIxGo3Tv3l3mzp0rJpNJAEjTpk1lz549smjRIrFYLAJAfH195ZNPPpENGzbY+qpdu7bExMRU6LOhAmfnbty48b5n/f32tXHjRts0X375pURGRkpgYKB4eXmJp6entGzZUubPny937twp1Ud2drb06NFD6tSpIwBEq9VK8+bNZcGCBfetpV69ejJ58mTbe7Nnz5bk5GTb3/PmzRM/Pz9be23atJE9e/ZUaD45y9m5IiL5+fkSHR0t/v7+4uHhIT4+PhIaGirHjx+X5cuXV2q9Wr9+vfTu3Vvq168vHh4eUrduXRk2bJhcuHCh3DWIiNy6dUvGjh0rdevWlRo1akj37t3llVdeEQDSqFEjOXLkSLnHW7lypW35mkwmGThwoKxatcr2OR966CFJTU2V999/X7y9vQWANGnSxHYJxs6dO6Vu3bol1mG9Xi+tW7eWxMTECi+zlJQU6datmzRo0MDWnp+fnwQHB8vu3bsr1FZFl395v6Pz5s0TEeH6UMXrAy9x+T9KLnFxFhUJUXfmTCFKFbNq1apS1xfn5+fL9OnTxcvLy3bJlBq4/B3PnutDWSH635ubEhE5qStXrmDKlCmljtd5enrC398fVqsVVqu1xH2eyXU5cn3gMVEicnpGoxF6vR7r1q3D1atXYbVakZaWhrVr1+KVV15BVFQU0tLSyvWIvqioKLU/DlVSedYHex1P5pYoETk9i8WCL7/8Eq+++ipatGiBnJwc1KhRA23btsWiRYswbtw4eHh4OMWjtajyyrM+2AtDlIhcQkhICL766iu1y6BqwlHrA3fnEhERKcQQJSIiUoghSkREpBBDlIiISCGGKBERkUIMUSIiIoUYokRERAoxRImIiBRiiBIRESnEECUiIlKIIUpERKQQQ5SIiEghhigREZFCbvcUl4SEBGg0GrXLqBKRkZGIjIxUuwwqg6uue1Q+XP6ux61CdMaMGQgPD1e7DJcnIli4cCHOnj2L6OhotGrVSu2SVBccHIzY2Fi1y3ALmZmZWLRoEW7evIn58+ejQYMGapdELkwjfEotVYGCggKMGDEC27ZtQ0JCAvr166d2SeQGTpw4gf79+0Ov1+OLL75A8+bN1S6JXFs8j4lSlfD09MSGDRsQFRWFwYMHcyuMqlxycjJ69OiBBg0aICUlhQFKDuFWu3PJsXQ6HdauXYtatWphxIgRyM7OxnPPPad2WeSCEhISMGrUKPTv3x8ff/wxjEaj2iWRm2CIUpXSaDRYunQp6tevj/HjxyMzMxOzZ89WuyxyIStWrMCMGTMwefJkLFu2DFotd7CR4zBEySGio6NRo0YNTJkyBRkZGVi0aJHaJZGTKyoqwtSpU7F69WosWrSI/5yRKhii5DDPP/88LBYLxowZg6ysLKxatYpbDaRIbm4uhg0bhu3btyMmJoaXdpFqGKLkUCNHjoS3tzciIyORlZWFjz76CHq9Xu2yyIncuHEDgwYNwsmTJ/HVV18hJCRE7ZLIjXEzgBxu4MCB2LZtG7Zu3YqhQ4ciLy9P7ZLISaSmpiI4OBhpaWlITk5mgJLqGKKkit69e2PHjh1ISUlBv379kJ2drXZJVM3t378fXbt2hcViwb59+9CyZUu1SyJiiJJ6unTpgt27d+PMmTPo06cPrl+/rnZJVE1t2rQJffr0QadOnbBjxw7Ur19f7ZKIADBESWVt27bF3r17cfPmTfTo0QOXLl1SuySqZt555x2EhoZi2LBh2Lp1K2rWrKl2SUQ2DFFSXbNmzbBnzx7odDqEhITg7NmzapdE1YCIYP78+Zg2bRr+9re/Ye3atfDw4LmQVL3w3rlUbWRkZKB///64cOECtm/fjvbt26tdEqkkPz8fY8aMQWJiIj788EOMGDFC7ZKI7oX3zqXqo06dOvj666/Rtm1b9OrVCykpKWqXRCrIzMzEE088gS+++ALbt29ngFK1xhClaqVGjRr4/PPP0bNnTzz++OP46quv1C6JHOj8+fPo1q0bzp49i6SkJPTq1UvtkojKxBClasfLywuxsbF46qmn8PTTT2Pjxo1ql0QOcPToUXTv3h0eHh7Yt28fOnTooHZJRA/EEKVqydPTE5988gmeffZZREREYP369WqXRFXo7p2HWrVqhT179qBx48Zql0RULjzVjaotnU6H9957D7Vq1cJf//pXZGVlYdq0aWqXRXa2fv16jB8/HsOHD8cHH3zA20CSU2GIUrWm0WiwePFi1KlTB9OnT8eVK1f4BBgXISL4xz/+gX/84x+Ijo7GG2+8AY1Go3ZZRBXCECWnEB0dDYvFgueffx65ublYsWIFf3CdWGFhISZNmoQPP/wQ7733HsaPH692SUSKMETJaUyYMAEWiwXPPvsssrKysG7dOl5874Ru376NiIgI7NmzB5s3b8aAAQPULolIMf4CkVMZNmwYvL29ER4ejqysLMTGxsLLy0vtsqicLl++jAEDBuDy5ctISkpC586d1S6JqFJ4di45nQEDBuCLL77Arl270L9/f9y+fVvtkqgcjh8/jqCgIOTn52Pfvn0MUHIJDFFySj179sTOnTtx9OhR9O3bFxkZGWqXRGXYuXMnunfvjoYNG2L37t1o0qSJ2iUR2QVDlJxW586d8c033yAtLQ09e/bE5cuX1S6J7iE+Ph4DBgxA3759sWPHDtSrV0/tkojshiFKTq1169bYs2cP7ty5g969e+PixYtql0S/sWLFCkRFRWHcuHGIi4uD0WhUuyQiu2KIktNr2rQp9uzZAy8vL4SEhODHH39UuyS3V1RUhEmTJmHmzJl45513sGLFCmi1/Lkh18O1mlyCn58fkpKS0LBhQ4SEhODw4cNql+S2cnJyMHjwYKxfvx4xMTF4/vnn1S6JqMowRMll1K5dG1999RU6dOiA3r1749tvv1W7JLdz48YNPPHEE0hJScHXX3+N8PBwtUsiqlIMUXIpZrMZW7ZsQd++ffHEE0/g//2//6d2SW4jNTUVXbt2xZUrV5CcnIxu3bqpXRJRlWOIksu5+yi1yMhIDBo0CPHx8WqX5PL27duHrl27onbt2khJSUGLFi3ULonIIXjHInJJOp0O69atQ61atTBs2DBkZWVh7Nixapflkj799FOMGDECTzzxBP73f/8XJpNJ7ZKIHIYhSi5Lo9Hg7bffhq+vL8aNG4ebN29i1qxZapflUlasWIEZM2bgL3/5C9asWcN7GZPb4RpPLi86OhomkwlTp07F9evX+Sg1OxARzJ07F2+++SZeeeUVzJ8/X+2SiFTBECW38MILL6BWrVr4y1/+glu3bmHlypWlrlvMz8/H2rVreUkGgDNnzqBmzZrw8/Mr9V5+fj5Gjx6NTz/9FB9//DGGDx+uQoVE1QNDlNzGqFGj4O3tjaioKNy8eRP//Oc/odfrAfz6fMvw8HBs3boVISEhaN++vcrVquuFF17A5cuX8e2336JGjRq24RkZGRg8eDB++OEHbN++HT179lSxSiL18excciuDBg3C559/js8++wyhoaHIy8uDiGDMmDHYtm0bdDodXnrpJbXLVNVXX32F7du34/jx4wgLC0NhYSEA4KeffkK3bt1w7tw5JCUlMUCJAGhERNQugsjRvvvuO/Tr1w/t27dH27ZtsWbNGhQXF9veT05ORteuXVWsUB1FRUV4+OGHcebMGRQVFUGn0+GZZ57BxIkT8fTTT6N+/frYtm0bGjVqpHapRNVBPEOU3NahQ4fQq1cv3Lp1C7/9Gnh4eODRRx91yzse/c///A8mTpxYYn5oNBro9Xr06dMH8fHxJXbvErm5eO7OJbe1d+9eZGdn4/f/RxYWFiI5ORk7duxQqTJ13Lp1Cy+//HKp4SKCgoIChIeHM0CJfochSm7pX//6F6ZOnXrf93U6HWbNmlUqYF3ZG2+8gaysrPt+5nHjxuHLL790cFVE1Rt355LbSUxMRERERIljoPezadMmDBo0yAFVqevChQto0aIFCgoK7juOVquF0WhEcnKy25+9TPR/uDuX3IvVakVMTAxExHZ5y/3odDrMmTOnXGHr7ObMmfPAre7i4mLk5OSgX79+yMjIcFBlRNUbQ5Tcil6vR0JCAs6cOYOJEyfCYDDc91Z1RUVF+PHHHxETE+PgKh1r//79iI2NhdVqvef7Go0GOp0OJpMJ48aNw7Zt21CnTh0HV0lUPXF3Lrm17OxsrF+/Hm+++SYuX74MrVaLoqIi2/sajQYNGzZEamoqPD09Vay06nTt2hX/+c9/bNeD3qXX62G1WtGuXTtMnjwZI0aMgNlsVqlKomqJu3PJvXl7e2Pq1Kn4+eefsXnzZnTq1AkAbLt6RQRpaWn45z//qWKVVSc2Nhb79++3BejdrU69Xo/IyEgcPHgQR48exbhx4xigRPfALVGi30lOTsbSpUuxadMm6HQ6WK1W+Pr64vz58zAYDGqXZzf5+flo3rw5Ll26ZNvqbNOmDV544QWMGDECNWvWVLtEouqON1ugqvf2228jJSVF7TIqLCcnB6mpqTh37hwKCwvRvn17l3rY9OnTp3Hs2DFotVo0btwYgYGBTneskw9cJ5XF8wb0VOVSUlKwb98+BAUFqV1KhZjNZrRv3x5t2rTBTz/9hJ9//hkBAQFV+szMhIQEBAUFVflt9fLz85GWloaOHTuiSZMmDzxTubq5dOkS9u3bp3YZRHyKCzlGUFCQ0281FBcXIzc3t0rv2qPRaDB9+nRERERUWR/Ar1vZznyMMy4uDpGRkWqXQcRLXIjKS6vVusxt75w5QImqE4YoERGRQgxRIiIihRiiRERECjFEiYiIFGKIEhERKcQQJSIiUoghSkREpBBDlIiISCGGKBERkUIMUSIiIoUYokRERAoxRImIiBRiiBIRESnEEKVqZ8mSJahfvz40Gg3ee+89tcspl+LiYixbtgzBwcEO6zMxMREBAQHQaDTQaDTw8/PDyJEjHzjdkSNHEBUVhWbNmsHLywv16tVDhw4d8Prrr9vGiYqKsrX7oNfWrVtL1fK3v/2tzBrefvttaDQaaLVatGrVCt98802l5weRGhiiVO3MmjULycnJapdRbmfOnEGPHj0wY8YM5ObmOqzf0NBQnDt3DoGBgbBYLLhy5Qo+/vjjMqc5duwYgoOD4efnh127diErKwvJycl48sknkZSUVGLcL7/8Ejdv3oTVasXly5cBAAMHDkRBQQFycnKQnp6O5557rlQtALB27VpYrdZ71lBUVIR33nkHANCnTx+cOnUKPXr0qMysIFINQ5RcQl5enkO3Au86cuQI5syZg4kTJ6Jjx44O77+ilixZglq1amH58uVo2rQpDAYDWrRogddeew1Go9E2nkajQbdu3WCxWODh4VFiuF6vh8lkgo+PDzp37lyqj86dO+PKlSvYtGnTPWtITExEw4YN7f/hiFTAECWXsG7dOqSnpzu83w4dOiAxMREjRoyAl5eXw/uvqBs3biArKwsZGRklhnt6emLLli22v2NiYmAymR7Y3vjx4/HUU0+VGDZp0iQAwJo1a+45zdtvv42ZM2dWtHSiaokhSk5j9+7dePTRR2EymeDt7Y127dohOzsb06ZNw8yZM5GamgqNRoPmzZtj+fLlMJvN0Gq16Ny5M3x9faHX62E2m9GpUyeEhISgcePGMBgMqFWrFmbPnq32x3OILl26ICcnB3369MG3335bJX306dMHrVu3xq5du3D69OkS73377bfIzc3FE088USV9EzkaQ5ScQk5ODgYOHIiwsDBkZGTgzJkzaNGiBQoKCrB8+XI8/fTTCAwMhIjg7NmzmDZtGl588UWICNasWYOffvoJV65cQY8ePXDo0CHMnTsXhw4dQkZGBp599lm89dZbOHLkiNofs8rNnj0bjzzyCI4cOYLu3bujbdu2ePPNN0ttmVbWhAkTAKDUiWFLly7FjBkz7NoXkZoYouQUzp8/j+zsbLRt2xYGgwG+vr5ITExEvXr1HjhtmzZtYDKZULduXQwbNgwA4O/vj3r16sFkMtnOaD116lSVfobqwGg0Ijk5GStWrECrVq1w4sQJREdHo3Xr1ti9e7fd+nn22WdhNpvx0UcfIS8vDwBw7tw5HDhwAMOHD7dbP0RqY4iSUwgICED9+vUxcuRIzJ8/H+fPn1fUjqenJwCgsLDQNkyv1wPAfc8mdTV6vR5TpkzByZMnsW/fPgwePBjp6ekIDw9HZmamXfqwWCwYPnw4MjMzsWHDBgDAsmXLMGnSJNsyIHIFDFFyCkajETt37kT37t2xYMECBAQEICoqyraVQ8o89thj+PTTTzFx4kRcu3YNu3btslvbd08weu+993Dz5k3Ex8fbdvMSuQqGKDmNtm3bYsuWLUhLS0N0dDRiY2OxZMkStcuq1r755hssW7bM9ndoaGiJrfC7Ro0aBQB2vc61Y8eOCAoKwnfffYfx48cjPDwctWvXtlv7RNUBQ5ScQlpaGk6cOAEA8PHxwRtvvIFOnTrZhtG9HTx4EGaz2fZ3fn7+PefZ3bNo27dvb9f+726NJiQkYPr06XZtm6g6YIiSU0hLS8OECRNw6tQpFBQU4NChQ7hw4QKCgoIAAHXq1EFaWhrOnz+PW7duuc3xzfuxWq24evUqkpKSSoQoAAwZMgRxcXG4efMmsrKysHnzZsyZMweDBg2ye4hGRESgXr16GDJkCAICAuzaNlG1IERVLCwsTMLCwso9/tKlS8XX11cAiNlslqFDh8r58+clODhYateuLTqdTv7whz/Iyy+/LIWFhSIi8v3330uTJk3EaDRK9+7dZe7cuWIymQSANG3aVPbs2SOLFi0Si8UiAMTX11c++eQT2bBhg62v2rVrS0xMTIU+W0pKinTr1k0aNGggAASA+Pn5SXBwsOzevbtCbYmIAJDY2Nhyjbtx40YJDAy09Xu/18aNG23TfPnllxIZGSmBgYHi5eUlnp6e0rJlS5k/f77cuXOnVB/Z2dnSo0cPqVOnjgAQrVYrzZs3lwULFty3lnr16snkyZNt782ePVuSk5Ntf8+bN0/8/Pxs7bVp00b27NlTofkUGxsr/PmiaiBOIyLi4NwmNxMeHg4AiI+PV7mS6k+j0SA2NhYRERFql1KtxcXFITIyEvz5IpXFc3cuERGRQgxRot84depUuR7/FRUVpXapRFQNeDx4FCL30apVK+4iJKJy45YoERGRQgxRIiIihRiiRERECjFEiYiIFGKIEhERKcQQJSIiUoghSkREpBBDlIiISCGGKBERkUIMUSIiIoUYokRERAoxRImIiBRiiBIRESnEECUiIlKIj0Ijh9i3bx/Cw8PVLsMpLFu2DPHx8WqXUa1dunRJ7RKIADBEyQG6du2qdglOw9PTE1otdxA9SKNGjRAWFqZ2GUTQCJ9ATFRtaDQal1yUHwAACLVJREFUxMbGIiIiQu1SiOjB4vkvLxERkUIMUSIiIoUYokRERAoxRImIiBRiiBIRESnEECUiIlKIIUpERKQQQ5SIiEghhigREZFCDFEiIiKFGKJEREQKMUSJiIgUYogSEREpxBAlIiJSiCFKRESkEEOUiIhIIYYoERGRQgxRIiIihRiiRERECjFEiYiIFGKIEhERKcQQJSIiUoghSkREpBBDlIiISCGGKBERkUIMUSIiIoUYokRERAoxRImIiBRiiBIRESnEECUiIlKIIUpERKQQQ5SIiEghhigREZFCGhERtYsgckejRo3C4cOHSww7f/48fHx8YDabbcP0ej22bNmChg0bOrpEIipbvIfaFRC5q5YtW+Ljjz8uNfz27dsl/m7VqhUDlKia4u5cIpUMGzYMGo2mzHH0ej1Gjx7tmIKIqMIYokQqCQwMxB//+Edotff/GhYWFiIyMtKBVRFRRTBEiVT0zDPP3DdENRoNHn30UTRt2tSxRRFRuTFEiVQUGRmJ4uLie76n1WrxzDPPOLgiIqoIhiiRivz8/BASEgKdTnfP90NDQx1cERFVBEOUSGWjRo0qNUyr1aJ3797w9fVVoSIiKi+GKJHKwsPD73lc9F7hSkTVC0OUSGXe3t548skn4eHx38u2dTodBg0apGJVRFQeDFGiamDkyJEoKioCAHh4eGDgwIGwWCwqV0VED8IQJaoGBg4cCKPRCAAoKirCiBEjVK6IiMqDIUpUDRgMBgwdOhQAYDKZ0K9fP5UrIqLy4L1zSVWXLl1CcnKy2mVUC40bNwYAdOnSBZ999pnK1VQPjRs3RteuXdUug+i++BQXUlVcXBxva0f3FRYWhvj4eLXLILofPsWFqgd3/19Oo9EgNjYWJ06cwLx580qcqeuuwsPD1S6B6IF4TJSoGmGAEjkXhihRNcIAJXIuDFEiIiKFGKJEREQKMUSJiIgUYogSEREpxBAlIiJSiCFKRESkEEOUiIhIIYYoERGRQgxRIiIihRiiRERECjFEiYiIFGKIEhERKcQQJac3duxY1KxZExqNBocPH1a7nCqXmJiIgIAAaDSaEi9PT0/Ur18fvXr1wltvvYXMzEy1SyVyeQxRcnpr167FBx98oHYZDhMaGopz584hMDAQFosFIoLi4mKkp6cjLu7/t3M/IVH8YRjAn1nF3R1jNGIjYjUyokDz0EGiDILoIN1ySw8dLDpE52IhQyKIiApPSgjRcZlZD/2DuhR48lAgRYmJgcKymRLiprNo2dPhR/tjCU0n13H1+cBeZr/ffV9eBh6YP+tg9+7diMfjqK2txZs3b/xuV2RDU4iKbACGYaCyshLHjh3Dw4cP4TgOvnz5gpMnT2J6etrv9kQ2LIWobAiGYfjdwroSi8XQ1taGiYkJ3L9/3+92RDYshagUHZK4c+cO9u3bh2AwiIqKCly5cuWPdQsLC+jo6EB1dTXC4TDq6+th2zYAoLu7G+Xl5TBNE48fP0ZTUxMsy0I0GkUikcj7nb6+PjQ0NMA0TViWhQMHDiCTyfy1ht/a2toAAM+fP88d2+wzEVl1FPGRbdtc6WnY3t5OwzB47949Tk1N0XVddnV1EQAHBgZy6y5fvsxgMMje3l5OTU3x6tWrDAQCfP36de53APDly5ecnp7mxMQEjx49yvLycs7Pz5MkZ2ZmaFkWb9++zWw2y/HxcZ46dYqTk5PLqrFcAGjb9or27NmzhxUVFYt+n8lkCIBVVVVFOZNYLMZYLLaiPSJrzFGIiq9WGqKu69I0TZ44cSLveCKRyAvRbDZL0zTZ2tqatzcYDPLSpUsk/w+MbDabW/M7jEdGRkiS79+/JwA+e/bsj16WU2O5ChGiJGkYBisrK5fd73qaiUJUioCjy7lSVEZGRuC6Lo4fP77kuo8fP8J1XdTV1eWOhcNh7NixA0NDQ4vuKysrAwB8//4dAFBTU4Pt27fj7NmzuH79OkZHR/+5xlqZnZ0FSViWBUAzESkEhagUlVQqBQCIRCJLrpudnQUAXLt2Le9dyrGxMbiuu+x64XAYr169QmNjI27evImamhq0trYim82uWo1CGR4eBgDs378fgGYiUggKUSkqoVAIADA3N7fkut8h29nZCZJ5n/7+/hXVrK2txdOnT5FOpxGPx2HbNu7evbuqNQrhxYsXAICmpiYAmolIIShEpajU1dUhEAigr69vyXVVVVUIhUL//A9G6XQag4ODAP4LoVu3buHgwYMYHBxctRqFMD4+js7OTkSjUZw/fx6AZiJSCApRKSqRSATNzc3o7e3FgwcPkMlk8O7dO/T09OStC4VCOHfuHBKJBLq7u5HJZLCwsIBUKoXPnz8vu146ncbFixcxNDSE+fl5DAwMYGxsDIcOHVq1Gv+CJGZmZvDz50+QxOTkJGzbxpEjR1BSUoJHjx7l7olulpmIrKk1fpJJJI+XV1y+ffvGCxcucNu2bdyyZQsbGxvZ0dFBAIxGo3z79i1Jcm5ujvF4nNXV1SwtLWUkEmFzczM/fPjArq4umqZJANy7dy8/ffrEnp4eWpZFANy1axeHh4c5OjrKw4cPc+vWrSwpKeHOnTvZ3t7OHz9+/LXGSmAFT+c+efKE9fX1NE2TZWVlDAQCBJB7ErehoYE3btzg169f/9hbTDPR07lSBByDJP2LcNnsHMdBS0sLNvtpaBgGbNvGmTNn/G5l3Th9+jQAIJlM+tyJyKKSupwrIiLikUJURETEI4WoiIiIRwpRERERjxSiIiIiHilERUREPFKIioiIeKQQFRER8UghKiIi4pFCVERExCOFqIiIiEcKUREREY8UoiIiIh4pREVERDxSiIqIiHikEBUREfFIISoiIuJRqd8NiACA4zh+t+C7/v5+v1tYV1KpFKLRqN9tiCzJIEm/m5DNy3EctLS0+N2GrFOxWAzJZNLvNkQWk1SIioiIeJPUPVERERGPFKIiIiIeKURFREQ8UoiKiIh49Aub+cxnTmy4awAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbelEm0zhadD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f42fdb-10b0-4866-8cb0-7efbbcd951bc"
      },
      "source": [
        "# Запустим обучение и сохраним модель \n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=150) \n",
        "model.save( '/content/drive/MyDrive/Базы/Модели и веса к ДЗ/model_150epochs(rms).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "238/238 [==============================] - 33s 106ms/step - loss: 2.2181\n",
            "Epoch 2/150\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 1.9770\n",
            "Epoch 3/150\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 1.9272\n",
            "Epoch 4/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 1.8893\n",
            "Epoch 5/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 1.8559\n",
            "Epoch 6/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.8240\n",
            "Epoch 7/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.7917\n",
            "Epoch 8/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.7613\n",
            "Epoch 9/150\n",
            "238/238 [==============================] - 28s 120ms/step - loss: 1.7294\n",
            "Epoch 10/150\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.6961\n",
            "Epoch 11/150\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 1.6618\n",
            "Epoch 12/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.6285\n",
            "Epoch 13/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.5970\n",
            "Epoch 14/150\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.5664\n",
            "Epoch 15/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.5347\n",
            "Epoch 16/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 1.5018\n",
            "Epoch 17/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.4686\n",
            "Epoch 18/150\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.4358\n",
            "Epoch 19/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.4048\n",
            "Epoch 20/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 1.3740\n",
            "Epoch 21/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 1.3454\n",
            "Epoch 22/150\n",
            "238/238 [==============================] - 27s 111ms/step - loss: 1.3174\n",
            "Epoch 23/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.2907\n",
            "Epoch 24/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 1.2642\n",
            "Epoch 25/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 1.2379\n",
            "Epoch 26/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.2127\n",
            "Epoch 27/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.1871\n",
            "Epoch 28/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.1624\n",
            "Epoch 29/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.1374\n",
            "Epoch 30/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.1145\n",
            "Epoch 31/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.0938\n",
            "Epoch 32/150\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 1.0757\n",
            "Epoch 33/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 1.0574\n",
            "Epoch 34/150\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 1.0419\n",
            "Epoch 35/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.0265\n",
            "Epoch 36/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 1.0131\n",
            "Epoch 37/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.0002\n",
            "Epoch 38/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.9875\n",
            "Epoch 39/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.9745\n",
            "Epoch 40/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.9639\n",
            "Epoch 41/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.9550\n",
            "Epoch 42/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.9467\n",
            "Epoch 43/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.9388\n",
            "Epoch 44/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.9312\n",
            "Epoch 45/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.9239\n",
            "Epoch 46/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.9167\n",
            "Epoch 47/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.9101\n",
            "Epoch 48/150\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.9036\n",
            "Epoch 49/150\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.8972\n",
            "Epoch 50/150\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.8902\n",
            "Epoch 51/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.8835\n",
            "Epoch 52/150\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.8763\n",
            "Epoch 53/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.8686\n",
            "Epoch 54/150\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.8628\n",
            "Epoch 55/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.8575\n",
            "Epoch 56/150\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.8530\n",
            "Epoch 57/150\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.8484\n",
            "Epoch 58/150\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.8427\n",
            "Epoch 59/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.8392\n",
            "Epoch 60/150\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.8349\n",
            "Epoch 61/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.8306\n",
            "Epoch 62/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.8272\n",
            "Epoch 63/150\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.8241\n",
            "Epoch 64/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.8204\n",
            "Epoch 65/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.8174\n",
            "Epoch 66/150\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.8141\n",
            "Epoch 67/150\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.8110\n",
            "Epoch 68/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.8078\n",
            "Epoch 69/150\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.8057\n",
            "Epoch 70/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.8024\n",
            "Epoch 71/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.8003\n",
            "Epoch 72/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.7980\n",
            "Epoch 73/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.7952\n",
            "Epoch 74/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.7927\n",
            "Epoch 75/150\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.7898\n",
            "Epoch 76/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.7877\n",
            "Epoch 77/150\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.7850\n",
            "Epoch 78/150\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.7829\n",
            "Epoch 79/150\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7815\n",
            "Epoch 80/150\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7791\n",
            "Epoch 81/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.7765\n",
            "Epoch 82/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.7745\n",
            "Epoch 83/150\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.7730\n",
            "Epoch 84/150\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7718\n",
            "Epoch 85/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7694\n",
            "Epoch 86/150\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7681\n",
            "Epoch 87/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7662\n",
            "Epoch 88/150\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7654\n",
            "Epoch 89/150\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7631\n",
            "Epoch 90/150\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7625\n",
            "Epoch 91/150\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7610\n",
            "Epoch 92/150\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7591\n",
            "Epoch 93/150\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7581\n",
            "Epoch 94/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7561\n",
            "Epoch 95/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7554\n",
            "Epoch 96/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7536\n",
            "Epoch 97/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7522\n",
            "Epoch 98/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7510\n",
            "Epoch 99/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7504\n",
            "Epoch 100/150\n",
            "238/238 [==============================] - 26s 107ms/step - loss: 0.7487\n",
            "Epoch 101/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7479\n",
            "Epoch 102/150\n",
            "238/238 [==============================] - 26s 110ms/step - loss: 0.7461\n",
            "Epoch 103/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7454\n",
            "Epoch 104/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7446\n",
            "Epoch 105/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7434\n",
            "Epoch 106/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7425\n",
            "Epoch 107/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7415\n",
            "Epoch 108/150\n",
            "238/238 [==============================] - 26s 107ms/step - loss: 0.7406\n",
            "Epoch 109/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7394\n",
            "Epoch 110/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7390\n",
            "Epoch 111/150\n",
            "238/238 [==============================] - 25s 106ms/step - loss: 0.7381\n",
            "Epoch 112/150\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.7377\n",
            "Epoch 113/150\n",
            "238/238 [==============================] - 25s 106ms/step - loss: 0.7361\n",
            "Epoch 114/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7346\n",
            "Epoch 115/150\n",
            "238/238 [==============================] - 25s 106ms/step - loss: 0.7348\n",
            "Epoch 116/150\n",
            "238/238 [==============================] - 25s 107ms/step - loss: 0.7343\n",
            "Epoch 117/150\n",
            "238/238 [==============================] - 25s 107ms/step - loss: 0.7339\n",
            "Epoch 118/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7333\n",
            "Epoch 119/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7327\n",
            "Epoch 120/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7326\n",
            "Epoch 121/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7317\n",
            "Epoch 122/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7310\n",
            "Epoch 123/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7300\n",
            "Epoch 124/150\n",
            "238/238 [==============================] - 25s 106ms/step - loss: 0.7293\n",
            "Epoch 125/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7284\n",
            "Epoch 126/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7288\n",
            "Epoch 127/150\n",
            "238/238 [==============================] - 26s 107ms/step - loss: 0.7277\n",
            "Epoch 128/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7277\n",
            "Epoch 129/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7273\n",
            "Epoch 130/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7269\n",
            "Epoch 131/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7254\n",
            "Epoch 132/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7259\n",
            "Epoch 133/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7256\n",
            "Epoch 134/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7255\n",
            "Epoch 135/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7247\n",
            "Epoch 136/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7253\n",
            "Epoch 137/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7248\n",
            "Epoch 138/150\n",
            "238/238 [==============================] - 26s 111ms/step - loss: 0.7241\n",
            "Epoch 139/150\n",
            "238/238 [==============================] - 26s 107ms/step - loss: 0.7245\n",
            "Epoch 140/150\n",
            "238/238 [==============================] - 25s 107ms/step - loss: 0.7234\n",
            "Epoch 141/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7234\n",
            "Epoch 142/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7235\n",
            "Epoch 143/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7233\n",
            "Epoch 144/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7229\n",
            "Epoch 145/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7215\n",
            "Epoch 146/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7220\n",
            "Epoch 147/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7215\n",
            "Epoch 148/150\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.7222\n",
            "Epoch 149/150\n",
            "238/238 [==============================] - 25s 106ms/step - loss: 0.7213\n",
            "Epoch 150/150\n",
            "238/238 [==============================] - 26s 109ms/step - loss: 0.7214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEHzJjlRYK5-"
      },
      "source": [
        "model.compile(optimizer=Adadelta(), loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rPD8f5tY4up",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e87510-60ac-4fa5-91e3-16eced305198"
      },
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=50) \n",
        "model.save( '/content/drive/My Drive/Предобученные сети/model_150epochs(rms) + 50(ada).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "238/238 [==============================] - 33s 106ms/step - loss: 0.6854\n",
            "Epoch 2/50\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.6853\n",
            "Epoch 3/50\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.6853\n",
            "Epoch 4/50\n",
            "238/238 [==============================] - 24s 103ms/step - loss: 0.6852\n",
            "Epoch 5/50\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.6852\n",
            "Epoch 6/50\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.6851\n",
            "Epoch 7/50\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.6851\n",
            "Epoch 8/50\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.6850\n",
            "Epoch 9/50\n",
            "238/238 [==============================] - 26s 107ms/step - loss: 0.6850\n",
            "Epoch 10/50\n",
            "238/238 [==============================] - 25s 106ms/step - loss: 0.6849\n",
            "Epoch 11/50\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.6849\n",
            "Epoch 12/50\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.6848\n",
            "Epoch 13/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6848\n",
            "Epoch 14/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6848\n",
            "Epoch 15/50\n",
            "238/238 [==============================] - 25s 107ms/step - loss: 0.6847\n",
            "Epoch 16/50\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.6847\n",
            "Epoch 17/50\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.6846\n",
            "Epoch 18/50\n",
            "238/238 [==============================] - 25s 106ms/step - loss: 0.6846\n",
            "Epoch 19/50\n",
            "238/238 [==============================] - 25s 107ms/step - loss: 0.6845\n",
            "Epoch 20/50\n",
            "238/238 [==============================] - 26s 107ms/step - loss: 0.6845\n",
            "Epoch 21/50\n",
            "238/238 [==============================] - 25s 106ms/step - loss: 0.6845\n",
            "Epoch 22/50\n",
            "238/238 [==============================] - 26s 108ms/step - loss: 0.6844\n",
            "Epoch 23/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6844\n",
            "Epoch 24/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6843\n",
            "Epoch 25/50\n",
            "238/238 [==============================] - 25s 106ms/step - loss: 0.6843\n",
            "Epoch 26/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6843\n",
            "Epoch 27/50\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.6842\n",
            "Epoch 28/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6842\n",
            "Epoch 29/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6841\n",
            "Epoch 30/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6841\n",
            "Epoch 31/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6841\n",
            "Epoch 32/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6840\n",
            "Epoch 33/50\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.6840\n",
            "Epoch 34/50\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.6840\n",
            "Epoch 35/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6839\n",
            "Epoch 36/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6839\n",
            "Epoch 37/50\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.6839\n",
            "Epoch 38/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6838\n",
            "Epoch 39/50\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.6838\n",
            "Epoch 40/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6837\n",
            "Epoch 41/50\n",
            "238/238 [==============================] - 24s 101ms/step - loss: 0.6837\n",
            "Epoch 42/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6837\n",
            "Epoch 43/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6836\n",
            "Epoch 44/50\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.6836\n",
            "Epoch 45/50\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.6836\n",
            "Epoch 46/50\n",
            "238/238 [==============================] - 25s 103ms/step - loss: 0.6835\n",
            "Epoch 47/50\n",
            "238/238 [==============================] - 25s 106ms/step - loss: 0.6835\n",
            "Epoch 48/50\n",
            "238/238 [==============================] - 24s 102ms/step - loss: 0.6835\n",
            "Epoch 49/50\n",
            "238/238 [==============================] - 25s 105ms/step - loss: 0.6834\n",
            "Epoch 50/50\n",
            "238/238 [==============================] - 25s 104ms/step - loss: 0.6834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jrhHhh02_uO"
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/Предобученные сети/model_150epochs(rms) + 50(ada).h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_U_rY8UiRL2"
      },
      "source": [
        "# **Подготовка и запуск рабочей нейросети с генерацией ответов**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1428s\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv9utvcjh2co"
      },
      "source": [
        "# ######################\n",
        "# # Создаем рабочую модель для вывода ответов на запросы пользователя https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1455s\n",
        "# ######################\n",
        "# def makeInferenceModels():\n",
        "#   # Определим модель кодера, на входе далее будут закодированные вопросы(encoderForInputs), на выходе состояния state_h, state_c\n",
        "#   encoderModel = Model(encoderInputs, encoderStates) \n",
        "\n",
        "#   decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "#   decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "#   decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "#   # Берём ответы, прошедшие через эмбединг, вместе с состояниями и подаём LSTM cлою\n",
        "#   decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "#   decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "#   decoderOutputs = decoderDense(decoderOutputs) # и ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "#   # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "#   # на выходе предсказываемый ответ и новые состояния\n",
        "#   decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "#   return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSSOhZpgh9LI"
      },
      "source": [
        "######################\n",
        "# Создадим функцию, которая преобразует вопрос пользователя в последовательность индексов https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1593s\n",
        "######################\n",
        "def strToTokens(sentence: str): # функция принимает строку на вход (предложение с вопросом)\n",
        "  words = sentence.lower().split() # приводит предложение к нижнему регистру и разбирает на слова\n",
        "  tokensList = tokenizer.texts_to_sequences(words) # здесь будет последовательность токенов/индексов\n",
        "  # for word in words: # для каждого слова в предложении\n",
        "  #   tokensList.append(tokenizer.word_index[word]) # определяем токенизатором индекс и добавляем в список\n",
        "\n",
        "    # Функция вернёт вопрос в виде последовательности индексов, ограниченной длиной самого длинного вопроса из нашей базы вопросов\n",
        "  return pad_sequences([tokensList], maxlen=maxLenQuestions , padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0Dxd1eiEid"
      },
      "source": [
        "# ######################\n",
        "# # Устанавливаем окончательные настройки и запускаем модель https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=1645s\n",
        "# ######################\n",
        "\n",
        "# encModel , decModel = makeInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "# for _ in range(3): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "#   # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "#   statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "#   # Создаём пустой массив размером (1, 1)\n",
        "#   emptyTargetSeq = np.zeros((1, 1))    \n",
        "#   emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "#   stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "#   decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "#   while not stopCondition : # пока не сработало стоп-условие\n",
        "#     # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "#     # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "#     decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "#     #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "#     sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "#     sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "#     for word , index in tokenizer.word_index.items():\n",
        "#       if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "#         decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "#         sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "#     # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "#     if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "#       stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "\n",
        "#     emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "#     statesValues = [h, c] # и состояния, обновленные декодером\n",
        "#     # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "#   print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfhu067toXGQ"
      },
      "source": [
        "# **Загрузка и запуск предобученной модели**\n",
        "https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=2100s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Lg3eOVqKyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed3cb71-5054-4faf-f6a9-4d65e5156054"
      },
      "source": [
        "# Подгружаем модель из файла и выведем её параметры\n",
        "model = load_model('/content/drive/My Drive/Предобученные сети/model_150epochs(rms) + 50(ada).h5')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 200)    3018600     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    3018600     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 15093)  3033693     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,712,493\n",
            "Trainable params: 9,712,493\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEfb58cXqsKi"
      },
      "source": [
        "######################\n",
        "# Устанавливаем связи между слоями рабочей модели и предобученной https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=2174s\n",
        "######################\n",
        "def loadInferenceModels():\n",
        "  encoderInputs = model.input[0]   # входом энкодера рабочей модели будет первый инпут предобученной модели(input_1)\n",
        "  encoderEmbedding = model.layers[2] # связываем эмбединг слои(model.layers[2] это embedding_1)\n",
        "  encoderOutputs, state_h_enc, state_c_enc = model.layers[4].output # вытягиваем аутпуты из первого LSTM слоя обуч.модели и даем энкодеру(lstm_1)\n",
        "  encoderStates = [state_h_enc, state_c_enc] # ложим забранные состояния в состояния энкодера\n",
        "  encoderModel = Model(encoderInputs, encoderStates) # формируем модель\n",
        "\n",
        "  decoderInputs = model.input[1]   # входом декодера рабочей модели будет второй инпут предобученной модели(input_2)\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "  decoderEmbedding = model.layers[3] # связываем эмбединг слои(model.layers[3] это embedding_2)\n",
        "  decoderLSTM = model.layers[5] # связываем LSTM слои(model.layers[5] это lstm_2)\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding.output, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "\n",
        "  decoderDense = model.layers[6] # связываем полносвязные слои(model.layers[6] это dense_1)\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # выход с LSTM мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "    # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "    # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "  return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTpsqjakx2rs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792be57c-a428-4286-9fd3-979f45525078"
      },
      "source": [
        "######################\n",
        "# Устанавливаем окончательные настройки и запускаем рабочую модель над предобученной https://www.youtube.com/watch?v=JSPbJ9CNZ9w&t=2272s\n",
        "######################\n",
        "\n",
        "encModel , decModel = loadInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "for _ in range(6): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "  # Создаём пустой массив размером (1, 1)\n",
        "  emptyTargetSeq = np.zeros((1, 1))    \n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "  stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "  decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "  while not stopCondition : # пока не сработало стоп-условие\n",
        "    # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "    # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "    decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "    #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "    sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "    sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "    for word , index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "        sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "    # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "    emptyTargetSeq = np.zeros((1, 1)) # создаем пустой массив\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c] # и состояния, обновленные декодером\n",
        "    # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "  print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос : Привет\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            " что ты здесь делаешь \n",
            "Задайте вопрос : Как дела\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            " за ночь сделали пятнадцать я не знаю \n",
            "Задайте вопрос : Ты откуд\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            " я здесь люблю \n",
            "Задайте вопрос : Как тебя зовут \n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            " меня \n",
            "Задайте вопрос : Сколько тебе лет\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            " не знаю а сколько нужно \n",
            "Задайте вопрос : ты меня знаешь\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            " я \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98O0XcM9yCbm"
      },
      "source": [
        "# **Глоссарий**\n",
        "-  Seq2Seq - sequence-to-sequence модель, состоит из двух рекуррентных нейронных сетей (RNN): \n",
        "\n",
        "encoder (кодер), которая обрабатывает входные данные,\n",
        "\n",
        "decoder (декодер), которая генерирует данные вывода.\n",
        "- Yaml - удобный текстовый формат, позволяющий хранить структурированные данные в иерархии. https://ru.bmstu.wiki/YAML\n",
        "yaml.safe_load - безопасный метод загрузки данных из файлов, предотвращающий возможность запуска произвольного кода для файлов из ненадежных источников\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqJ3CgG6jJMq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}