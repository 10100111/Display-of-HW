{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7.Pro. Полносвязные сети, обучающая и тестовая выборки",
      "provenance": [],
      "collapsed_sections": [
        "Ah7dy1kFL2H9",
        "6CTlj7a_4JT9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10100111/Display-of-HW1/blob/main/7_Pro_%D0%9F%D0%BE%D0%BB%D0%BD%D0%BE%D1%81%D0%B2%D1%8F%D0%B7%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8%2C_%D0%BE%D0%B1%D1%83%D1%87%D0%B0%D1%8E%D1%89%D0%B0%D1%8F_%D0%B8_%D1%82%D0%B5%D1%81%D1%82%D0%BE%D0%B2%D0%B0%D1%8F_%D0%B2%D1%8B%D0%B1%D0%BE%D1%80%D0%BA%D0%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBMGknXIWG3M"
      },
      "source": [
        "Задание Pro\n",
        "\n",
        "Макс 10 баллов\n",
        "Повысьте точность модели по обнаружению мин (база sonar)  до 90 % на тестовой выборке. \n",
        "\n",
        "Можно использовать различные варианты слоев Dropout и BatchNormalization. Можно менять количество примеров в обучающей и проверочной выборках, но нельзя менять количество примеров в тестовой."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrfd6FzSLrE2"
      },
      "source": [
        "from tensorflow.keras.models import Sequential # НС прямого распространения\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization # Основные слои\n",
        "from tensorflow.keras import utils # Утилиты для to_categorical\n",
        "from tensorflow.keras.preprocessing import image # Для отрисовки изображения\n",
        "from tensorflow.keras.optimizers import Adam, Adadelta # Алгоритмы оптимизации, для настройки скорости обучения\n",
        "import numpy as np # Библиотека работы с массивами\n",
        "import matplotlib.pyplot as plt # Отрисовка изображений\n",
        "from PIL import Image # Отрисовка изображений\n",
        "import pandas as pd # Библиотека pandas\n",
        "from google.colab import files # Импорт файлов\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler # Функции для нормализации данных\n",
        "from sklearn import preprocessing # Пакет предварительной обработки данных\n",
        "\n",
        "# Отрисовывать изображения в ноутбуке, а не в консоль или файл\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OpTfgGWiSzT",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "3c142c92-0b68-455f-bc51-12d70df15e72"
      },
      "source": [
        "# Загружаем файлы\n",
        "files.upload()\n",
        "!ls # Выводим содержимое корневой папки"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-de0a71bf-7296-4b15-8f85-de08640285b6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-de0a71bf-7296-4b15-8f85-de08640285b6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sonar.csv to sonar.csv\n",
            "sample_data  sonar.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uO8Fnn3ZsfN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "7c4b40e1-89ab-407b-abb1-021c68be6af0"
      },
      "source": [
        "# Загружаем данные из файла sonar.csv\n",
        "df = pd.read_csv(\"sonar.csv\", header=None)   # header=None, когда данные не имеют строки с заголовками\n",
        "df.head()                                    # Выводим первые 5 строк наших данных"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.0645</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>0.2999</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.5071</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.5550</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.7104</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6791</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>0.5121</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.8537</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.6692</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.2744</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.2834</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.2641</td>\n",
              "      <td>0.1386</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0       1       2       3       4   ...      56      57      58      59  60\n",
              "0  0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032   R\n",
              "1  0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044   R\n",
              "2  0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078   R\n",
              "3  0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117   R\n",
              "4  0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094   R\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfudSojo9fY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86671727-dbed-49b9-d035-93479ac3f91d"
      },
      "source": [
        "print(df.shape) # Размерность данных"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(208, 61)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkBpydSVqsCI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0d0d0e-ba13-49ea-becd-50637cb7282b"
      },
      "source": [
        "dataset = df.values                 # Берем только значения массива(без индексов)\n",
        "X = dataset[:,0:60].astype(float)   # Присваиваем им тип данных - float(с плавающей точкой) данным с 0 по 60 колонки\n",
        "Y = dataset[:,60]                   # Присваеваем значению Y данные из столбца с индексом 60\n",
        "Y[Y=='R']='0'                       # Если значение элемента столбца равно 'R', присваеваем ему значение '0'\n",
        "Y[Y=='M']='1'                       # Если значение элемента столбца равно 'Y', присваеваем ему значение '1'\n",
        "Y = Y.astype(int)                   # Меняем тип данных столбца на 'int'(целочисленный тип данных)\n",
        "print(X.shape)                      # Выводим размерность X\n",
        "print(Y.shape)                      # Выводим размерность Y\n",
        "print(Y)                            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(208, 60)\n",
            "(208,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMenuxjkazgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96ead741-ef73-4216-971f-d325a40dd4ae"
      },
      "source": [
        "# Создание обучающей, проверочной и тестовой выборки\n",
        "# sklearn - популярная библиотека для машинного обучения\n",
        "# train_test_split - функция разделения на обучающую и проверочную/тестовую выборку\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# test_size=0.2 - будет выделено 20% от тренировочных данных \n",
        "# shuffle=True - перемешать данные\n",
        "# x_train - данные для обучения\n",
        "# x_test - данные для проверки\n",
        "# y_train - правильные ответы для обучения\n",
        "# y_test - правильные ответы для проверки\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)    \n",
        "print (x_train.shape)\n",
        "print (x_test.shape)\n",
        "print (y_train.shape)\n",
        "print (y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(166, 60)\n",
            "(42, 60)\n",
            "(166,)\n",
            "(42,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi-wF-oyQd41"
      },
      "source": [
        "# Функция пересоздаёт пустую сеть\n",
        "def createModel():\n",
        "\n",
        "  # Создаем сеть\n",
        "  model = Sequential()\n",
        "\n",
        "  # Добавляем слои\n",
        "  model.add(Dense(60, input_dim=60, activation='relu'))\n",
        "  model.add(Dense(30,  activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Компилируем сеть\n",
        "  model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "  return model # Возвращаем созданную сеть"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN4ERMFzKB3o",
        "outputId": "80fdbdd0-a947-4694-eb79-23f239c69e0f"
      },
      "source": [
        "# Сделаем списки с количеством примеров  n_val - проверочная выборка и count_list - обучающая выборка\n",
        "x_len = x_train.shape[0] # Запоминаем размер всей выборки целиком\n",
        "n_val = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\n",
        "count_list = [x_len-x for x in n_val]\n",
        "print(count_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[161, 156, 151, 146, 141, 136, 131, 126, 121, 116, 111, 106, 101, 96, 91, 86]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwsNnZuXscFA",
        "outputId": "db558d30-95ef-414f-b6b4-acb729135abe"
      },
      "source": [
        "# Запускаем в цикле создание и обучение нейронки на обучающем наборе данных из примеров в количестве от 86 до 161 с шагом 5, \n",
        "# чтобы понять какая выборка оптимальна для большей точности\n",
        "\n",
        "for i in range(len(n_val)):\n",
        "  print('Обучающая выборка', count_list[i], 'примеров')\n",
        "\n",
        "  model = createModel()\n",
        "\n",
        "  # Обучаем сеть\n",
        "  model.fit(x_train[:x_len-n_val[i]], \n",
        "            y_train[:x_len-n_val[i]], \n",
        "            batch_size=8, \n",
        "            epochs=100,            \n",
        "            validation_data=(x_train[x_len-n_val[i]:], y_train[x_len-n_val[i]:]), \n",
        "            verbose=0)\n",
        "    # Вычисляем результаты сети на тестовом наборе\n",
        "  scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "  # scores состоит из двух знанчений\n",
        "  # scores[0] - loss сети на тестовой выборке\n",
        "  # scores[1] - процент правильно распознанных примеров на тестовой выборке\n",
        "  print(scores)\n",
        "  print(\"Доля верных ответов на тестовых данных, в процентах: \", round(scores[1] * 100, 4), \"%\", sep=\"\")\n",
        "  prediction = model.predict(x_test) # Делаем предикт тестовой выборки\n",
        "  n = np.random.randint(0, 42)        # Предиктим рандомное число из базы\n",
        "  print('Предсказание ', np.argmax(prediction[n]))\n",
        "  print('Правильный ответ', y_test[n])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучающая выборка 161 примеров\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3852 - accuracy: 0.9048\n",
            "[0.38518092036247253, 0.9047619104385376]\n",
            "Доля верных ответов на тестовых данных, в процентах: 90.4762%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 156 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4136 - accuracy: 0.8571\n",
            "[0.41360577940940857, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 151 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4421 - accuracy: 0.8571\n",
            "[0.4420541524887085, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 146 примеров\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4798 - accuracy: 0.8333\n",
            "[0.47975650429725647, 0.8333333134651184]\n",
            "Доля верных ответов на тестовых данных, в процентах: 83.3333%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 141 примеров\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4111 - accuracy: 0.8333\n",
            "[0.4111134707927704, 0.8333333134651184]\n",
            "Доля верных ответов на тестовых данных, в процентах: 83.3333%\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5ab748ddd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 136 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3597 - accuracy: 0.8571\n",
            "[0.35974666476249695, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5ab7327560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 131 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5020 - accuracy: 0.7857\n",
            "[0.5020123720169067, 0.7857142686843872]\n",
            "Доля верных ответов на тестовых данных, в процентах: 78.5714%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 126 примеров\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4334 - accuracy: 0.8571\n",
            "[0.4333912134170532, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 121 примеров\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3599 - accuracy: 0.8333\n",
            "[0.35986223816871643, 0.8333333134651184]\n",
            "Доля верных ответов на тестовых данных, в процентах: 83.3333%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 116 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2990 - accuracy: 0.9048\n",
            "[0.2989668548107147, 0.9047619104385376]\n",
            "Доля верных ответов на тестовых данных, в процентах: 90.4762%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 111 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4618 - accuracy: 0.8810\n",
            "[0.4617774486541748, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 106 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4852 - accuracy: 0.7857\n",
            "[0.4851844012737274, 0.7857142686843872]\n",
            "Доля верных ответов на тестовых данных, в процентах: 78.5714%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 101 примеров\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4252 - accuracy: 0.8333\n",
            "[0.42522138357162476, 0.8333333134651184]\n",
            "Доля верных ответов на тестовых данных, в процентах: 83.3333%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 96 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4119 - accuracy: 0.8810\n",
            "[0.411940336227417, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 91 примеров\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4556 - accuracy: 0.8810\n",
            "[0.455643892288208, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 86 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4022 - accuracy: 0.9048\n",
            "[0.4021739065647125, 0.9047619104385376]\n",
            "Доля верных ответов на тестовых данных, в процентах: 90.4762%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUT8utMsSonN"
      },
      "source": [
        "# Путем нескольких запусков определились оптимальные значения обучающего набора данных от 86 до 111 примеров, а также 161 пример\n",
        "# Достигнут показатель доли верных ответов на тестовых данных, в процентах: 90.4762% при обучающей выборке 161 пример\n",
        "# К текущему эксперименту с выборкой применим слои Dropout и BatchNormalization \n",
        "# Создадим новую модель сети\n",
        "\n",
        "def createModelDropoutBatchNormalization():\n",
        "\n",
        "  # Создаем сеть\n",
        "  model = Sequential()\n",
        "\n",
        "  # Добавляем слои\n",
        "  # model.add(BatchNormalization()) \n",
        "  model.add(Dropout(0.2, input_dim=60))\n",
        "  model.add(Dense(60, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(30, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Компилируем сеть\n",
        "  model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "  return model # Возвращаем созданную сеть"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL4Zh3DJRs4H",
        "outputId": "901fad4a-c794-467c-f027-3935331f5b0e"
      },
      "source": [
        "\n",
        "for i in range(len(n_val)):\n",
        "  print('Обучающая выборка', count_list[i], 'примеров')\n",
        "\n",
        "  model = createModelDropoutBatchNormalization()\n",
        "\n",
        "  # Обучаем сеть\n",
        "  model.fit(x_train[:x_len-n_val[i]], \n",
        "            y_train[:x_len-n_val[i]], \n",
        "            batch_size=8, \n",
        "            epochs=100,            \n",
        "            validation_data=(x_train[x_len-n_val[i]:], y_train[x_len-n_val[i]:]), \n",
        "            verbose=0)\n",
        "    # Вычисляем результаты сети на тестовом наборе\n",
        "  scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "  # scores состоит из двух знанчений\n",
        "  # scores[0] - loss сети на тестовой выборке\n",
        "  # scores[1] - процент правильно распознанных примеров на тестовой выборке\n",
        "  print(scores)\n",
        "  print(\"Доля верных ответов на тестовых данных, в процентах: \", round(scores[1] * 100, 4), \"%\", sep=\"\")\n",
        "  prediction = model.predict(x_test) # Делаем предикт тестовой выборки\n",
        "  n = np.random.randint(0, 42)        # Предиктим рандомное число из базы\n",
        "  print('Предсказание ', np.argmax(prediction[n]))\n",
        "  print('Правильный ответ', y_test[n])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучающая выборка 161 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2440 - accuracy: 0.8810\n",
            "[0.24397200345993042, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 156 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3239 - accuracy: 0.8810\n",
            "[0.3239283859729767, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 151 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2807 - accuracy: 0.8810\n",
            "[0.28071328997612, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 146 примеров\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3313 - accuracy: 0.8571\n",
            "[0.33125340938568115, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 141 примеров\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2352 - accuracy: 0.8810\n",
            "[0.23523646593093872, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 136 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2506 - accuracy: 0.8571\n",
            "[0.2505916953086853, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 131 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2672 - accuracy: 0.8810\n",
            "[0.2672184109687805, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 126 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2541 - accuracy: 0.8810\n",
            "[0.2540639042854309, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 121 примеров\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2485 - accuracy: 0.8571\n",
            "[0.24848811328411102, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 116 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3306 - accuracy: 0.8571\n",
            "[0.3306275010108948, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 111 примеров\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3094 - accuracy: 0.9048\n",
            "[0.30942994356155396, 0.9047619104385376]\n",
            "Доля верных ответов на тестовых данных, в процентах: 90.4762%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 106 примеров\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3758 - accuracy: 0.8095\n",
            "[0.3758492171764374, 0.8095238208770752]\n",
            "Доля верных ответов на тестовых данных, в процентах: 80.9524%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 101 примеров\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2974 - accuracy: 0.8810\n",
            "[0.2973712384700775, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 96 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3069 - accuracy: 0.8571\n",
            "[0.3068670630455017, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 91 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2810 - accuracy: 0.9048\n",
            "[0.2809949517250061, 0.9047619104385376]\n",
            "Доля верных ответов на тестовых данных, в процентах: 90.4762%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 86 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3152 - accuracy: 0.8571\n",
            "[0.3152400255203247, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_snNgHjrOiP"
      },
      "source": [
        "# Несколько запусков сети со слоями Dropout и BatchNormalization в разных комбинациях дал 90.4762% на тестовой выборке ,при обучающей выборке из 91 примера\n",
        "# Создадим новую модель сети без слоя Normalization\n",
        "\n",
        "def createModelDropout():\n",
        "\n",
        "  # Создаем сеть\n",
        "  model = Sequential()\n",
        "\n",
        "  # Добавляем слои\n",
        "  \n",
        "  model.add(Dropout(0.2, input_dim=60))\n",
        "  model.add(Dense(60, activation='relu'))\n",
        "  \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(30, activation='relu'))\n",
        "  \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Компилируем сеть\n",
        "  model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "  return model # Возвращаем созданную сеть"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQsLx5sDrA4c",
        "outputId": "fc7a3fc2-50e8-4f0e-cd38-c5463d4b9375"
      },
      "source": [
        "# Запускаем обучение сети без слоя нормализации c Dropout слоем и получаем точность 90.4762% на тестовой выборке ,при обучающей выборке из 151 или 91 примеров\n",
        "\n",
        "for i in range(len(n_val)):\n",
        "  print('Обучающая выборка', count_list[i], 'примеров')\n",
        "\n",
        "  model = createModelDropout()\n",
        "\n",
        "  # Обучаем сеть\n",
        "  model.fit(x_train[:x_len-n_val[i]], \n",
        "            y_train[:x_len-n_val[i]], \n",
        "            batch_size=8, \n",
        "            epochs=100,            \n",
        "            validation_data=(x_train[x_len-n_val[i]:], y_train[x_len-n_val[i]:]), \n",
        "            verbose=0)\n",
        "    # Вычисляем результаты сети на тестовом наборе\n",
        "  scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "  # scores состоит из двух знанчений\n",
        "  # scores[0] - loss сети на тестовой выборке\n",
        "  # scores[1] - процент правильно распознанных примеров на тестовой выборке\n",
        "  print(scores)\n",
        "  print(\"Доля верных ответов на тестовых данных, в процентах: \", round(scores[1] * 100, 4), \"%\", sep=\"\")\n",
        "  prediction = model.predict(x_test) # Делаем предикт тестовой выборки\n",
        "  n = np.random.randint(0, 42)        # Предиктим рандомное число из базы\n",
        "  print('Предсказание ', np.argmax(prediction[n]))\n",
        "  print('Правильный ответ', y_test[n])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучающая выборка 161 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3131 - accuracy: 0.8810\n",
            "[0.3131074607372284, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 156 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2864 - accuracy: 0.8810\n",
            "[0.2863517999649048, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 151 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3240 - accuracy: 0.9048\n",
            "[0.32404083013534546, 0.9047619104385376]\n",
            "Доля верных ответов на тестовых данных, в процентах: 90.4762%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 146 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3278 - accuracy: 0.8333\n",
            "[0.3277680277824402, 0.8333333134651184]\n",
            "Доля верных ответов на тестовых данных, в процентах: 83.3333%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 141 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3204 - accuracy: 0.8571\n",
            "[0.32043948769569397, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 136 примеров\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3180 - accuracy: 0.8810\n",
            "[0.3179992139339447, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 131 примеров\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3385 - accuracy: 0.8095\n",
            "[0.3385239839553833, 0.8095238208770752]\n",
            "Доля верных ответов на тестовых данных, в процентах: 80.9524%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 126 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3166 - accuracy: 0.8571\n",
            "[0.31660881638526917, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 121 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3590 - accuracy: 0.8333\n",
            "[0.35897788405418396, 0.8333333134651184]\n",
            "Доля верных ответов на тестовых данных, в процентах: 83.3333%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 116 примеров\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3307 - accuracy: 0.8810\n",
            "[0.3306889235973358, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 111 примеров\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3546 - accuracy: 0.8333\n",
            "[0.3545880615711212, 0.8333333134651184]\n",
            "Доля верных ответов на тестовых данных, в процентах: 83.3333%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 106 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3903 - accuracy: 0.8333\n",
            "[0.3903394937515259, 0.8333333134651184]\n",
            "Доля верных ответов на тестовых данных, в процентах: 83.3333%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 101 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3614 - accuracy: 0.8333\n",
            "[0.3613613545894623, 0.8333333134651184]\n",
            "Доля верных ответов на тестовых данных, в процентах: 83.3333%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 96 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3319 - accuracy: 0.8571\n",
            "[0.3319185674190521, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 91 примеров\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3225 - accuracy: 0.9048\n",
            "[0.32251590490341187, 0.9047619104385376]\n",
            "Доля верных ответов на тестовых данных, в процентах: 90.4762%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 86 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3813 - accuracy: 0.8095\n",
            "[0.38133543729782104, 0.8095238208770752]\n",
            "Доля верных ответов на тестовых данных, в процентах: 80.9524%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az-Wc2UxtRdK"
      },
      "source": [
        "# Создадим новую модель сети без слоя Dropout со слоем нормализации, интересно посмотреть что будет ))\n",
        "\n",
        "def createModelBatchNormalization():\n",
        "\n",
        "  # Создаем сеть\n",
        "  model = Sequential()\n",
        "\n",
        "  # Добавляем слои BatchNormalization вместо Dropout\n",
        "  \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(60, activation='relu'))\n",
        "  \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(30, activation='relu'))\n",
        "  \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Компилируем сеть\n",
        "  model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "  return model # Возвращаем созданную сеть"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEJVfUkOxKeY",
        "outputId": "9d500fc0-3966-44a1-d1cd-c95128ecc7a6"
      },
      "source": [
        "# Запускаем обучение сети без слоя Dropout и получаем:\n",
        "# - точность 92.8571% на тестовой выборке ,при обучающей выборке из 141 , 136, 106 примеров\n",
        "# - точность 90.4762% на тестовой выборке ,при обучающей выборке из 126 примеров\n",
        "\n",
        "for i in range(len(n_val)):\n",
        "  print('Обучающая выборка', count_list[i], 'примеров')\n",
        "\n",
        "  model = createModelBatchNormalization()\n",
        "\n",
        "  # Обучаем сеть\n",
        "  model.fit(x_train[:x_len-n_val[i]], \n",
        "            y_train[:x_len-n_val[i]], \n",
        "            batch_size=8, \n",
        "            epochs=100,            \n",
        "            validation_data=(x_train[x_len-n_val[i]:], y_train[x_len-n_val[i]:]), \n",
        "            verbose=0)\n",
        "    # Вычисляем результаты сети на тестовом наборе\n",
        "  scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "  # scores состоит из двух знанчений\n",
        "  # scores[0] - loss сети на тестовой выборке\n",
        "  # scores[1] - процент правильно распознанных примеров на тестовой выборке\n",
        "  print(scores)\n",
        "  print(\"Доля верных ответов на тестовых данных, в процентах: \", round(scores[1] * 100, 4), \"%\", sep=\"\")\n",
        "  prediction = model.predict(x_test) # Делаем предикт тестовой выборки\n",
        "  n = np.random.randint(0, 42)        # Предиктим рандомное число из базы\n",
        "  print('Предсказание ', np.argmax(prediction[n]))\n",
        "  print('Правильный ответ', y_test[n])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучающая выборка 161 примеров\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3851 - accuracy: 0.8333\n",
            "[0.385055273771286, 0.8333333134651184]\n",
            "Доля верных ответов на тестовых данных, в процентах: 83.3333%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 156 примеров\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4996 - accuracy: 0.8571\n",
            "[0.49959826469421387, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 151 примеров\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3954 - accuracy: 0.8810\n",
            "[0.3954109847545624, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 146 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4055 - accuracy: 0.8810\n",
            "[0.40548768639564514, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 141 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2592 - accuracy: 0.9286\n",
            "[0.2591746151447296, 0.9285714030265808]\n",
            "Доля верных ответов на тестовых данных, в процентах: 92.8571%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 136 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3024 - accuracy: 0.9286\n",
            "[0.30242475867271423, 0.9285714030265808]\n",
            "Доля верных ответов на тестовых данных, в процентах: 92.8571%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 131 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4996 - accuracy: 0.8810\n",
            "[0.49957484006881714, 0.8809523582458496]\n",
            "Доля верных ответов на тестовых данных, в процентах: 88.0952%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 126 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4533 - accuracy: 0.9048\n",
            "[0.45333603024482727, 0.9047619104385376]\n",
            "Доля верных ответов на тестовых данных, в процентах: 90.4762%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 121 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4105 - accuracy: 0.8333\n",
            "[0.41048866510391235, 0.8333333134651184]\n",
            "Доля верных ответов на тестовых данных, в процентах: 83.3333%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 116 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4093 - accuracy: 0.7857\n",
            "[0.409286767244339, 0.7857142686843872]\n",
            "Доля верных ответов на тестовых данных, в процентах: 78.5714%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 111 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3166 - accuracy: 0.8571\n",
            "[0.31660890579223633, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 106 примеров\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2642 - accuracy: 0.9286\n",
            "[0.264165997505188, 0.9285714030265808]\n",
            "Доля верных ответов на тестовых данных, в процентах: 92.8571%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 101 примеров\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2972 - accuracy: 0.8571\n",
            "[0.2971821427345276, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 1\n",
            "Обучающая выборка 96 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4371 - accuracy: 0.8333\n",
            "[0.4370800256729126, 0.8333333134651184]\n",
            "Доля верных ответов на тестовых данных, в процентах: 83.3333%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 91 примеров\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3936 - accuracy: 0.8571\n",
            "[0.3935973644256592, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n",
            "Обучающая выборка 86 примеров\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5195 - accuracy: 0.8571\n",
            "[0.5195145606994629, 0.8571428656578064]\n",
            "Доля верных ответов на тестовых данных, в процентах: 85.7143%\n",
            "Предсказание  0\n",
            "Правильный ответ 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT148dIvzeeg"
      },
      "source": [
        "Резюме:\n",
        "Максимальная точность 92.8571% достигнута на тестовой выборке ,при обучающей выборке из 141 , 136, 106 примеров с применением слоев BatchNormalization"
      ]
    }
  ]
}